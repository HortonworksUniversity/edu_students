{"paragraphs":[{"text":"%md\n# About This Lab\n**Objective:** Become familiar with simple RDD operations. Load a simple text file into Resilient Distributed Dataset (RDD) and display the contents. Then \ncreate two new RDDs and use transformations to union them and remove duplicates.\n**Exercise files** \n    Exercise directory: /home/training/training_materials/devsh/exercises/rdds\n    Data (local): /home/training/training_materials/devsh/data/frostroad.txt\n                  /home/training/training_materials/devsh/data/makes1.txt  makes2.txt\n**Successful outcome:**\n**Before you begin:**\n**Related lessons:** RDD Overview\n\n---","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>About This Lab</h1>\n<p><strong>Objective:</strong> Become familiar with simple RDD operations. Load a simple text file into Resilient Distributed Dataset (RDD) and display the contents. Then\n<br  />create two new RDDs and use transformations to union them and remove duplicates.\n<br  /><strong>Exercise files</strong></p>\n<pre><code>Exercise directory: /home/training/training_materials/devsh/exercises/rdds\nData (local): /home/training/training_materials/devsh/data/frostroad.txt\n              /home/training/training_materials/devsh/data/makes1.txt  makes2.txt\n</code></pre>\n<p><strong>Successful outcome:</strong>\n<br  /><strong>Before you begin:</strong>\n<br  /><strong>Related lessons:</strong> RDD Overview</p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1617197552235_-1776510587","id":"20171105-200834_1116095891","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:248537"},{"text":"%md\n# Setup\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Setup</h1>\n"}]},"apps":[],"jobName":"paragraph_1617197552236_229747249","id":"20181114-164229_902436001","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248538"},{"title":"Set the environment variable to manage thread count","text":"%sh\n\nPYSPARK_PIN_THREAD=true","user":"anonymous","dateUpdated":"2021-03-31T08:43:33-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1617197552236_1439295683","id":"20200830-145651_990177858","dateCreated":"2021-03-31T06:32:32-0700","dateStarted":"2021-03-31T08:43:33-0700","dateFinished":"2021-03-31T08:43:33-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248539"},{"title":"Start the Spark Context for Livy","text":"%pyspark\n\nsc= spark.sparkContext","user":"anonymous","dateUpdated":"2021-03-31T08:43:36-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<font color=\"red\">Previous livy session is expired, new livy session is created. Paragraphs that depend on this paragraph need to be re-executed!</font>"}]},"apps":[],"jobName":"paragraph_1617197552236_1219181871","id":"20200830-145805_1013187790","dateCreated":"2021-03-31T06:32:32-0700","dateStarted":"2021-03-31T08:43:36-0700","dateFinished":"2021-03-31T08:44:22-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248540"},{"text":"%md\n# Lab\n---","user":"anonymous","dateUpdated":"2021-03-31T08:43:38-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Lab</h1>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1617197552237_1928527575","id":"20181114-164844_1661453681","dateCreated":"2021-03-31T06:32:32-0700","dateStarted":"2021-03-31T08:43:38-0700","dateFinished":"2021-03-31T08:43:38-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248541"},{"text":"%md\n### Review the API Documentation for RDD Operations\n\nReview the API docs for the RDD class (which is in the Python module pyspark, and the Scala package org.apache.spark.rdd). Take note of the various available \noperations.","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Review the API Documentation for RDD Operations</h3>\n<p>Review the API docs for the RDD class (which is in the Python module pyspark, and the Scala package org.apache.spark.rdd). Take note of the various available\n<br  />operations.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552237_1552439170","id":"20200113-224229_628565915","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248542"},{"text":"%md\n### Read and Display Data from a Text File\n\nReview the simple text file you will be using. The file is located at /home/training/training_materials/devsh/data/frostroad.txt.","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Read and Display Data from a Text File</h3>\n<p>Review the simple text file you will be using. The file is located at /home/training/training_materials/devsh/data/frostroad.txt.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552237_-1213640840","id":"20200113-224321_2135751926","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248543"},{"title":"1 - Read /home/training/training_materials/devsh/data/frostroad.txt","text":"%sh\n\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617197552237_-982173508","id":"20200113-224501_1013111284","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248544"},{"title":"2 - Upload the text file to HDFS directory /devsh_loudacre","text":"%sh\n\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617197552238_-751725947","id":"20200113-224925_2003023834","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248545"},{"title":"3 - Define an RDD based on the frostroad.txt text file","text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617197552238_1926722632","id":"20200113-225910_142286046","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248546"},{"text":"%md\nSpark has not yet read the file. It will not do so until you perform an action on the RDD. Try counting the number of elements in the RDD using the count action:","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Spark has not yet read the file. It will not do so until you perform an action on the RDD. Try counting the number of elements in the RDD using the count action:</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552238_-326942449","id":"20200113-230441_1168973087","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248547"},{"title":"4 - Count the lines in your RDD","text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617197552238_183014338","id":"20200113-230437_57310419","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248548"},{"text":"%md\nThe count operation causes the RDD to be materialized (created and populated).\nThe number of lines (23) should be displayed, for example:\n```pyspark\nOut[2]: 23(Python) \n```\nor\n```spark\nres1: Long = 23(Scala)\n```\nCall the collect operation to return all data in the RDD to the Spark driver. Take note of the type of the return value; in Python will be a list of strings, \nand in Scala it will be an array of strings.\n\n**Note:** collect returns the entire set of data. This is convenient for very small RDDs like this one, but be careful using collect for more typical large sets of data.","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>The count operation causes the RDD to be materialized (created and populated).\n<br  />The number of lines (23) should be displayed, for example:</p>\n<pre><code class=\"pyspark\">Out[2]: 23(Python) \n</code></pre>\n<p>or</p>\n<pre><code class=\"spark\">res1: Long = 23(Scala)\n</code></pre>\n<p>Call the collect operation to return all data in the RDD to the Spark driver. Take note of the type of the return value; in Python will be a list of strings,\n<br  />and in Scala it will be an array of strings.</p>\n<p><strong>Note:</strong> collect returns the entire set of data. This is convenient for very small RDDs like this one, but be careful using collect for more typical large sets of data.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552238_-154600697","id":"20200113-230739_691307132","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248549"},{"title":"5 - Collect your RDD","text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617197552239_425741100","id":"20200113-230735_278776244","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248550"},{"title":"6 - Display the contents of the collected data by looping through the collection","text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617197552239_1169549433","id":"20200113-231332_2020637729","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248551"},{"text":"%md\n### Transform Data in an RDD\n\nIn this exercise, you will load two text files containing the names of various cell phone makes, and append one to the other. Review the two text files you will \nbe using by viewing (without editing) the file in a separate window. The files are makes1.txt and makes2.txt in the \n/home/training/training_materials/devsh/data directory.","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Transform Data in an RDD</h3>\n<p>In this exercise, you will load two text files containing the names of various cell phone makes, and append one to the other. Review the two text files you will\n<br  />be using by viewing (without editing) the file in a separate window. The files are makes1.txt and makes2.txt in the\n<br  />/home/training/training_materials/devsh/data directory.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552239_900608036","id":"20200113-231500_1328075001","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248552"},{"title":"7 - Upload the two text file to HDFS directory /devsh_loudacre","text":"%sh\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617197552240_-1760882308","id":"20200113-231458_1609746509","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248553"},{"title":"8 - Create an RDD called makes1RDD based on the /devsh_loudacre/makes1.txt file","text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617197552240_-423184374","id":"20200113-232112_1295518722","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248554"},{"title":"9 - Display the contents of the makes1RDD data using collect and then looping through returned collection","text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617197552240_-685274465","id":"20200113-232111_276596298","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248555"},{"title":"10 - Repeat the previous steps to create and display an RDD called makes2RDD based on the second file, /devsh_loudacre/makes2.txt","text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617197552240_-1895705634","id":"20200113-232706_792978821","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248556"},{"title":"11 - Create a new RDD by appending the second RDD to the first using the union transformation","text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617197552241_-1005521015","id":"20200113-232958_1153053244","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248557"},{"title":"12 - Collect and display the contents of the new allMakesRDD RDD","text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617197552241_150626614","id":"20200113-233207_1689738900","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248558"},{"text":"%md\nUse the distinct transformation to remove duplicates from allMakesRDD. Collect and display the contents to confirm that duplicate elements were removed.","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Use the distinct transformation to remove duplicates from allMakesRDD. Collect and display the contents to confirm that duplicate elements were removed.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552241_579468649","id":"20200113-233456_1826475012","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248559"},{"title":"13 - Use the distinct transformation to remove duplicates from allMakesRDD","text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617197552241_2060324384","id":"20200113-233451_1173735633","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248560"},{"text":"%md\n### Optional: \nTry performing different transformations on the RDDs you created above, such as intersection, subtract, or zip. See the RDD API documentation for details.","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Optional:</h3>\n<p>Try performing different transformations on the RDDs you created above, such as intersection, subtract, or zip. See the RDD API documentation for details.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552241_1450907061","id":"20200113-233716_587539793","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248561"},{"text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617197552242_-664246008","id":"20210123-132028_2142098562","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248562"},{"text":"%md\n# Result\n**You have now:** \n\n* loaded a simple text file into a Resilient Distributed Dataset (RDD) and displayed its contents;\n* created two new RDDs and \n* used transformations to union them and remove duplicates.\n\n---","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Result</h1>\n<p><strong>You have now:</strong></p>\n<ul>\n<li>loaded a simple text file into a Resilient Distributed Dataset (RDD) and displayed its contents;</li>\n<li>created two new RDDs and</li>\n<li>used transformations to union them and remove duplicates.</li>\n</ul>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1617197552242_1316371545","id":"20181119-142716_792318228","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248563"},{"text":"%md\n# Solution\n---","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Solution</h1>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1617197552242_-2048501994","id":"20171113-155535_1769142099","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248564"},{"text":"%md\n### Review the API Documentation for RDD Operations\n\nReview the API docs for the RDD class (which is in the Python module pyspark, and the Scala package org.apache.spark.rdd). Take note of the various available \noperations.","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Review the API Documentation for RDD Operations</h3>\n<p>Review the API docs for the RDD class (which is in the Python module pyspark, and the Scala package org.apache.spark.rdd). Take note of the various available\n<br  />operations.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552242_1204867473","id":"20210121-154951_163702855","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248565"},{"text":"%md\n#### Define RDD\nResilient Distributed Dataset (RDD) is a fundamental data structure of Spark. It is an immutable distributed collection of row objects. In Spark a RDD is \ndivided into logical partitions, each partition may be computed on different nodes of the cluster. A Spark logical partition generally maps to a HDFS data block.","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Define RDD</h4>\n<p>Resilient Distributed Dataset (RDD) is a fundamental data structure of Spark. It is an immutable distributed collection of row objects. In Spark a RDD is\n<br  />divided into logical partitions, each partition may be computed on different nodes of the cluster. A Spark logical partition generally maps to a HDFS data block.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552242_-2073684991","id":"20210123-131250_1289201985","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248566"},{"text":"%md\n### Read and Display Data from a Text File","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Read and Display Data from a Text File</h3>\n"}]},"apps":[],"jobName":"paragraph_1617197552243_-1739883950","id":"20210123-125534_651787489","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248567"},{"title":"1 - Read /home/training/training_materials/devsh/data/frostroad.txt","text":"%sh\n\ncat /home/training/training_materials/devsh/data/frostroad.txt","user":"anonymous","dateUpdated":"2021-03-31T09:45:50-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Two roads diverged in a yellow wood,\nAnd sorry I could not travel both\nAnd be one traveler, long I stood\nAnd looked down one as far as I could\nTo where it bent in the undergrowth;\n\nThen took the other, as just as fair,\nAnd having perhaps the better claim,\nBecause it was grassy and wanted wear;\nThough as for that the passing there\nHad worn them really about the same,\n\nAnd both that morning equally lay\nIn leaves no step had trodden black.\nOh, I kept the first for another day!\nYet knowing how way leads on to way,\nI doubted if I should ever come back.\n\nI shall be telling this with a sigh\nSomewhere ages and ages hence:\nTwo roads diverged in a wood, and I--\nI took the one less traveled by,\nAnd that has made all the difference."}]},"apps":[],"jobName":"paragraph_1617197552243_478727890","id":"20200113-224727_1264359813","dateCreated":"2021-03-31T06:32:32-0700","dateStarted":"2021-03-31T09:45:50-0700","dateFinished":"2021-03-31T09:45:50-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248568"},{"text":"%md\nReview the simple text file you will be using. The file is located at \n`/home/training/training_materials/devsh/data/frostroad.txt`.\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Review the simple text file you will be using. The file is located at\n<br  /><code>/home/training/training_materials/devsh/data/frostroad.txt</code>.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552243_-1025341981","id":"20210121-155224_1487935282","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248569"},{"title":"2 - Upload the text file to HDFS directory /devsh_loudacre","text":"%sh\nhdfs dfs -rm -r -skipTrash /devsh_loudacre/frostroad.txt\nhdfs dfs -put /home/training/training_materials/devsh/data/frostroad.txt /devsh_loudacre","user":"anonymous","dateUpdated":"2021-03-31T09:45:56-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rm: `/devsh_loudacre/frostroad.txt': No such file or directory\n"}]},"apps":[],"jobName":"paragraph_1617197552244_-820481490","id":"20200113-225002_1928604162","dateCreated":"2021-03-31T06:32:32-0700","dateStarted":"2021-03-31T09:45:56-0700","dateFinished":"2021-03-31T09:46:00-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248570"},{"text":"%md\nLoad the `frostroad.txt` file into hdfs.\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Load the <code>frostroad.txt</code> file into hdfs.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552244_1204399593","id":"20210121-160418_139257689","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248571"},{"title":"3 - Define an RDD based on the frostroad.txt text file","text":"%pyspark\n\nmyRDD = sc.textFile(\"/devsh_loudacre/frostroad.txt\")","user":"anonymous","dateUpdated":"2021-03-31T09:46:03-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<font color=\"red\">Previous livy session is expired, new livy session is created. Paragraphs that depend on this paragraph need to be re-executed!</font>"}]},"apps":[],"jobName":"paragraph_1617197552244_71279865","id":"20200113-225945_408602366","dateCreated":"2021-03-31T06:32:32-0700","dateStarted":"2021-03-31T09:46:03-0700","dateFinished":"2021-03-31T09:46:50-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248572"},{"text":"%md\nDefine a RDD, `myRDD`, and load the text file `frostroad.txt`\nUse the spark context `textFile` function to load unstructured data, such as web logs.\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Define a RDD, <code>myRDD</code>, and load the text file <code>frostroad.txt</code>\n<br  />Use the spark context <code>textFile</code> function to load unstructured data, such as web logs.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552245_1157105413","id":"20210121-160450_434885179","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248573"},{"title":"4 - Count the lines in your RDD","text":"%pyspark\n\nsc.setJobGroup(\"Working with RDDs\",\"Count the lines in your RDD\")\nmyRDD.count()","user":"anonymous","dateUpdated":"2021-03-31T09:46:20-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"23"}]},"apps":[],"jobName":"paragraph_1617197552245_1696962219","id":"20200113-230550_584302657","dateCreated":"2021-03-31T06:32:32-0700","dateStarted":"2021-03-31T09:46:20-0700","dateFinished":"2021-03-31T09:46:53-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248574"},{"text":"%md\nSpark has not yet read the file. It will not do so until you perform an action on the RDD. Try counting the number of elements in the RDD using the count action:\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Spark has not yet read the file. It will not do so until you perform an action on the RDD. Try counting the number of elements in the RDD using the count action:</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552245_183161232","id":"20210121-155030_1717285378","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248575"},{"text":"%md\n#### Spark is lazy execution\nSpark uses lazy execution, transformations do not manipulate data, only actions result in data manipulation. The term materialize is used when data is \ncreated and populated.\n\nThe count operation causes the RDD to be materialized.\nThe number of lines (23) should be displayed, for example:\n```pyspark\nOut[2]: 23(Python) \n```\nor\n```spark\nres1: Long = 23(Scala)\n```\nCall the collect operation to return all data in the RDD to the Spark driver. \nTake note of the type of the return value; in Python will be a list of strings, and in Scala it will be an array of strings.\n\n**Note:** collect returns the entire set of data. This is convenient for very small RDDs like this one, but be careful using collect for more typical large \nsets of data.\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Spark is lazy execution</h4>\n<p>Spark uses lazy execution, transformations do not manipulate data, only actions result in data manipulation. The term materialize is used when data is\n<br  />created and populated.</p>\n<p>The count operation causes the RDD to be materialized.\n<br  />The number of lines (23) should be displayed, for example:</p>\n<pre><code class=\"pyspark\">Out[2]: 23(Python) \n</code></pre>\n<p>or</p>\n<pre><code class=\"spark\">res1: Long = 23(Scala)\n</code></pre>\n<p>Call the collect operation to return all data in the RDD to the Spark driver.\n<br  />Take note of the type of the return value; in Python will be a list of strings, and in Scala it will be an array of strings.</p>\n<p><strong>Note:</strong> collect returns the entire set of data. This is convenient for very small RDDs like this one, but be careful using collect for more typical large\n<br  />sets of data.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552245_1662217200","id":"20210121-155324_467124236","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248576"},{"title":"5 - Collect your RDD","text":"%pyspark\n\nsc.setJobGroup(\"Working with RDDs\",\"Collect your RDD\")\nlines = myRDD.collect()","user":"anonymous","dateUpdated":"2021-03-31T08:49:23-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1617197552245_1904040217","id":"20200113-231206_1684140761","dateCreated":"2021-03-31T06:32:32-0700","dateStarted":"2021-03-31T08:49:23-0700","dateFinished":"2021-03-31T08:49:24-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248577"},{"text":"%md\nReturn all of the data by using the `collect` function. Take note of the type of the return value; in Python it will be a list of strings, and in Scala it \nwill be an array of strings.\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Return all of the data by using the <code>collect</code> function. Take note of the type of the return value; in Python it will be a list of strings, and in Scala it\n<br  />will be an array of strings.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552246_1166148439","id":"20210121-160633_1720813316","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248578"},{"title":"6 - Display the contents of the collected data by looping through the collection","text":"%pyspark\n\nfor line in lines: print(line)","user":"anonymous","dateUpdated":"2021-03-31T08:50:29-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Two roads diverged in a yellow wood,\nAnd sorry I could not travel both\nAnd be one traveler, long I stood\nAnd looked down one as far as I could\nTo where it bent in the undergrowth;\n\nThen took the other, as just as fair,\nAnd having perhaps the better claim,\nBecause it was grassy and wanted wear;\nThough as for that the passing there\nHad worn them really about the same,\n\nAnd both that morning equally lay\nIn leaves no step had trodden black.\nOh, I kept the first for another day!\nYet knowing how way leads on to way,\nI doubted if I should ever come back.\n\nI shall be telling this with a sigh\nSomewhere ages and ages hence:\nTwo roads diverged in a wood, and I--\nI took the one less traveled by,\nAnd that has made all the difference."}]},"apps":[],"jobName":"paragraph_1617197552246_795877526","id":"20200113-231347_761889459","dateCreated":"2021-03-31T06:32:32-0700","dateStarted":"2021-03-31T08:50:29-0700","dateFinished":"2021-03-31T08:50:30-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248579"},{"text":"%md\n### Transform Data in a RDD\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Transform Data in a RDD</h3>\n"}]},"apps":[],"jobName":"paragraph_1617197552246_-179082912","id":"20210123-130351_1801379061","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248580"},{"title":"7 - Upload the two text file to HDFS directory /devsh_loudacre","text":"%sh\nhdfs dfs -rm -r -skipTrash /devsh_loudacre/makes1.txt /devsh/loudacre/makes2.txt\nhdfs dfs -put /home/training/training_materials/devsh/data/makes*.txt /devsh_loudacre\n\nhdfs dfs -head /devsh_loudacre/makes1.txt\necho \" \"\necho \" \"\nhdfs dfs -head /devsh_loudacre/makes2.txt","user":"anonymous","dateUpdated":"2021-03-31T08:52:57-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rm: `/devsh_loudacre/makes1.txt': No such file or directory\nrm: `/devsh/loudacre/makes2.txt': No such file or directory\nSorrento\nTitanic\nSorrento\nTitanic\nMeeToo\nMeeToo\nMeeToo\nTitanic\nMeeToo\nMeeToo\nTitanic\nSorrento\nSorrento \n \nTitanic\nMeeToo\nMeeToo\niFruit\niFruit\nTitanic\nMeeToo\niFruit\nTitanic\nRonin\nTitanic\nTitanic\nTitanic"}]},"apps":[],"jobName":"paragraph_1617197552246_-1460094508","id":"20200113-231737_1676606596","dateCreated":"2021-03-31T06:32:32-0700","dateStarted":"2021-03-31T08:52:57-0700","dateFinished":"2021-03-31T08:53:05-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248581"},{"text":"%md\nIn this exercise, you will load two text files containing the names of various cell phone makes, and append one to the other. Review the two text files you will \nbe using. The files are makes1.txt and makes2.txt in the \n`/home/training/training_materials/devsh/data directory`.\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>In this exercise, you will load two text files containing the names of various cell phone makes, and append one to the other. Review the two text files you will\n<br  />be using. The files are makes1.txt and makes2.txt in the\n<br  /><code>/home/training/training_materials/devsh/data directory</code>.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552247_-1141521078","id":"20210121-155430_2040341259","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248582"},{"title":"8 - Create an RDD called makes1RDD based on the /devsh_loudacre/makes1.txt file","text":"%pyspark\n\nmakes1RDD = sc.textFile(\"/devsh_loudacre/makes1.txt\")","user":"anonymous","dateUpdated":"2021-03-31T08:53:45-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1617197552247_-574801513","id":"20200113-232201_1879966356","dateCreated":"2021-03-31T06:32:32-0700","dateStarted":"2021-03-31T08:53:45-0700","dateFinished":"2021-03-31T08:53:46-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248583"},{"text":"%md\nCreate an RDD, `makes1RDD`, and load the makes1.txt file.\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Create an RDD, <code>makes1RDD</code>, and load the makes1.txt file.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552247_-123239787","id":"20210121-160807_1322215638","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248584"},{"title":"9 - Display the contents of the makes1RDD data using collect and then looping through returned collection","text":"%pyspark\n\nsc.setJobGroup(\"Working with RDDs\",\"Display the contents of the makes1RDD\")\nfor make in makes1RDD.collect(): print(make)","user":"anonymous","dateUpdated":"2021-03-31T08:54:01-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Sorrento\nTitanic\nSorrento\nTitanic\nMeeToo\nMeeToo\nMeeToo\nTitanic\nMeeToo\nMeeToo\nTitanic\nSorrento\nSorrento"}]},"apps":[],"jobName":"paragraph_1617197552247_-715651648","id":"20200113-232514_292697455","dateCreated":"2021-03-31T06:32:32-0700","dateStarted":"2021-03-31T08:54:01-0700","dateFinished":"2021-03-31T08:54:02-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248585"},{"text":"%md\n#### Looping through the RDD\nRDD are collections of row objects, which are unstructured records, unlike a DataFrame, you must loop through the collection to display the records.\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Looping through the RDD</h4>\n<p>RDD are collections of row objects, which are unstructured records, unlike a DataFrame, you must loop through the collection to display the records.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552247_-1436551489","id":"20210123-130840_840805836","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248586"},{"title":"10 - Repeat the previous steps to create and display an RDD called makes2RDD based on the second file, /devsh_loudacre/makes2.txt","text":"%pyspark\n\nmakes2RDD = sc.textFile(\"/devsh_loudacre/makes2.txt\")\nsc.setJobGroup(\"Working with RDDs\",\"Display the contents of the makes2RDD\")\nfor make in makes2RDD.collect(): print(make)","user":"anonymous","dateUpdated":"2021-03-31T08:54:59-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Titanic\nMeeToo\nMeeToo\niFruit\niFruit\nTitanic\nMeeToo\niFruit\nTitanic\nRonin\nTitanic\nTitanic\nTitanic"}]},"apps":[],"jobName":"paragraph_1617197552248_-1783466876","id":"20200113-232724_1729214708","dateCreated":"2021-03-31T06:32:32-0700","dateStarted":"2021-03-31T08:54:59-0700","dateFinished":"2021-03-31T08:55:00-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248587"},{"text":"%md\nUse the Python foreach loop to print out all records from makes2RDD.\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Use the Python foreach loop to print out all records from makes2RDD.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552248_1625171622","id":"20210121-160940_1102442443","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248588"},{"title":"11 - Create a new RDD by appending the second RDD to the first using the union transformation","text":"%pyspark\n\nallMakesRDD = makes1RDD.union(makes2RDD)","user":"anonymous","dateUpdated":"2021-03-31T08:55:43-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1617197552248_1491554927","id":"20200113-233026_550163966","dateCreated":"2021-03-31T06:32:32-0700","dateStarted":"2021-03-31T08:55:43-0700","dateFinished":"2021-03-31T08:55:44-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248589"},{"text":"%md\n#### RDD functions\nUse the `union` function to append the first RDD to the second RDD. \n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>RDD functions</h4>\n<p>Use the <code>union</code> function to append the first RDD to the second RDD.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552248_1100348350","id":"20210121-161039_940350799","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248590"},{"title":"12 - Collect and display the contents of the new allMakesRDD RDD","text":"%pyspark\n\nsc.setJobGroup(\"Working with RDDs\",\"Display the contents of the allMakesRDD\")\nfor make in allMakesRDD.collect(): print(make)\n","user":"anonymous","dateUpdated":"2021-03-31T08:56:15-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Sorrento\nTitanic\nSorrento\nTitanic\nMeeToo\nMeeToo\nMeeToo\nTitanic\nMeeToo\nMeeToo\nTitanic\nSorrento\nSorrento\nTitanic\nMeeToo\nMeeToo\niFruit\niFruit\nTitanic\nMeeToo\niFruit\nTitanic\nRonin\nTitanic\nTitanic\nTitanic"}]},"apps":[],"jobName":"paragraph_1617197552249_-1399442246","id":"20200113-233223_65376122","dateCreated":"2021-03-31T06:32:32-0700","dateStarted":"2021-03-31T08:56:15-0700","dateFinished":"2021-03-31T08:56:17-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248591"},{"title":"13 - Use the distinct transformation to remove duplicates from allMakesRDD","text":"%pyspark\n\nsc.setJobGroup(\"Working with RDDs\",\"Display the unique makes\")\nfor make in allMakesRDD.distinct().collect(): print(make)","user":"anonymous","dateUpdated":"2021-03-31T08:56:51-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Sorrento\nMeeToo\nTitanic\nRonin\niFruit"}]},"apps":[],"jobName":"paragraph_1617197552249_1339083480","id":"20200113-233603_408861853","dateCreated":"2021-03-31T06:32:32-0700","dateStarted":"2021-03-31T08:56:51-0700","dateFinished":"2021-03-31T08:56:52-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248592"},{"text":"%md\nUse the distinct transformation to remove duplicates from allMakesRDD. Use the `distinct` function to remove duplicates. Use the `collect` function to \ncollect and display the contents. This will confirm that duplicate elements were removed.\n","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Use the distinct transformation to remove duplicates from allMakesRDD. Use the <code>distinct</code> function to remove duplicates. Use the <code>collect</code> function to\n<br  />collect and display the contents. This will confirm that duplicate elements were removed.</p>\n"}]},"apps":[],"jobName":"paragraph_1617197552249_-577791838","id":"20210121-160135_1732209921","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248593"},{"text":"%md\n# Tear Down\n---","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Tear Down</h1>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1617197552249_2000452091","id":"20200830-150902_66980237","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248594"},{"title":"Delete HDFS files to prevent files exist errors","text":"%sh\n\nhdfs dfs -rm -r -f -skipTrash /devsh_loudacre/frostroad.txt\nhdfs dfs -rm -r -f -skipTrash /devsh_loudacre/makes*.txt\n","user":"anonymous","dateUpdated":"2021-03-31T08:57:34-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Deleted /devsh_loudacre/frostroad.txt\nDeleted /devsh_loudacre/makes1.txt\nDeleted /devsh_loudacre/makes2.txt\n"}]},"apps":[],"jobName":"paragraph_1617197552249_340621555","id":"20210203-064845_1384167053","dateCreated":"2021-03-31T06:32:32-0700","dateStarted":"2021-03-31T08:57:34-0700","dateFinished":"2021-03-31T08:57:38-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248595"},{"title":"Delete the Livy session","text":"%sh\n\nsessionId=$(curl -s localhost:8998/sessions | jq '.sessions[0].id')\ncurl -s localhost:8998/sessions/$sessionId -X DELETE","user":"anonymous","dateUpdated":"2021-03-31T08:57:43-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"{\"msg\":\"deleted\"}"}]},"apps":[],"jobName":"paragraph_1617197552250_-252586855","id":"20200830-150921_2047498407","dateCreated":"2021-03-31T06:32:32-0700","dateStarted":"2021-03-31T08:57:43-0700","dateFinished":"2021-03-31T08:57:48-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248596"},{"title":"Additional resources","text":"%md\nWe hope you've enjoyed this lab. Below are additional resources that you should find useful:\n\n1. [Cloudera Tutorials](http://cloudera.com/tutorials.html) are your natural next step where you can explore Spark in more depth.\n2. [Cloudera Community](https://community.cloudera.com) is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.\n3. [Apache Spark Documentation](https://spark.apache.org/documentation.html) - official Spark documentation.\n4. [Apache Zeppelin Project Home Page](https://zeppelin.apache.org) - official Zeppelin web site.","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":10,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>We hope you've enjoyed this lab. Below are additional resources that you should find useful:</p>\n<ol>\n<li><a href=\"http://cloudera.com/tutorials.html\">Cloudera Tutorials</a> are your natural next step where you can explore Spark in more depth.</li>\n<li><a href=\"https://community.cloudera.com\">Cloudera Community</a> is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.</li>\n<li><a href=\"https://spark.apache.org/documentation.html\">Apache Spark Documentation</a> - official Spark documentation.</li>\n<li><a href=\"https://zeppelin.apache.org\">Apache Zeppelin Project Home Page</a> - official Zeppelin web site.</li>\n</ol>\n"}]},"apps":[],"jobName":"paragraph_1617197552250_-1385554085","id":"20181116-135131_93712280","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248597"},{"text":"%angular\n</br>\n</br>\n</br>\n</br>\n<center>\n<a href=\"https://www.cloudera.com/about/training/courses.html\">\n  <img src=\"https://www.cloudera.com/content/dam/www/marketing/media-kit/logo-assets/cloudera_logo_darkorange.png\" alt=\"Cloudera University\" style=\"width:280px;height:40px;border:0;\" align=\"middle\">\n</a>\n</center>\n</br>\n</br>","user":"anonymous","dateUpdated":"2021-03-31T06:32:32-0700","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":2,"editorMode":"ace/mode/undefined","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"ANGULAR","data":"</br>\n</br>\n</br>\n</br>\n<center>\n<a href=\"https://www.cloudera.com/about/training/courses.html\">\n  <img src=\"https://www.cloudera.com/content/dam/www/marketing/media-kit/logo-assets/cloudera_logo_darkorange.png\" alt=\"Cloudera University\" style=\"width:280px;height:40px;border:0;\" align=\"middle\">\n</a>\n</center>\n</br>\n</br>"}]},"apps":[],"jobName":"paragraph_1617197552250_2081079481","id":"20200110-154537_1406191376","dateCreated":"2021-03-31T06:32:32-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:248598"}],"name":"/DevSH/Pyspark/RDD","id":"2G33Q8B2C","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"angular:shared_process":[],"sh:shared_process":[],"livy:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}