{"paragraphs":[{"text":"%md\n# About\n**Lab:** Aggregating and Joining Streaming DataFrames\n**Objective:** Practice streaming to inlcude both full and windowed aggregation transformations.\n**File locations:**\n    Exercise directory: /home/training/training_materials/devsh/exercises/streaming-aggregation\n    Data (local): /home/training/training_materials/devsh/data/activations_stream\n    Test script: /home/training/training_materials/devsh/scripts/streamtest-kafka.sh    \n\n**Successful outcome:** \n**Before you begin:** \n**Related lessons:** \n\n---","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>About</h1>\n<p><strong>Lab:</strong> Aggregating and Joining Streaming DataFrames\n<br  /><strong>Objective:</strong> Practice streaming to inlcude both full and windowed aggregation transformations.\n<br  /><strong>File locations:</strong></p>\n<pre><code>Exercise directory: /home/training/training_materials/devsh/exercises/streaming-aggregation\nData (local): /home/training/training_materials/devsh/data/activations_stream\nTest script: /home/training/training_materials/devsh/scripts/streamtest-kafka.sh    \n</code></pre>\n<p><strong>Successful outcome:</strong>\n<br  /><strong>Before you begin:</strong>\n<br  /><strong>Related lessons:</strong></p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1617309777858_1274338601","id":"20181126-092644_1457476546","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:431704"},{"text":"%md\n# Setup","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Setup</h1>\n"}]},"apps":[],"jobName":"paragraph_1617309777860_562705459","id":"20181201-044336_178705192","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431705"},{"title":"Open two terminals","text":"%md\nTerminal 1 for Kafka\nTerminal 2 for Spark","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Terminal 1 for Kafka\n<br  />Terminal 2 for Spark</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777861_1984875055","id":"20210124-174856_1641692178","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431706"},{"text":"%md\n# Lab\n","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Lab</h1>\n"}]},"apps":[],"jobName":"paragraph_1617309777861_-2096537919","id":"20181126-093358_358613711","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431707"},{"text":"%md\n#### Find the Most Commonly Activated Devices Models\n\nIn this section, you will find the most common device models activated by counting model names and sorting by count. The count will be based on full aggregation \nof all the data received in the stream.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Find the Most Commonly Activated Devices Models</h4>\n<p>In this section, you will find the most common device models activated by counting model names and sorting by count. The count will be based on full aggregation\n<br  />of all the data received in the stream.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777862_-1782752086","id":"20200426-213726_1385705129","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431708"},{"title":"1 - Terminate any Spark shells","text":"%md\nIf you currently have a Spark shell running in a terminal session, exit it.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>If you currently have a Spark shell running in a terminal session, exit it.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777862_902667619","id":"20200426-213833_1554281507","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431709"},{"title":"2 - In terminal 2 start a new local Spark shell","text":"%md\nStart a new Python or Scala Spark shell running locally with two threads.\n\n```\npyspark --master local[2]\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Start a new Python or Scala Spark shell running locally with two threads.</p>\n<pre><code>pyspark --master local[2]\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777863_-578912881","id":"20200426-213832_1251923548","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431710"},{"title":"3 - Set the default number of partitions for shuffle operations","text":"%md\nSet the default number of partitions for shuffle operations, which includes aggregation operations.\n\n```\nspark.conf.set(\"spark.sql.shuffle.partitions\",\"4\")\n```\n\nThe default number of partitions is 200. This is reasonable in a typical production cluster containing many worker hosts. Your exercise environment includes \nonly a single host. If the number of partitions in a DataFrame greatly exceeds the number of worker hosts, you will get very poor performance. For these \nexercises, you must lower the number of partitions to allow your aggregation operations to complete in a reasonable amount of time.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Set the default number of partitions for shuffle operations, which includes aggregation operations.</p>\n<pre><code>spark.conf.set(\"spark.sql.shuffle.partitions\",\"4\")\n</code></pre>\n<p>The default number of partitions is 200. This is reasonable in a typical production cluster containing many worker hosts. Your exercise environment includes\n<br  />only a single host. If the number of partitions in a DataFrame greatly exceeds the number of worker hosts, you will get very poor performance. For these\n<br  />exercises, you must lower the number of partitions to allow your aggregation operations to complete in a reasonable amount of time.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777863_256639414","id":"20200426-213832_1922966997","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431711"},{"title":"4 - Create a streaming DataFrame","text":"%md\nCreate a streaming DataFrame called `kafkaDF` to receive messages in the `activations` topic.\n\n```\nkafkaDF = spark.readStream.format(\"kafka\"). \\\noption(\"kafka.bootstrap.servers\", \"localhost:9092\"). \\\noption(\"subscribe\", \"activations\").load()\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Create a streaming DataFrame called <code>kafkaDF</code> to receive messages in the <code>activations</code> topic.</p>\n<pre><code>kafkaDF = spark.readStream.format(\"kafka\"). \\\noption(\"kafka.bootstrap.servers\", \"localhost:9092\"). \\\noption(\"subscribe\", \"activations\").load()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777863_-1891909560","id":"20200426-213830_1680734993","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431712"},{"title":"5 - Create a new DataFrame based on kafkaDF","text":"%md\nCreate a new DataFrame based on kafkaDF with an activation column containing the activation message values, parsed from JSON format.\n\n```\nfrom pyspark.sql.types import *\n\nactivationsSchema = StructType([\n    StructField(\"acct_num\", IntegerType()),\n    StructField(\"dev_id\", StringType()),\n    StructField(\"phone\", StringType()),\n    StructField(\"model\", StringType())])\n\nfrom pyspark.sql.functions import *\n\nactivationsDF = kafkaDF. \\\nselect(from_json(kafkaDF.value.cast(\"string\"),\nactivationsSchema).alias(\"activation\"))\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Create a new DataFrame based on kafkaDF with an activation column containing the activation message values, parsed from JSON format.</p>\n<pre><code>from pyspark.sql.types import *\n\nactivationsSchema = StructType([\n    StructField(\"acct_num\", IntegerType()),\n    StructField(\"dev_id\", StringType()),\n    StructField(\"phone\", StringType()),\n    StructField(\"model\", StringType())])\n\nfrom pyspark.sql.functions import *\n\nactivationsDF = kafkaDF. \\\nselect(from_json(kafkaDF.value.cast(\"string\"),\nactivationsSchema).alias(\"activation\"))\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777864_1519186073","id":"20200426-213815_593478837","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431713"},{"title":"6 - Create a streaming DataFrame","text":"%md\nCreate a streaming DataFrame that counts the rows in `activationsDF` by model name and sorts the results in descending order.\n\n```\nsortedModelCountDF = activationsDF. \\\ngroupBy(activationsDF.activation.model).count(). \\\nsort(\"count\",ascending=False)\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Create a streaming DataFrame that counts the rows in <code>activationsDF</code> by model name and sorts the results in descending order.</p>\n<pre><code>sortedModelCountDF = activationsDF. \\\ngroupBy(activationsDF.activation.model).count(). \\\nsort(\"count\",ascending=False)\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777864_-1447345475","id":"20200426-213806_799679800","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431714"},{"title":"7 - Start a query based on the sortedModelCountDF DataFrame","text":"%md\nThe query should\n- Display the complete results to the console\n- Disable truncation of the rows\n- Set a trigger interval of five seconds\n    - This is not required by the query, but will aggregate larger batches of data so that you will be able to analyze the results more easily.\n\n```\nsortedModelCountQuery = sortedModelCountDF. \\\nwriteStream.outputMode(\"complete\"). \\\nformat(\"console\").option(\"truncate\",\"false\"). \\\ntrigger(processingTime=\"5 seconds\").start()\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>The query should</p>\n<ul>\n<li>Display the complete results to the console</li>\n<li>Disable truncation of the rows</li>\n<li>Set a trigger interval of five seconds<ul>\n<li>This is not required by the query, but will aggregate larger batches of data so that you will be able to analyze the results more easily.</li>\n</ul>\n</li>\n</ul>\n<pre><code>sortedModelCountQuery = sortedModelCountDF. \\\nwriteStream.outputMode(\"complete\"). \\\nformat(\"console\").option(\"truncate\",\"false\"). \\\ntrigger(processingTime=\"5 seconds\").start()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777865_-446995003","id":"20200426-213804_1784840007","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431715"},{"title":"8 - In terminal 1 list the Kafka topics","text":"%md\n~~~\nkafka-topics.sh --list --bootstrap-server localhost:9092\n~~~","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<pre><code>kafka-topics.sh --list --bootstrap-server localhost:9092\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777865_-1026253063","id":"20200426-213803_1348196026","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431716"},{"title":"9 - Create the activations topic for the streaming messages","text":"%md\n(If you created it previously, you will get an exception saying the topic already exists. This is not aproblem and you can proceed with the exercises.)\n\n```xml\nkafka-topics --create --bootstrap-server localhost:9092 --partitions 2 --replication-factor 1 --topic activations\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>(If you created it previously, you will get an exception saying the topic already exists. This is not aproblem and you can proceed with the exercises.)</p>\n<pre><code class=\"xml\">kafka-topics --create --bootstrap-server localhost:9092 --partitions 2 --replication-factor 1 --topic activations\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777866_360774988","id":"20200426-213803_553810788","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431717"},{"title":"10 - Test the query","text":"%md\nGenerate Kafka messages to test the query using the provided test script.\n```\n/home/training/training_materials/devsh/scripts/streamtest-kafka.sh activations localhost:9092 10 /home/training/training_materials/devsh/data/activations_stream\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Generate Kafka messages to test the query using the provided test script.</p>\n<pre><code>/home/training/training_materials/devsh/scripts/streamtest-kafka.sh activations localhost:9092 10 /home/training/training_materials/devsh/data/activations_stream\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777867_-473247273","id":"20200426-213802_883829322","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431718"},{"title":"11 - Stopping the test script","text":"%md\nLet the script run for about 20 seconds, then stop it using:\n~~~xml\nCtrl+C\n~~~","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Let the script run for about 20 seconds, then stop it using:</p>\n<pre><code class=\"xml\">Ctrl+C\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777867_364898665","id":"20200426-213802_1039300162","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431719"},{"title":"12 - Observe the results","text":"%md\nReturn to the Spark shell and observe the results displayed on the console. Note that the model counts continue to increase between batches. They will \nincrease indefinitely because the query runs against all the data received in the stream.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Return to the Spark shell and observe the results displayed on the console. Note that the model counts continue to increase between batches. They will\n<br  />increase indefinitely because the query runs against all the data received in the stream.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777868_791843644","id":"20200426-213801_1474504317","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431720"},{"title":"13 - Stop the query","text":"%md\n```\nsortedModelCountQuery.stop()\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<pre><code>sortedModelCountQuery.stop()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777868_-1355763091","id":"20200426-213801_1490570835","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431721"},{"text":"%md\n#### Count Activated Models within a Sliding Window\n\nIn this section, you will count the number of activation events per model every five seconds. Each batch of results will contain the counts for events received \nduring the prior 10 seconds.\n\nNote that aggregating results over a 10 second window would not be a common production use case. In the exercise, you will use this small window duration so \nthat you can analyze the results more easily.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Count Activated Models within a Sliding Window</h4>\n<p>In this section, you will count the number of activation events per model every five seconds. Each batch of results will contain the counts for events received\n<br  />during the prior 10 seconds.</p>\n<p>Note that aggregating results over a 10 second window would not be a common production use case. In the exercise, you will use this small window duration so\n<br  />that you can analyze the results more easily.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777868_1232584307","id":"20200426-213759_1853192695","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431722"},{"title":"14 - Create a DataFrame","text":"%md\nCreate a DataFrame called activationsTimeDF. This DataFrame will be identical to the activationsDF you created above, except that it will contain a timestamp \ncolumn with the time the activation event occurred. An event time value is required to do aggregations within a window.\n\n```\nactivationsTimeDF = kafkaDF. \\\nselect(\"timestamp\",from_json(kafkaDF.value.cast(\"string\"),\nactivationsSchema).alias(\"activation\"))\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Create a DataFrame called activationsTimeDF. This DataFrame will be identical to the activationsDF you created above, except that it will contain a timestamp\n<br  />column with the time the activation event occurred. An event time value is required to do aggregations within a window.</p>\n<pre><code>activationsTimeDF = kafkaDF. \\\nselect(\"timestamp\",from_json(kafkaDF.value.cast(\"string\"),\nactivationsSchema).alias(\"activation\"))\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777869_926417960","id":"20200426-213759_2132726473","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431723"},{"title":"15 - Count activation events","text":"%md\nDefine a new DataFrame that counts activation events that occurred in the 10 seconds prior, updated every five seconds. In order to be able to analyze the \nquery more easily, limit the query to models MeeToo 3.0 and 3.1.\n\n```\nwindowModelCountDF = activationsTimeDF. \\\nwhere(activationsTimeDF.activation.model.\nstartswith(\"MeeToo 3\")). \\\ngroupBy(window(\"timestamp\", \"10 seconds\", \"5 seconds\"),\n\"activation.model\"). \\\ncount()\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Define a new DataFrame that counts activation events that occurred in the 10 seconds prior, updated every five seconds. In order to be able to analyze the\n<br  />query more easily, limit the query to models MeeToo 3.0 and 3.1.</p>\n<pre><code>windowModelCountDF = activationsTimeDF. \\\nwhere(activationsTimeDF.activation.model.\nstartswith(\"MeeToo 3\")). \\\ngroupBy(window(\"timestamp\", \"10 seconds\", \"5 seconds\"),\n\"activation.model\"). \\\ncount()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777869_1133466635","id":"20200426-213758_1015727381","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431724"},{"title":"16 - Start a query based on the windowModelCountDF DataFrame","text":"%md\nThe query should\n\n- Display the complete results to the console\n- Disable truncation of the rows\n- Set a trigger interval of five seconds\n\n```\nwindowModelCountQuery = windowModelCountDF. \\\nwriteStream.outputMode(\"complete\"). \\\nformat(\"console\").option(\"truncate\",\"false\"). \\\ntrigger(processingTime=\"5 seconds\").start()\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>The query should</p>\n<ul>\n<li>Display the complete results to the console</li>\n<li>Disable truncation of the rows</li>\n<li>Set a trigger interval of five seconds</li>\n</ul>\n<pre><code>windowModelCountQuery = windowModelCountDF. \\\nwriteStream.outputMode(\"complete\"). \\\nformat(\"console\").option(\"truncate\",\"false\"). \\\ntrigger(processingTime=\"5 seconds\").start()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777870_-950864255","id":"20200426-213757_1299348615","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431725"},{"title":"17 - Test the query","text":"%md\nIn a separate terminal window, generate test events using the provided test script.\n\n```\n/home/training/training_materia/devsh/scripts/streamtest-kafka.sh activations localhost:9092 10 /home/training_material/devsh/data/telco/activations_stream\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>In a separate terminal window, generate test events using the provided test script.</p>\n<pre><code>/home/training/training_materia/devsh/scripts/streamtest-kafka.sh activations localhost:9092 10 /home/training_material/devsh/data/telco/activations_stream\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777870_-1437409661","id":"20200426-213756_727522879","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431726"},{"title":"18 - Stopping the test script","text":"%md\nLet the script run for at least 20 seconds, then stop it using `Ctrl+C`.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Let the script run for at least 20 seconds, then stop it using <code>Ctrl+C</code>.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777871_179195569","id":"20200426-213755_729951167","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431727"},{"title":"19 - Observe the results","text":"%md\nReturn to the Spark shell and observe the results displayed on the console.\n\nIn particular, take note of the time period values in the `window` column. The value is a pair consisting of a start time and an end time.\n\n- Each period spans a 10-second time period, reflecting the window duration you specified above; for example, a period \n  with start time `2019-06-05 08:12:40` and end time `2019-06-05 08:12:50`.\n- New windows are generated every five seconds. For example, a period with start time `2019-06-05 08:12:40` will be \n  followed by a period starting `2019-06-05 08:12:45` -- five seconds later.\n- Each row in the results shows the number of times a particular device model occurred within a window. That means there \n  will be up to two rows for any one window -- one with the MeeToo 3.0 count and the other with the MeeToo 3.1 count.\n- The events included in consecutive windows overlap. That is, an event that occurred at `2019-06-05 08:12:48` is included \n  in two 10-second windows: the `2019-06-05 08:12:40` and `2019-06-05 08:12:45` windows.\n- Note that the results are unordered; results for consecutive windows may not be displayed consecutively in the output.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Return to the Spark shell and observe the results displayed on the console.</p>\n<p>In particular, take note of the time period values in the <code>window</code> column. The value is a pair consisting of a start time and an end time.</p>\n<ul>\n<li>Each period spans a 10-second time period, reflecting the window duration you specified above; for example, a period\n<br  />with start time <code>2019-06-05 08:12:40</code> and end time <code>2019-06-05 08:12:50</code>.</li>\n<li>New windows are generated every five seconds. For example, a period with start time <code>2019-06-05 08:12:40</code> will be\n<br  />followed by a period starting <code>2019-06-05 08:12:45</code> &ndash; five seconds later.</li>\n<li>Each row in the results shows the number of times a particular device model occurred within a window. That means there\n<br  />will be up to two rows for any one window &ndash; one with the MeeToo 3.0 count and the other with the MeeToo 3.1 count.</li>\n<li>The events included in consecutive windows overlap. That is, an event that occurred at <code>2019-06-05 08:12:48</code> is included\n<br  />in two 10-second windows: the <code>2019-06-05 08:12:40</code> and <code>2019-06-05 08:12:45</code> windows.</li>\n<li>Note that the results are unordered; results for consecutive windows may not be displayed consecutively in the output.</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1617309777871_389957963","id":"20200426-213755_1149864474","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431728"},{"title":"20 - Stop the query","text":"%md\n```\nwindowModelCountQuery.stop()\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<pre><code>windowModelCountQuery.stop()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777872_1689915749","id":"20200426-213755_784337107","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431729"},{"title":"21 - Run the query using the update output mode","text":"%md\nRerun the query above, except use the `update` output mode.\n\n```\nwindowModelCountQuery2 = windowModelCountDF. \\\nwriteStream.outputMode(\"update\"). \\\nformat(\"console\").option(\"truncate\",\"false\").\ntrigger(processingTime=\"15 seconds\").start()\n```\n\nNote that the trigger interval is longer than in the last query. This means that each batch will be based on more data, making the results easier to analyze.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Rerun the query above, except use the <code>update</code> output mode.</p>\n<pre><code>windowModelCountQuery2 = windowModelCountDF. \\\nwriteStream.outputMode(\"update\"). \\\nformat(\"console\").option(\"truncate\",\"false\").\ntrigger(processingTime=\"15 seconds\").start()\n</code></pre>\n<p>Note that the trigger interval is longer than in the last query. This means that each batch will be based on more data, making the results easier to analyze.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777872_1219572843","id":"20200426-213753_1787869932","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431730"},{"title":"22 - Test the query","text":"%md\nGenerate test events as you did above. Let the script run for at least a minute.\n\n```\n/home/training/training_material/devsh/scripts/streamtest-kafka.sh activations localhost:9092 10 /home/training/training_material/devsh/data/activations_stream\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Generate test events as you did above. Let the script run for at least a minute.</p>\n<pre><code>/home/training/training_material/devsh/scripts/streamtest-kafka.sh activations localhost:9092 10 /home/training/training_material/devsh/data/activations_stream\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777873_112566399","id":"20200426-213752_1401656742","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431731"},{"title":"23 - Review the output","text":"%md\nReview the `update` mode output.\n\nThis time only windows with counts that changed between the previous batch and the current one are displayed. That is, if no MeeToo 3.0 devices were activated \nbetween `2019-06-05 08:12:40` and `2019-06-05 08:12:50`, then the row containing the MeeToo 3.0 count for that window will not be shown.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Review the <code>update</code> mode output.</p>\n<p>This time only windows with counts that changed between the previous batch and the current one are displayed. That is, if no MeeToo 3.0 devices were activated\n<br  />between <code>2019-06-05 08:12:40</code> and <code>2019-06-05 08:12:50</code>, then the row containing the MeeToo 3.0 count for that window will not be shown.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777873_-605530390","id":"20200426-213751_400998628","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431732"},{"title":"24 - Stopping the query","text":"%md\nStop the windowModelCountQuery2 query.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Stop the windowModelCountQuery2 query.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777874_-135198530","id":"20200426-213751_2130137713","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431733"},{"text":"%md\n#### Join Streaming Activation and Static Account Data\n\nIn this section, you will join static account data in the `devsh.accounts` Hive table with streaming activation data based on the account ID. Only active \naccounts (those for which the `acct_close_dt` is null) will be included in the results. You will practice using both an inner and an outer join.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Join Streaming Activation and Static Account Data</h4>\n<p>In this section, you will join static account data in the <code>devsh.accounts</code> Hive table with streaming activation data based on the account ID. Only active\n<br  />accounts (those for which the <code>acct_close_dt</code> is null) will be included in the results. You will practice using both an inner and an outer join.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777874_-338659814","id":"20200428-190617_1622516387","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431734"},{"title":"25 - Define a static DataFrame","text":"%md\nDefine a static DataFrame containing rows where `acct_close_dt` is null.\n\n```\naccountsStaticDF = spark.read.table(\"telco.accounts\")\n\nactiveAccountsStaticDF = accountsStaticDF.where(accountsStaticDF.acct_close_dt.isNull())\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Define a static DataFrame containing rows where <code>acct_close_dt</code> is null.</p>\n<pre><code>accountsStaticDF = spark.read.table(\"telco.accounts\")\n\nactiveAccountsStaticDF = accountsStaticDF.where(accountsStaticDF.acct_close_dt.isNull())\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777875_-276438722","id":"20200426-213749_1082815533","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431735"},{"title":"26 - Join the DataFrames","text":"%md\nJoin the static active accounts DataFrame with the `activationsDF` you created in the previous section. Include the account number, first name, last name, \naccount close date, and device ID in the new DataFrame.\n\n```\njoinedDF = activeAccountsStaticDF. \\\njoin(activationsDF, activationsDF.activation.acct_num == accountsStaticDF.acct_num). \\\nselect(\"acct_num\",\"first_name\",\"last_name\",\"acct_num\",\"acct_close_dt\",\"activation.dev_id\")\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Join the static active accounts DataFrame with the <code>activationsDF</code> you created in the previous section. Include the account number, first name, last name,\n<br  />account close date, and device ID in the new DataFrame.</p>\n<pre><code>joinedDF = activeAccountsStaticDF. \\\njoin(activationsDF, activationsDF.activation.acct_num == accountsStaticDF.acct_num). \\\nselect(\"acct_num\",\"first_name\",\"last_name\",\"acct_num\",\"acct_close_dt\",\"activation.dev_id\")\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777875_1861606421","id":"20200426-213748_357446253","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431736"},{"title":"27 - Display account data","text":"%md\nStart a query to display account data to the console. Use append output mode and set a one second trigger.\n\n```\njoinedQuery = joinedDF. \\\nwriteStream.outputMode(\"append\"). \\\nformat(\"console\").option(\"truncate\",\"false\"). \\\ntrigger(processingTime=\"1 seconds\").start()\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Start a query to display account data to the console. Use append output mode and set a one second trigger.</p>\n<pre><code>joinedQuery = joinedDF. \\\nwriteStream.outputMode(\"append\"). \\\nformat(\"console\").option(\"truncate\",\"false\"). \\\ntrigger(processingTime=\"1 seconds\").start()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777876_-1280227659","id":"20200426-222959_1833111122","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431737"},{"title":"28 - Test the query","text":"%md\nGenerate test events as you did in the last section. Let the script run for a few seconds.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Generate test events as you did in the last section. Let the script run for a few seconds.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777877_-1929062498","id":"20200426-222958_1488462629","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431738"},{"title":"29 - Review the output","text":"%md\nReview the console output in the Spark shell. Note that the joined DataFrame contains only activation data associated with active accounts. Inactive \naccounts were excluded from the accounts data, and you performed an inner join (the default), so activation records for accounts not in the accounts \nDataFrame were ignored.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Review the console output in the Spark shell. Note that the joined DataFrame contains only activation data associated with active accounts. Inactive\n<br  />accounts were excluded from the accounts data, and you performed an inner join (the default), so activation records for accounts not in the accounts\n<br  />DataFrame were ignored.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777877_-500964243","id":"20200426-222957_1006781391","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431739"},{"title":"30 - Stop the query","text":"","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617309777878_1339592152","id":"20200426-222957_336923731","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431740"},{"title":"31 - Perform a right outer join","text":"%md\nRepeat the steps above, but this time perform a right outer join.\n\n```\njoinedRightDF = activeAccountsStaticDF. \\\njoin(activationsDF, activationsDF.activation.acct_num ==\naccountsStaticDF.acct_num,\"right_outer\"). \\\nselect(\"acct_num\",\"first_name\",\"last_name\",\n\"acct_close_dt\",\"activation.dev_id\")\n\njoinedRightQuery = joinedRightDF.writeStream. \\\noutputMode(\"append\").format(\"console\"). \\\noption(\"truncate\",\"false\"). \\\ntrigger(processingTime=\"1 seconds\").start()\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Repeat the steps above, but this time perform a right outer join.</p>\n<pre><code>joinedRightDF = activeAccountsStaticDF. \\\njoin(activationsDF, activationsDF.activation.acct_num ==\naccountsStaticDF.acct_num,\"right_outer\"). \\\nselect(\"acct_num\",\"first_name\",\"last_name\",\n\"acct_close_dt\",\"activation.dev_id\")\n\njoinedRightQuery = joinedRightDF.writeStream. \\\noutputMode(\"append\").format(\"console\"). \\\noption(\"truncate\",\"false\"). \\\ntrigger(processingTime=\"1 seconds\").start()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777878_1210225208","id":"20200426-235904_525060356","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431741"},{"title":"32 - Test the query and compare the results","text":"%md\nTest the query using the message generation script again and compare the results to the previous query. Note that this time, the output includes rows in which \nthe account data (such as account number) is null. That is because the outer join includes all data from the streaming DataFrame, even when it does not have \na matching row in the static DataFrame.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Test the query using the message generation script again and compare the results to the previous query. Note that this time, the output includes rows in which\n<br  />the account data (such as account number) is null. That is because the outer join includes all data from the streaming DataFrame, even when it does not have\n<br  />a matching row in the static DataFrame.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777879_-1387766859","id":"20200426-235902_243047401","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431742"},{"title":"33 - Stop the query","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617309777879_-947109019","id":"20200427-000105_1731816017","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431743"},{"text":"%md\n# Result\n**You have now:** \n\n---","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Result</h1>\n<p><strong>You have now:</strong></p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1617309777880_-1313401527","id":"20181126-133507_1472573213","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431744"},{"text":"%md\n# Solution\n---","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Solution</h1>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1617309777880_-1953888808","id":"20181018-125200_1133281582","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431745"},{"text":"%md\n#### Find the Most Commonly Activated Devices Models\n\nIn this section, you will find the most common device models activated by counting model names and sorting by count. The count will be based on full \naggregation of all the data received in the stream.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Find the Most Commonly Activated Devices Models</h4>\n<p>In this section, you will find the most common device models activated by counting model names and sorting by count. The count will be based on full\n<br  />aggregation of all the data received in the stream.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777881_-878425210","id":"20210122-153638_1368987437","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431746"},{"title":"1 - Terminate any Spark shells","text":"%md\nIf you currently have a Spark shell running in a terminal session, exit it.\n\n~~~pyspark\nquit()\n~~~","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>If you currently have a Spark shell running in a terminal session, exit it.</p>\n<pre><code class=\"pyspark\">quit()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777881_585873558","id":"20200427-010510_1061909187","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431747"},{"title":"2 - In terminal 2 start a new local Spark shell","text":"%md\nStart a new Python or Scala Spark shell running locally with two threads.\n\n```\npyspark --master local[2]\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Start a new Python or Scala Spark shell running locally with two threads.</p>\n<pre><code>pyspark --master local[2]\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777882_-566892203","id":"20210122-153758_1559744086","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431748"},{"title":"3 - Set the default number of partitions for shuffle operations","text":"%md\nSet the default number of partitions for shuffle operations, which includes aggregation operations.\n\n```\nspark.conf.set(\"spark.sql.shuffle.partitions\",\"4\")\n```\n\nThe default number of partitions is 200. This is reasonable in a typical production cluster containing many worker hosts. Your exercise environment includes \nonly a single host. If the number of partitions in a DataFrame greatly exceeds the number of worker hosts, you will get very poor performance. For these \nexercises, you must lower the number of partitions to allow your aggregation operations to complete in a reasonable amount of time.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Set the default number of partitions for shuffle operations, which includes aggregation operations.</p>\n<pre><code>spark.conf.set(\"spark.sql.shuffle.partitions\",\"4\")\n</code></pre>\n<p>The default number of partitions is 200. This is reasonable in a typical production cluster containing many worker hosts. Your exercise environment includes\n<br  />only a single host. If the number of partitions in a DataFrame greatly exceeds the number of worker hosts, you will get very poor performance. For these\n<br  />exercises, you must lower the number of partitions to allow your aggregation operations to complete in a reasonable amount of time.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777882_-504035561","id":"20200429-233749_462865264","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431749"},{"title":"4 - Create a streaming DataFrame","text":"%md\nCreate a streaming DataFrame called `kafkaDF` to receive messages in the `activations` topic.\n\n```\nkafkaDF = spark.readStream.format(\"kafka\"). \\\noption(\"kafka.bootstrap.servers\", \"localhost:9092\"). \\\noption(\"subscribe\", \"activations\").load()\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Create a streaming DataFrame called <code>kafkaDF</code> to receive messages in the <code>activations</code> topic.</p>\n<pre><code>kafkaDF = spark.readStream.format(\"kafka\"). \\\noption(\"kafka.bootstrap.servers\", \"localhost:9092\"). \\\noption(\"subscribe\", \"activations\").load()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777883_-553992145","id":"20210122-153938_1405813654","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431750"},{"title":"5 - Create a new DataFrame based on kafkaDF","text":"%md\nCreate a new DataFrame based on kafkaDF with an activation column containing the activation message values, parsed from JSON format.\n\n```\nfrom pyspark.sql.types import *\n\nactivationsSchema = StructType([\n  StructField(\"acct_num\", IntegerType()),\n  StructField(\"dev_id\", StringType()),\n  StructField(\"phone\", StringType()),\n  StructField(\"model\", StringType())])\n\nfrom pyspark.sql.functions import *\n\n# full aggregation\nactivationsDF = kafkaDF.select(from_json(kafkaDF.value.cast(\"string\"), activationsSchema).alias(\"activation\"))\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Create a new DataFrame based on kafkaDF with an activation column containing the activation message values, parsed from JSON format.</p>\n<pre><code>from pyspark.sql.types import *\n\nactivationsSchema = StructType([\n  StructField(\"acct_num\", IntegerType()),\n  StructField(\"dev_id\", StringType()),\n  StructField(\"phone\", StringType()),\n  StructField(\"model\", StringType())])\n\nfrom pyspark.sql.functions import *\n\n# full aggregation\nactivationsDF = kafkaDF.select(from_json(kafkaDF.value.cast(\"string\"), activationsSchema).alias(\"activation\"))\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777887_-635896742","id":"20200429-233746_29770565","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431751"},{"title":"6 - Create a streaming DataFrame","text":"%md\nCreate a streaming DataFrame that counts the rows in `activationsDF` by model name and sorts the results in descending order.\n\n```\nsortedModelCountDF = activationsDF. \\\ngroupBy(activationsDF.activation.model).count(). \\\nsort(\"count\",ascending=False)\n```\n","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Create a streaming DataFrame that counts the rows in <code>activationsDF</code> by model name and sorts the results in descending order.</p>\n<pre><code>sortedModelCountDF = activationsDF. \\\ngroupBy(activationsDF.activation.model).count(). \\\nsort(\"count\",ascending=False)\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777887_574997570","id":"20210122-154118_1940037440","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431752"},{"title":"7 - Start a query based on the sortedModelCountDF DataFrame","text":"%md\nThe query should\n- Display the complete results to the console\n- Disable truncation of the rows\n- Set a trigger interval of five seconds\n    - This is not required by the query, but will aggregate larger batches of data so that you will be able to analyze the results more easily.\n\n```\nsortedModelCountQuery = sortedModelCountDF. \\\nwriteStream.outputMode(\"complete\"). \\\nformat(\"console\").option(\"truncate\",\"false\"). \\\ntrigger(processingTime=\"5 seconds\").start()\n```\n","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>The query should</p>\n<ul>\n<li>Display the complete results to the console</li>\n<li>Disable truncation of the rows</li>\n<li>Set a trigger interval of five seconds<ul>\n<li>This is not required by the query, but will aggregate larger batches of data so that you will be able to analyze the results more easily.</li>\n</ul>\n</li>\n</ul>\n<pre><code>sortedModelCountQuery = sortedModelCountDF. \\\nwriteStream.outputMode(\"complete\"). \\\nformat(\"console\").option(\"truncate\",\"false\"). \\\ntrigger(processingTime=\"5 seconds\").start()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777888_1801541959","id":"20210122-155125_225784613","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431753"},{"title":"8 - In terminal 1 list the Kafka topics","text":"%md\n~~~xml\nkafka-topics --list --bootstrap-server localhost:9092\n~~~","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<pre><code class=\"xml\">kafka-topics --list --bootstrap-server localhost:9092\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777888_-94421994","id":"20200429-233739_428786167","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431754"},{"title":"9 - In terminal 1 create the activations topic for the streaming session","text":"%md\n(If you created it previously, you will get an exception saying the topic already exists. This is not a problem and you can proceed with the exercises.)\n\n```xml\nkafka-topics --create \\\n--bootstrap-server localhost:9092 \\\n--partitions 2 \\\n--replication-factor 1 \\\n--topic activations\n```\n","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>(If you created it previously, you will get an exception saying the topic already exists. This is not a problem and you can proceed with the exercises.)</p>\n<pre><code class=\"xml\">kafka-topics --create \\\n--bootstrap-server localhost:9092 \\\n--partitions 2 \\\n--replication-factor 1 \\\n--topic activations\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777889_1843730234","id":"20210122-155222_597890807","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431755"},{"title":"10 - Test the query","text":"%md\nGenerate Kafka messages to test the query using the provided test script.\n```\n/home/training/training_materials/devsh/scripts/streamtest-kafka.sh activations localhost:9092 10 /home/training/training_materials/devsh/data/activations_stream\n```\n","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Generate Kafka messages to test the query using the provided test script.</p>\n<pre><code>/home/training/training_materials/devsh/scripts/streamtest-kafka.sh activations localhost:9092 10 /home/training/training_materials/devsh/data/activations_stream\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777889_1999168944","id":"20210122-155352_264624039","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431756"},{"title":"11 - Stopping the test script","text":"%md\nLet the script run for about 20 seconds, then stop it using `Ctrl+C`.\n```\nCtrl+C\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Let the script run for about 20 seconds, then stop it using <code>Ctrl+C</code>.</p>\n<pre><code>Ctrl+C\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777890_1788249803","id":"20200429-233738_246730740","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431757"},{"title":"12 - Observe the results","text":"%md\nReturn to the Spark shell and observe the results displayed on the console. Note that the model counts continue to increase between batches. They will \nincrease indefinitely because the query runs against all the data received in the stream.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Return to the Spark shell and observe the results displayed on the console. Note that the model counts continue to increase between batches. They will\n<br  />increase indefinitely because the query runs against all the data received in the stream.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777890_-507475767","id":"20210122-155534_1084544440","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431758"},{"title":"13 - Stop the query","text":"%md\n```\nsortedModelCountQuery.stop()\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<pre><code>sortedModelCountQuery.stop()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777891_295868859","id":"20200429-233738_1286834654","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431759"},{"text":"%md\n#### Count Activated Models within a Sliding Window\n\nIn this section, you will count the number of activation events per model every five seconds. Each batch of results will contain the counts for events received \nduring the prior 10 seconds.\n\nNote that aggregating results over a 10 second window would not be a common production use case. In the exercise, you will use this small window duration \nso that you can analyze the results more easily.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Count Activated Models within a Sliding Window</h4>\n<p>In this section, you will count the number of activation events per model every five seconds. Each batch of results will contain the counts for events received\n<br  />during the prior 10 seconds.</p>\n<p>Note that aggregating results over a 10 second window would not be a common production use case. In the exercise, you will use this small window duration\n<br  />so that you can analyze the results more easily.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777891_2119049609","id":"20200429-233735_232008717","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431760"},{"title":"14 - Create a DataFrame","text":"%md\nCreate a DataFrame called activationsTimeDF. This DataFrame will be identical to the activationsDF you created above, except that it will contain a timestamp \ncolumn with the time the activation event occurred. An event time value is required to do aggregations within a window.\n\n```\nactivationsTimeDF = kafkaDF. \\\nselect(\"timestamp\",from_json(kafkaDF.value.cast(\"string\"),\nactivationsSchema).alias(\"activation\"))\n```\n","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Create a DataFrame called activationsTimeDF. This DataFrame will be identical to the activationsDF you created above, except that it will contain a timestamp\n<br  />column with the time the activation event occurred. An event time value is required to do aggregations within a window.</p>\n<pre><code>activationsTimeDF = kafkaDF. \\\nselect(\"timestamp\",from_json(kafkaDF.value.cast(\"string\"),\nactivationsSchema).alias(\"activation\"))\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777891_1908450559","id":"20210122-155709_1943918024","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431761"},{"title":"15 - Count activation events","text":"%md\nDefine a new DataFrame that counts activation events that occurred in the 10 seconds prior, updated every five seconds. In order to be able to analyze the \nquery more easily, limit the query to models MeeToo 3.0 and 3.1.\n\n```\nwindowModelCountDF = activationsTimeDF. \\\nwhere(activationsTimeDF.activation.model.\nstartswith(\"MeeToo 3\")). \\\ngroupBy(window(\"timestamp\", \"10 seconds\", \"5 seconds\"),\n\"activation.model\"). \\\ncount()\n```\n","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Define a new DataFrame that counts activation events that occurred in the 10 seconds prior, updated every five seconds. In order to be able to analyze the\n<br  />query more easily, limit the query to models MeeToo 3.0 and 3.1.</p>\n<pre><code>windowModelCountDF = activationsTimeDF. \\\nwhere(activationsTimeDF.activation.model.\nstartswith(\"MeeToo 3\")). \\\ngroupBy(window(\"timestamp\", \"10 seconds\", \"5 seconds\"),\n\"activation.model\"). \\\ncount()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777892_-659582348","id":"20210122-155755_1167414743","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431762"},{"title":"16 - Start a query based on the windowModelCountDF DataFrame","text":"%md\nThe query should\n\n- Display the complete results to the console\n- Disable truncation of the rows\n- Set a trigger interval of five seconds\n\n```\nwindowModelCountQuery = windowModelCountDF. \\\nwriteStream.outputMode(\"complete\"). \\\nformat(\"console\").option(\"truncate\",\"false\"). \\\ntrigger(processingTime=\"5 seconds\").start()\n```\n","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>The query should</p>\n<ul>\n<li>Display the complete results to the console</li>\n<li>Disable truncation of the rows</li>\n<li>Set a trigger interval of five seconds</li>\n</ul>\n<pre><code>windowModelCountQuery = windowModelCountDF. \\\nwriteStream.outputMode(\"complete\"). \\\nformat(\"console\").option(\"truncate\",\"false\"). \\\ntrigger(processingTime=\"5 seconds\").start()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777892_-1264450812","id":"20210122-155834_289756914","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431763"},{"title":"17 - Test the query","text":"%md\nIn a separate terminal window, generate test events using the provided test script.\n\n```\n/home/training/training_materia/devsh/scripts/streamtest-kafka.sh activations localhost:9092 10 /home/training_material/devsh/data/telco/activations_stream\n```\n","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>In a separate terminal window, generate test events using the provided test script.</p>\n<pre><code>/home/training/training_materia/devsh/scripts/streamtest-kafka.sh activations localhost:9092 10 /home/training_material/devsh/data/telco/activations_stream\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777893_-1960379859","id":"20210122-155957_655818382","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431764"},{"title":"18 - Stopping the test script","text":"%md\nLet the script run for at least 20 seconds, then stop it using `Ctrl+C`.\n\n```\nCtrl+C\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Let the script run for at least 20 seconds, then stop it using <code>Ctrl+C</code>.</p>\n<pre><code>Ctrl+C\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777893_-1220460993","id":"20200429-233731_1252515190","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431765"},{"title":"19 - Observe the results","text":"%md\nReturn to the Spark shell and observe the results displayed on the console.\n\nIn particular, take note of the time period values in the `window` column. The value is a pair consisting of a start time and an end time.\n\n- Each period spans a 10-second time period, reflecting the window duration you specified above; for example, a \n  period with start time `2019-06-05 08:12:40` and end time `2019-06-05 08:12:50`.\n- New windows are generated every five seconds. For example, a period with start time `2019-06-05 08:12:40` will be \n  followed by a period starting `2019-06-05 08:12:45` -- five seconds later.\n- Each row in the results shows the number of times a particular device model occurred within a window. That means there \n  will be up to two rows for any one window -- one with the MeeToo 3.0 count and the other with the MeeToo 3.1 count.\n- The events included in consecutive windows overlap. That is, an event that occurred at `2019-06-05 08:12:48` is included \n  in two 10-second windows: the `2019-06-05 08:12:40` and `2019-06-05 08:12:45` windows.\n- Note that the results are unordered; results for consecutive windows may not be displayed consecutively in the output.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Return to the Spark shell and observe the results displayed on the console.</p>\n<p>In particular, take note of the time period values in the <code>window</code> column. The value is a pair consisting of a start time and an end time.</p>\n<ul>\n<li>Each period spans a 10-second time period, reflecting the window duration you specified above; for example, a\n<br  />period with start time <code>2019-06-05 08:12:40</code> and end time <code>2019-06-05 08:12:50</code>.</li>\n<li>New windows are generated every five seconds. For example, a period with start time <code>2019-06-05 08:12:40</code> will be\n<br  />followed by a period starting <code>2019-06-05 08:12:45</code> &ndash; five seconds later.</li>\n<li>Each row in the results shows the number of times a particular device model occurred within a window. That means there\n<br  />will be up to two rows for any one window &ndash; one with the MeeToo 3.0 count and the other with the MeeToo 3.1 count.</li>\n<li>The events included in consecutive windows overlap. That is, an event that occurred at <code>2019-06-05 08:12:48</code> is included\n<br  />in two 10-second windows: the <code>2019-06-05 08:12:40</code> and <code>2019-06-05 08:12:45</code> windows.</li>\n<li>Note that the results are unordered; results for consecutive windows may not be displayed consecutively in the output.</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1617309777894_1669568619","id":"20210122-160138_1040078399","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431766"},{"title":"20 - Stop the query","text":"%md\n```\nwindowModelCountQuery.stop()\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<pre><code>windowModelCountQuery.stop()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777894_-173327413","id":"20200429-233730_693625211","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431767"},{"title":"21 - Run the query using the update output mode","text":"%md\nRerun the query above, except use the `update` output mode.\n\n```\nwindowModelCountQuery2 = windowModelCountDF. \\\nwriteStream.outputMode(\"update\"). \\\nformat(\"console\").option(\"truncate\",\"false\"). \\\ntrigger(processingTime=\"15 seconds\").start()\n```\n\nNote that the trigger interval is longer than in the last query. This means that each batch will be based on more data, \nmaking the results easier to analyze.\n","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Rerun the query above, except use the <code>update</code> output mode.</p>\n<pre><code>windowModelCountQuery2 = windowModelCountDF. \\\nwriteStream.outputMode(\"update\"). \\\nformat(\"console\").option(\"truncate\",\"false\"). \\\ntrigger(processingTime=\"15 seconds\").start()\n</code></pre>\n<p>Note that the trigger interval is longer than in the last query. This means that each batch will be based on more data,\n<br  />making the results easier to analyze.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777895_-787722361","id":"20210122-160228_910614616","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431768"},{"title":"22 - Test the query","text":"%md\nGenerate test events as you did above. Let the script run for at least a minute.\n\n```\n/home/training/training_material/devsh/scripts/streamtest-kafka.sh activations localhost:9092 10 /home/training/training_material/devsh/data/activations_stream\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Generate test events as you did above. Let the script run for at least a minute.</p>\n<pre><code>/home/training/training_material/devsh/scripts/streamtest-kafka.sh activations localhost:9092 10 /home/training/training_material/devsh/data/activations_stream\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777895_-2043443317","id":"20210122-160319_532106077","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431769"},{"title":"23 - Review the output","text":"%md\nReview the `update` mode output.\n\nThis time only windows with counts that changed between the previous batch and the current one are displayed. That is, if no MeeToo 3.0 devices were activated \nbetween `2019-06-05 08:12:40` and `2019-06-05 08:12:50`, then the row containing the MeeToo 3.0 count for that window will not be shown.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Review the <code>update</code> mode output.</p>\n<p>This time only windows with counts that changed between the previous batch and the current one are displayed. That is, if no MeeToo 3.0 devices were activated\n<br  />between <code>2019-06-05 08:12:40</code> and <code>2019-06-05 08:12:50</code>, then the row containing the MeeToo 3.0 count for that window will not be shown.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777895_870006365","id":"20210122-160612_659137142","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431770"},{"title":"24 - Stop the query","text":"%md\n```\nwindowModelCountQuery2.stop()\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<pre><code>windowModelCountQuery2.stop()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777896_866636234","id":"20200429-235635_1832562156","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431771"},{"title":"","text":"%md\n#### Join Streaming Activation and Static Account Data\n\nIn this section, you will join static account data in the `devsh.accounts` Hive table with streaming activation data based on the account ID. Only active \naccounts (those for which the `acct_close_dt` is null) will be included in the results. You will practice using both an inner and an outer join.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Join Streaming Activation and Static Account Data</h4>\n<p>In this section, you will join static account data in the <code>devsh.accounts</code> Hive table with streaming activation data based on the account ID. Only active\n<br  />accounts (those for which the <code>acct_close_dt</code> is null) will be included in the results. You will practice using both an inner and an outer join.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777896_1109757875","id":"20200429-235633_245798890","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431772"},{"title":"25 - Define a static DataFrame","text":"%md\nDefine a static DataFrame containing rows where `acct_close_dt` is null.\n\n```\naccountsStaticDF = spark.read.table(\"devsh.accounts\")\n\nactiveAccountsStaticDF = accountsStaticDF.where(accountsStaticDF.acct_close_dt.isNull())\n```\n","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Define a static DataFrame containing rows where <code>acct_close_dt</code> is null.</p>\n<pre><code>accountsStaticDF = spark.read.table(\"devsh.accounts\")\n\nactiveAccountsStaticDF = accountsStaticDF.where(accountsStaticDF.acct_close_dt.isNull())\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777897_1053203692","id":"20210122-160847_765257905","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431773"},{"title":"26 - Join the DataFrames","text":"%md\nJoin the static active accounts DataFrame with the `activationsDF` you created in the previous section. Include the account number, first name, last name, \naccount close date, and device ID in the new DataFrame.\n\n```\njoinedDF = activeAccountsStaticDF. \\\njoin(activationsDF, activationsDF.activation.acct_num == accountsStaticDF.acct_num). \\\nselect(\"acct_num\",\"first_name\",\"last_name\",\"acct_num\",\"acct_close_dt\",\"activation.dev_id\")\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Join the static active accounts DataFrame with the <code>activationsDF</code> you created in the previous section. Include the account number, first name, last name,\n<br  />account close date, and device ID in the new DataFrame.</p>\n<pre><code>joinedDF = activeAccountsStaticDF. \\\njoin(activationsDF, activationsDF.activation.acct_num == accountsStaticDF.acct_num). \\\nselect(\"acct_num\",\"first_name\",\"last_name\",\"acct_num\",\"acct_close_dt\",\"activation.dev_id\")\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777897_-654597207","id":"20200429-235820_1131193567","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431774"},{"title":"27 - Display account data","text":"%md\nStart a query to display account data to the console. Use append output mode and set a one second trigger.\n\n```\njoinedQuery = joinedDF. \\\nwriteStream.outputMode(\"append\"). \\\nformat(\"console\").option(\"truncate\",\"false\"). \\\ntrigger(processingTime=\"1 seconds\").start()\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Start a query to display account data to the console. Use append output mode and set a one second trigger.</p>\n<pre><code>joinedQuery = joinedDF. \\\nwriteStream.outputMode(\"append\"). \\\nformat(\"console\").option(\"truncate\",\"false\"). \\\ntrigger(processingTime=\"1 seconds\").start()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777898_1005077057","id":"20210122-160931_700026690","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431775"},{"title":"28 - Test the query","text":"%md\nGenerate test events as you did in the last section. Let the script run for a few seconds.\n\n```\n/home/training/training_materials/devsh/scripts/streamtest-kafka.sh activations localhost:9092 10 /home/training/training_material/devsh/data/activations_stream\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Generate test events as you did in the last section. Let the script run for a few seconds.</p>\n<pre><code>/home/training/training_materials/devsh/scripts/streamtest-kafka.sh activations localhost:9092 10 /home/training/training_material/devsh/data/activations_stream\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777898_-1544289276","id":"20200427-010654_2032587977","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431776"},{"title":"29 - Review the output","text":"%md\nReview the console output in the Spark shell. Note that the joined DataFrame contains only activation data associated with active accounts. Inactive accounts \nwere excluded from the accounts data, and you performed an inner join (the default), so activation records for accounts not in the accounts DataFrame were \nignored.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Review the console output in the Spark shell. Note that the joined DataFrame contains only activation data associated with active accounts. Inactive accounts\n<br  />were excluded from the accounts data, and you performed an inner join (the default), so activation records for accounts not in the accounts DataFrame were\n<br  />ignored.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777899_1147263173","id":"20210122-161144_1046384193","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431777"},{"title":"30 - Stop the query","text":"%md\n```\njoinedQuery.stop()\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<pre><code>joinedQuery.stop()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777899_-184653769","id":"20200427-010625_1405494394","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431778"},{"title":"31 - Perform a right outer join","text":"%md\nRepeat the steps above, but this time perform a right outer join.\n\n```\njoinedRightDF = activeAccountsStaticDF. \\\njoin(activationsDF, activationsDF.activation.acct_num ==\naccountsStaticDF.acct_num,\"right_outer\"). \\\nselect(\"acct_num\",\"first_name\",\"last_name\",\n\"acct_close_dt\",\"activation.dev_id\")\n\njoinedRightQuery = joinedRightDF.writeStream. \\\noutputMode(\"append\").format(\"console\"). \\\noption(\"truncate\",\"false\"). \\\ntrigger(processingTime=\"1 seconds\").start()\n```\n","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Repeat the steps above, but this time perform a right outer join.</p>\n<pre><code>joinedRightDF = activeAccountsStaticDF. \\\njoin(activationsDF, activationsDF.activation.acct_num ==\naccountsStaticDF.acct_num,\"right_outer\"). \\\nselect(\"acct_num\",\"first_name\",\"last_name\",\n\"acct_close_dt\",\"activation.dev_id\")\n\njoinedRightQuery = joinedRightDF.writeStream. \\\noutputMode(\"append\").format(\"console\"). \\\noption(\"truncate\",\"false\"). \\\ntrigger(processingTime=\"1 seconds\").start()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777899_-529054770","id":"20210122-161219_951154260","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431779"},{"title":"32 - Test the query and review the results","text":"%md\nTest the query using the message generation script again and compare the results to the previous query. Note that this time, the output includes rows in which \nthe account data (such as account number) is null. That is because the outer join includes all data from the streaming DataFrame, even when it does not have \na matching row in the static DataFrame.","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Test the query using the message generation script again and compare the results to the previous query. Note that this time, the output includes rows in which\n<br  />the account data (such as account number) is null. That is because the outer join includes all data from the streaming DataFrame, even when it does not have\n<br  />a matching row in the static DataFrame.</p>\n"}]},"apps":[],"jobName":"paragraph_1617309777900_1448497740","id":"20210122-161303_814860793","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431780"},{"title":"33 - Stop the query","text":" %md\n\n```pyspark\njoinedRightQuery.stop()\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<pre><code class=\"pyspark\">joinedRightQuery.stop()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777900_207032415","id":"20200427-010430_261610496","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431781"},{"text":"%md\n# Tear Down\n---\n","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Tear Down</h1>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1617309777901_-1657286919","id":"20210122-153312_2083005911","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431782"},{"title":"Quit pyspark","text":"%md\n~~~\nquit()\n~~~\n","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<pre><code>quit()\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777901_-1977092707","id":"20210207-105559_1557067683","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431783"},{"title":"Close terminals","text":"%md\n```xml\nexit\n```","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<pre><code class=\"xml\">exit\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617309777902_-774006862","id":"20210124-175027_1413450884","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431784"},{"title":"Additional resouorces","text":"%md\nWe hope you've enjoyed this lab. Below are additional resources that you should find useful:\n\n1. [Cloudera Tutorials](http://cloudera.com/tutorials.html) are your natural next step where you can explore Spark in more depth.\n2. [Cloudera Community](https://community.cloudera.com) is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.\n3. [Apache Spark Documentation](https://spark.apache.org/documentation.html) - official Spark documentation.\n4. [Apache Zeppelin Project Home Page](https://zeppelin.apache.org) - official Zeppelin web site.\n","user":"anonymous","dateUpdated":"2021-04-01T13:42:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>We hope you've enjoyed this lab. Below are additional resources that you should find useful:</p>\n<ol>\n<li><a href=\"http://cloudera.com/tutorials.html\">Cloudera Tutorials</a> are your natural next step where you can explore Spark in more depth.</li>\n<li><a href=\"https://community.cloudera.com\">Cloudera Community</a> is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.</li>\n<li><a href=\"https://spark.apache.org/documentation.html\">Apache Spark Documentation</a> - official Spark documentation.</li>\n<li><a href=\"https://zeppelin.apache.org\">Apache Zeppelin Project Home Page</a> - official Zeppelin web site.</li>\n</ol>\n"}]},"apps":[],"jobName":"paragraph_1617309777902_1465500757","id":"20181126-133017_244739700","dateCreated":"2021-04-01T13:42:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:431785"}],"name":"/DevSH/Pyspark/StreamAggregation","id":"2G55TP793","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"angular:shared_process":[],"sh:shared_process":[],"livy:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}