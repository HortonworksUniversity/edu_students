{"paragraphs":[{"text":"%md\n# About\n**Lab:** Persisting DataFrames\n**Objective:** Learn how to persist DataFrames to memory and/or disk.\n**File locations:**\n    Exercise directory: /home/training/training_materials/devsh/exercise/persist\n    Data (HDFS): /devsh_loudacre/accountdevice\n    Hive tables: devsh.accounts\n**Successful outcome:** \n**Before you begin:** \n**Related lessons:** \n\n---","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>About</h1>\n<p><strong>Lab:</strong> Persisting DataFrames\n<br  /><strong>Objective:</strong> Learn how to persist DataFrames to memory and/or disk.\n<br  /><strong>File locations:</strong></p>\n<pre><code>Exercise directory: /home/training/training_materials/devsh/exercise/persist\nData (HDFS): /devsh_loudacre/accountdevice\nHive tables: devsh.accounts\n</code></pre>\n<p><strong>Successful outcome:</strong>\n<br  /><strong>Before you begin:</strong>\n<br  /><strong>Related lessons:</strong></p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1617284281465_-1772490703","id":"20181126-092644_1457476546","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:143673"},{"text":"%md\n# Setup","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Setup</h1>\n"}]},"apps":[],"jobName":"paragraph_1617284281467_-1364363935","id":"20181201-044336_178705192","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143674"},{"title":"Set the environment variable to manage thread count","text":"%sh\n\nPYSPARK_PIN_THREAD=tru\n","user":"anonymous","dateUpdated":"2021-04-01T13:12:28-0700","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1617284281467_164180342","id":"20210121-214218_1626534289","dateCreated":"2021-04-01T06:38:01-0700","dateStarted":"2021-04-01T13:12:28-0700","dateFinished":"2021-04-01T13:12:28-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:143675"},{"title":"Start the Spark Context for Livy","text":"%pyspark\n\nsc = spark.sparkContext\n","user":"anonymous","dateUpdated":"2021-04-01T13:12:30-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<font color=\"red\">Previous livy session is expired, new livy session is created. Paragraphs that depend on this paragraph need to be re-executed!</font>"}]},"apps":[],"jobName":"paragraph_1617284281467_679075583","id":"20210121-214311_706726664","dateCreated":"2021-04-01T06:38:01-0700","dateStarted":"2021-04-01T13:12:30-0700","dateFinished":"2021-04-01T13:13:15-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:143676"},{"text":"%md\n# Lab\n","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Lab</h1>\n"}]},"apps":[],"jobName":"paragraph_1617284281468_1145629210","id":"20181126-093358_358613711","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143677"},{"text":"%md\n### Compare the Execution Plans of Persisted and Unpersisted Queries","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Compare the Execution Plans of Persisted and Unpersisted Queries</h3>\n"}]},"apps":[],"jobName":"paragraph_1617284281468_390760067","id":"20200426-035337_1420000263","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143678"},{"title":"1 - Join accounts with their associated devices","text":"%md\nCreate a DataFrame that joins account data for all accounts with their associated devices. To save time and effort, some stub code has been provided for you.","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Create a DataFrame that joins account data for all accounts with their associated devices. To save time and effort, some stub code has been provided for you.</p>\n"}]},"apps":[],"jobName":"paragraph_1617284281468_-407237153","id":"20200426-035404_1322046437","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143679"},{"text":"%pyspark\n# stub: query setup\naccountsDF = spark.read.table(\"devsh.accounts\")\naccountDeviceDF = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"/devsh_loudacre/accountdevice\")\naccountsDevsDF =  accountsDF.join(accountDeviceDF,accountsDF.acct_num == accountDeviceDF.account_id)","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617284281469_1995871551","id":"20200429-210012_1471698944","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143680"},{"title":"2 - Display info from the new DataFrame","text":"%md\nThe query code you pasted above defines a new DataFrame called `accountsDevsDF`, which joins account data and device data. Try executing a query starting \nwith the accountsDevsDF DataFrame that displays the account number, first name, last name and device ID for each row.","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>The query code you pasted above defines a new DataFrame called <code>accountsDevsDF</code>, which joins account data and device data. Try executing a query starting\n<br  />with the accountsDevsDF DataFrame that displays the account number, first name, last name and device ID for each row.</p>\n"}]},"apps":[],"jobName":"paragraph_1617284281469_-310329980","id":"20200426-035403_1370280892","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143681"},{"text":"%pyspark\n\naccountsDevsDF. \\\nselect(\"acct_num\",\"first_name\",\"last_name\",\"device_id\"). \\\nshow(5)","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617284281469_-596322121","id":"20200426-035403_1059527028","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143682"},{"title":"3 - Note the complexity of the query you just executed","text":"%md\nIn your browser, go to the **SQL** tab of your application's Spark UI, and view the execution visualization of the query you just executed. Take note of the \ncomplexity so that you can compare it to later executions when using persistence. \n\nRemember that queries are listed in the **SQL** tab in the order they were executed, starting with the most recent. The descriptions of multiple executions of \nthe same action will not distinguish one query from another, so make sure you choose the correct one for the query you are looking at.","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>In your browser, go to the <strong>SQL</strong> tab of your application's Spark UI, and view the execution visualization of the query you just executed. Take note of the\n<br  />complexity so that you can compare it to later executions when using persistence.</p>\n<p>Remember that queries are listed in the <strong>SQL</strong> tab in the order they were executed, starting with the most recent. The descriptions of multiple executions of\n<br  />the same action will not distinguish one query from another, so make sure you choose the correct one for the query you are looking at.</p>\n"}]},"apps":[],"jobName":"paragraph_1617284281469_845594197","id":"20200426-035402_1252980857","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143683"},{"title":"4 - Persist accountsDevsDF","text":"%md\nIn your Spark shell, persist the `accountsDevsDF` DataFrame using the default storage level.","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>In your Spark shell, persist the <code>accountsDevsDF</code> DataFrame using the default storage level.</p>\n"}]},"apps":[],"jobName":"paragraph_1617284281470_867932671","id":"20200426-035401_1680646515","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143684"},{"text":"%pyspark\n\naccountsDevsDF.persist()","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617284281470_1821150060","id":"20200426-035401_1324998326","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143685"},{"title":"5 - Repeat the final steps of the query you executed above","text":"%pyspark\n\naccountsDevsDF. \\\nselect(\"acct_num\",\"first_name\",\"last_name\",\"device_id\"). \\\nshow(5)","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617284281470_1773169596","id":"20200426-035400_914284045","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143686"},{"title":"6 - Compare the execution diagram of this query with the one executed before","text":"%md\nIn the browser, reload the Spark UI **SQL** tab, and view the execution diagram for the query just executed. Notice that it has far fewer steps. Instead of \nreading, filtering, and joining the data from the two sources, it reads the persisted data from memory. If you hover your mouse over the memory scan step, \nyou will see that the only operation it performs on the data in memory is the last step of the query: the unpersisted select transformation. Compare the \ndiagram for this query with the first one you executed above, before persisting.","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>In the browser, reload the Spark UI <strong>SQL</strong> tab, and view the execution diagram for the query just executed. Notice that it has far fewer steps. Instead of\n<br  />reading, filtering, and joining the data from the two sources, it reads the persisted data from memory. If you hover your mouse over the memory scan step,\n<br  />you will see that the only operation it performs on the data in memory is the last step of the query: the unpersisted select transformation. Compare the\n<br  />diagram for this query with the first one you executed above, before persisting.</p>\n"}]},"apps":[],"jobName":"paragraph_1617284281471_626596124","id":"20200426-035358_1654934869","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143687"},{"title":"7 - Analyze the two execution diagrams","text":"%md\nThe first time you execute a query on a persisted DataFrame, Dataset, or RDD, Spark has to execute the full query in order to materialize the data that gets \nsaved in memory or on disk. Compare the difference between the first and second queries after executing `persist` by re-executing the query one final time. \nThen use the Spark UI to compare both queries executed after the `persist` operation, and consider these questions.\n\n- Do the execution diagrams differ? Why or why not?\n- Did one query take longer than the other? If so, which one, and why?","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>The first time you execute a query on a persisted DataFrame, Dataset, or RDD, Spark has to execute the full query in order to materialize the data that gets\n<br  />saved in memory or on disk. Compare the difference between the first and second queries after executing <code>persist</code> by re-executing the query one final time.\n<br  />Then use the Spark UI to compare both queries executed after the <code>persist</code> operation, and consider these questions.</p>\n<ul>\n<li>Do the execution diagrams differ? Why or why not?</li>\n<li>Did one query take longer than the other? If so, which one, and why?</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1617284281471_1764851324","id":"20200426-035358_848001533","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143688"},{"text":"%md\n### View Storage for Persisted DataFrames","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>View Storage for Persisted DataFrames</h3>\n"}]},"apps":[],"jobName":"paragraph_1617284281471_-2056324791","id":"20200426-035357_341037510","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143689"},{"title":"8 - Review the properties of the RDD","text":"%md\nView the **Storage** tab in the Spark UI to see currently persisted data. The list shows the RDD identified by the execution plan for the query that generated \nthe data. Consider these questions.\n\n- What is the storage level of the RDD?\n- How many partitions of the RDD were persisted and how much space do those partitions take up in memory and on disk?\n- Note that only a small percentage of the data is cached. Why is that? How could you cache more of the data?\n- Click the RDD name to view the storage details. Which executors are storing data for this RDD?","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>View the <strong>Storage</strong> tab in the Spark UI to see currently persisted data. The list shows the RDD identified by the execution plan for the query that generated\n<br  />the data. Consider these questions.</p>\n<ul>\n<li>What is the storage level of the RDD?</li>\n<li>How many partitions of the RDD were persisted and how much space do those partitions take up in memory and on disk?</li>\n<li>Note that only a small percentage of the data is cached. Why is that? How could you cache more of the data?</li>\n<li>Click the RDD name to view the storage details. Which executors are storing data for this RDD?</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1617284281472_891159078","id":"20200426-035346_198043054","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143690"},{"title":"9 - Execute the query using the write action","text":"%md\nExecute the same query as above using the write action instead of show.","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Execute the same query as above using the write action instead of show.</p>\n"}]},"apps":[],"jobName":"paragraph_1617284281472_1588685257","id":"20200426-035345_2068263348","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143691"},{"text":"%pyspark\n\naccountsDevsDF.write.mode(\"overwrite\"). \\\nsave(\"/devsh_loudacre/accounts_devices\")","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617284281472_370791789","id":"20200426-035345_1468680125","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143692"},{"title":"10 - Analyze the storage used with the new version of the query","text":"%md\nReload the Spark UI **Storage** tab.\n\n- What percentage of the data is cached? Why? How does this compare to the last time you persisted the data?\n- How much memory is the data taking up? How much disk space?","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Reload the Spark UI <strong>Storage</strong> tab.</p>\n<ul>\n<li>What percentage of the data is cached? Why? How does this compare to the last time you persisted the data?</li>\n<li>How much memory is the data taking up? How much disk space?</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1617284281473_886739059","id":"20200426-062545_1647187544","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143693"},{"text":"%md\n### Change the Storage Level for the Persisted DataFrame","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Change the Storage Level for the Persisted DataFrame</h3>\n"}]},"apps":[],"jobName":"paragraph_1617284281473_-1245491972","id":"20200426-062544_2035581418","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143694"},{"title":"11 - Unpersist the accountsDevsDF DataFrame","text":"%pyspark\n\naccountsDevsDF.unpersist()","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617284281473_-583386973","id":"20200426-062544_2125101715","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143695"},{"title":"12 - Verify that the cache has been removed","text":"%md\nView the Spark UI **Storage** to verify that the cache for `accountsDevsDF` has been removed.","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>View the Spark UI <strong>Storage</strong> to verify that the cache for <code>accountsDevsDF</code> has been removed.</p>\n"}]},"apps":[],"jobName":"paragraph_1617284281474_1349716307","id":"20200426-062543_1322148377","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143696"},{"title":"13 - Persist the same DataFrame again","text":"%md\nRepersist the same DataFrame, setting the storage level to save the data files on disk, replicated twice.","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Repersist the same DataFrame, setting the storage level to save the data files on disk, replicated twice.</p>\n"}]},"apps":[],"jobName":"paragraph_1617284281474_-547943306","id":"20200426-062542_123835292","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143697"},{"text":"%pyspark\n\nfrom pyspark import StorageLevel\n\naccountsDevsDF.persist(StorageLevel.DISK_ONLY_2)","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617284281474_-114853619","id":"20200426-062542_1989337635","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143698"},{"title":"14 - Re-execute the previous query","text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617284281475_-1663332538","id":"20200426-062541_564847369","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143699"},{"title":"15 - Analyze how the data is stored","text":"%md\nReload the **Storage** tab to confirm that the storage level for the RDD is set correctly.\nAlso consider these questions:\n\n- How much memory is the data taking up? How much disk space?\n- Which executors are storing the RDD's data files?\n- How many partitions are stored? Are they replicated? Where?","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Reload the <strong>Storage</strong> tab to confirm that the storage level for the RDD is set correctly.\n<br  />Also consider these questions:</p>\n<ul>\n<li>How much memory is the data taking up? How much disk space?</li>\n<li>Which executors are storing the RDD's data files?</li>\n<li>How many partitions are stored? Are they replicated? Where?</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1617284281476_-1826079761","id":"20200426-062541_214949809","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143700"},{"text":"%md\n# Result\n**You have now:** \n\n---","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Result</h1>\n<p><strong>You have now:</strong></p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1617284281477_-550254071","id":"20181126-133507_1472573213","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143701"},{"text":"%md\n# Solution\n---","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Solution</h1>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1617284281477_1561572658","id":"20181018-125200_1133281582","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143702"},{"text":"%md\n### Compare the Execution Plans of Persisted and Unpersisted Queries","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Compare the Execution Plans of Persisted and Unpersisted Queries</h3>\n"}]},"apps":[],"jobName":"paragraph_1617284281478_-1462746859","id":"20200429-205813_408772061","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143703"},{"text":"%md\n#### Spark Cache and Persist\nSpark Cache and Persist are optimization techniques used in DataFrame/Dataset to improve job performance. The use case is for large jobs, billions or \ntrillions of rows of data, where reuse of the data versus repeating computations will greatly improve performance and signficantly reduce runtime. \n\nBoth the cache() and persist() methods will store intermediate computation of a DataFrame, this allows subsequent actions to reuse the results of these \ncomputations. When a dataset is persisted each node stores it's partitioned data in memory for reuse. This persisted data is fault-tolerant,if a dataset is \nlost, it will automatically be recomputed using the original transformations.\n\nCorrect use of Spark Cache and Persist will reduce costs and time due to improved execution.\n\n","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Spark Cache and Persist</h4>\n<p>Spark Cache and Persist are optimization techniques used in DataFrame/Dataset to improve job performance. The use case is for large jobs, billions or\n<br  />trillions of rows of data, where reuse of the data versus repeating computations will greatly improve performance and signficantly reduce runtime.</p>\n<p>Both the cache() and persist() methods will store intermediate computation of a DataFrame, this allows subsequent actions to reuse the results of these\n<br  />computations. When a dataset is persisted each node stores it's partitioned data in memory for reuse. This persisted data is fault-tolerant,if a dataset is\n<br  />lost, it will automatically be recomputed using the original transformations.</p>\n<p>Correct use of Spark Cache and Persist will reduce costs and time due to improved execution.</p>\n"}]},"apps":[],"jobName":"paragraph_1617284281478_1502007932","id":"20210124-103213_79776330","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143704"},{"text":"%md\n#### Syntax Spark Cache\n\n`cache() : dataset`\n\nSpark DataFrame or Dataset cache() method saves to storage level `MEMORY_AND_DISK`","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Syntax Spark Cache</h4>\n<p><code>cache() : dataset</code></p>\n<p>Spark DataFrame or Dataset cache() method saves to storage level <code>MEMORY_AND_DISK</code></p>\n"}]},"apps":[],"jobName":"paragraph_1617284281479_1879304055","id":"20210124-104618_422611205","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143705"},{"text":"%md\n#### Syntax Spark Persist\n\n`persist() : dataset`\n`persist(newLevel : org.apache.spark.stroage.StorageLevel) : dataset`\n\nSpark persist has two signatures. The first saves data to `MEMORY_AND_DISK`. The second sets the `StorageLevel`.\n\n`unpersist() : dataset`","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Syntax Spark Persist</h4>\n<p><code>persist() : dataset</code>\n<br  /><code>persist(newLevel : org.apache.spark.stroage.StorageLevel) : dataset</code></p>\n<p>Spark persist has two signatures. The first saves data to <code>MEMORY_AND_DISK</code>. The second sets the <code>StorageLevel</code>.</p>\n<p><code>unpersist() : dataset</code></p>\n"}]},"apps":[],"jobName":"paragraph_1617284281479_-1290997558","id":"20210124-104830_1558418408","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143706"},{"text":"%md\n#### Spark Persist Storage Levels\n\n`MEMORY_ONLY` This stores the DataFrame as deserialized objects to JVM memory. When there is not sufficent memory it will not save some partitions, re-computing \nthem as required.\n\n`MEMORY_ONLY_SER` This stores the DataFrame as serialized objects to JVM memory. It consumes less memory but requires more CPU.\n\n`MEMORY_AND_DISK` This is the default behavior. The DataFrame is stored as desereialized objects in the JVM memory, when required storage is greater than \navailable memory, it spills over to disk. IF I/O is involved this is noticabley slower.\n\n`DISK_ONLY` The DataFrame is stored only on disk resulting in higher CPU computation time for I/O.\n\nTo increase availability each partition can be replicated to two cluster nodes. \n`MEMORY_ONLY_2` or `MEMORY_ONLY_SER_2`","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Spark Persist Storage Levels</h4>\n<p><code>MEMORY_ONLY</code> This stores the DataFrame as deserialized objects to JVM memory. When there is not sufficent memory it will not save some partitions, re-computing\n<br  />them as required.</p>\n<p><code>MEMORY_ONLY_SER</code> This stores the DataFrame as serialized objects to JVM memory. It consumes less memory but requires more CPU.</p>\n<p><code>MEMORY_AND_DISK</code> This is the default behavior. The DataFrame is stored as desereialized objects in the JVM memory, when required storage is greater than\n<br  />available memory, it spills over to disk. IF I/O is involved this is noticabley slower.</p>\n<p><code>DISK_ONLY</code> The DataFrame is stored only on disk resulting in higher CPU computation time for I/O.</p>\n<p>To increase availability each partition can be replicated to two cluster nodes.\n<br  /><code>MEMORY_ONLY_2</code> or <code>MEMORY_ONLY_SER_2</code></p>\n"}]},"apps":[],"jobName":"paragraph_1617284281479_5562216","id":"20210124-105204_1695707574","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143707"},{"title":"1 - Join accounts with their associated devices","text":"%pyspark\n\naccountsDF = spark.read.table(\"devsh.accounts\")\naccountDeviceDF = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"/devsh_loudacre/accountdevice\")\naccountsDevsDF =  accountsDF.join(accountDeviceDF,accountsDF.acct_num == accountDeviceDF.account_id)","user":"anonymous","dateUpdated":"2021-04-01T13:24:38-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1617284281480_-1831840673","id":"20200429-205812_1635150681","dateCreated":"2021-04-01T06:38:01-0700","dateStarted":"2021-04-01T13:24:38-0700","dateFinished":"2021-04-01T13:24:47-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:143708"},{"text":"%md\nCreate a DataFrame that joins account data for all accounts with their associated devices. To save time and effort, some stub code has been provided for you\n","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Create a DataFrame that joins account data for all accounts with their associated devices. To save time and effort, some stub code has been provided for you</p>\n"}]},"apps":[],"jobName":"paragraph_1617284281480_27004610","id":"20210121-220907_675834635","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143709"},{"title":"2 - Display info from the new DataFrame","text":"%pyspark\n\naccountsDevsDF.select(\"acct_num\",\"first_name\",\"last_name\",\"device_id\").show(5)","user":"anonymous","dateUpdated":"2021-04-01T13:25:06-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+----------+---------+---------+\n|acct_num|first_name|last_name|device_id|\n+--------+----------+---------+---------+\n|       1|    Donald|   Becton|       29|\n|       1|    Donald|   Becton|        9|\n|       2|     Donna|    Jones|        5|\n|       3|    Dorthy| Chalmers|        5|\n|       4|     Leila|  Spencer|       38|\n+--------+----------+---------+---------+\nonly showing top 5 rows"}]},"apps":[],"jobName":"paragraph_1617284281480_-1284185319","id":"20200429-205855_48052881","dateCreated":"2021-04-01T06:38:01-0700","dateStarted":"2021-04-01T13:25:06-0700","dateFinished":"2021-04-01T13:25:08-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:143710"},{"text":"%md\nThe query code you pasted above defines a new DataFrame called `accountsDevsDF`, which joins account data and device data. Try executing a query starting \nwith the accountsDevsDF DataFrame that displays the account number, first name, last name and device ID for each row.","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>The query code you pasted above defines a new DataFrame called <code>accountsDevsDF</code>, which joins account data and device data. Try executing a query starting\n<br  />with the accountsDevsDF DataFrame that displays the account number, first name, last name and device ID for each row.</p>\n"}]},"apps":[],"jobName":"paragraph_1617284281481_1629909874","id":"20210121-220947_1313610659","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143711"},{"title":"3 - Note the complexity of the query you just executed","text":"%md\nIn your browser, go to the **SQL** tab of your application's Spark UI, and view the execution visualization of the query you just executed. Take note of the \ncomplexity so that you can compare it to later executions when using persistence. \n\nRemember that queries are listed in the **SQL** tab in the order they were executed, starting with the most recent. The descriptions of multiple executions of \nthe same action will not distinguish one query from another, so make sure you choose the correct one for the query you are looking at.","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>In your browser, go to the <strong>SQL</strong> tab of your application's Spark UI, and view the execution visualization of the query you just executed. Take note of the\n<br  />complexity so that you can compare it to later executions when using persistence.</p>\n<p>Remember that queries are listed in the <strong>SQL</strong> tab in the order they were executed, starting with the most recent. The descriptions of multiple executions of\n<br  />the same action will not distinguish one query from another, so make sure you choose the correct one for the query you are looking at.</p>\n"}]},"apps":[],"jobName":"paragraph_1617284281481_881875341","id":"20200429-205854_1575015129","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143712"},{"title":"4 - Persist accountsDevsDF","text":"%pyspark\n\naccountsDevsDF.persist()","user":"anonymous","dateUpdated":"2021-04-01T13:25:37-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"DataFrame[acct_num: int, acct_create_dt: timestamp, acct_close_dt: timestamp, first_name: string, last_name: string, address: string, city: string, state: string, zipcode: string, phone_number: string, created: timestamp, modified: timestamp, id: int, account_id: int, device_id: int, activation_date: bigint, account_device_id: string]"}]},"apps":[],"jobName":"paragraph_1617284281482_612398898","id":"20200429-205854_261598927","dateCreated":"2021-04-01T06:38:01-0700","dateStarted":"2021-04-01T13:25:37-0700","dateFinished":"2021-04-01T13:25:38-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:143713"},{"text":"%md\nIn your Spark shell, persist the `accountsDevsDF` DataFrame using the default storage level.\n","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>In your Spark shell, persist the <code>accountsDevsDF</code> DataFrame using the default storage level.</p>\n"}]},"apps":[],"jobName":"paragraph_1617284281482_868484371","id":"20210121-222343_1030436738","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143714"},{"title":"5 - Repeat the final steps of the query you executed above","text":"%pyspark\n\naccountsDevsDF.select(\"acct_num\",\"first_name\",\"last_name\",\"device_id\").show(5)","user":"anonymous","dateUpdated":"2021-04-01T13:28:37-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+----------+---------+---------+\n|acct_num|first_name|last_name|device_id|\n+--------+----------+---------+---------+\n|     148|    Johnny|   Vargas|       38|\n|     148|    Johnny|   Vargas|       29|\n|     463|    Robert|   Dailey|        5|\n|     463|    Robert|   Dailey|        9|\n|     471|       Kim|  Johnson|        9|\n+--------+----------+---------+---------+\nonly showing top 5 rows"}]},"apps":[],"jobName":"paragraph_1617284281483_1147644398","id":"20200429-205852_1436750479","dateCreated":"2021-04-01T06:38:01-0700","dateStarted":"2021-04-01T13:28:37-0700","dateFinished":"2021-04-01T13:28:42-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:143715"},{"title":"6 - Compare the execution diagram of this query with the one executed before","text":"%md\nIn the browser, reload the Spark UI **SQL** tab, and view the execution diagram for the query just executed. Notice that it has far fewer steps. Instead of \nreading, filtering, and joining the data from the two sources, it reads the persisted data from memory. If you hover your mouse over the memory scan step, \nyou will see that the only operation it performs on the data in memory is the last step of the query: the unpersisted selecttransformation. Compare the \ndiagram for this query with the first one you executed above, before persisting.","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>In the browser, reload the Spark UI <strong>SQL</strong> tab, and view the execution diagram for the query just executed. Notice that it has far fewer steps. Instead of\n<br  />reading, filtering, and joining the data from the two sources, it reads the persisted data from memory. If you hover your mouse over the memory scan step,\n<br  />you will see that the only operation it performs on the data in memory is the last step of the query: the unpersisted selecttransformation. Compare the\n<br  />diagram for this query with the first one you executed above, before persisting.</p>\n"}]},"apps":[],"jobName":"paragraph_1617284281483_-1040541538","id":"20200429-205851_2101455775","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143716"},{"title":"7 - Analyze the two execution diagrams","text":"%md\nThe first time you execute a query on a persisted DataFrame, Dataset, or RDD, Spark has to execute the full query in order to materialize the data that gets \nsaved in memory or on disk. Compare the difference between the first and second queries after executing `persist` by re-executing the query one final time. \nThen use the Spark UI to compare both queries executed after the `persist` operation, and consider these questions.\n\n- Do the execution diagrams differ? Why or why not?\n- Did one query take longer than the other? If so, which one, and why?","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>The first time you execute a query on a persisted DataFrame, Dataset, or RDD, Spark has to execute the full query in order to materialize the data that gets\n<br  />saved in memory or on disk. Compare the difference between the first and second queries after executing <code>persist</code> by re-executing the query one final time.\n<br  />Then use the Spark UI to compare both queries executed after the <code>persist</code> operation, and consider these questions.</p>\n<ul>\n<li>Do the execution diagrams differ? Why or why not?</li>\n<li>Did one query take longer than the other? If so, which one, and why?</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1617284281484_2072393580","id":"20200429-205850_795239181","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143717"},{"text":"%md\n### View Storage for Persisted DataFrames","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>View Storage for Persisted DataFrames</h3>\n"}]},"apps":[],"jobName":"paragraph_1617284281484_-1603732121","id":"20200429-205850_1346508345","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143718"},{"title":"8 - Review the properties of the RDD","text":"%md\nView the **Storage** tab in the Spark UI to see currently persisted data. The list shows the RDD identified by the execution plan for the query that generated \nthe data. Consider these questions.\n\n- What is the storage level of the RDD?\n- How many partitions of the RDD were persisted and how much space do those partitions take up in memory and on disk?\n- Note that only a small percentage of the data is cached. Why is that? How could you cache more of the data?\n- Click the RDD name to view the storage details. Which executors are storing data for this RDD?","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>View the <strong>Storage</strong> tab in the Spark UI to see currently persisted data. The list shows the RDD identified by the execution plan for the query that generated\n<br  />the data. Consider these questions.</p>\n<ul>\n<li>What is the storage level of the RDD?</li>\n<li>How many partitions of the RDD were persisted and how much space do those partitions take up in memory and on disk?</li>\n<li>Note that only a small percentage of the data is cached. Why is that? How could you cache more of the data?</li>\n<li>Click the RDD name to view the storage details. Which executors are storing data for this RDD?</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1617284281485_1157154838","id":"20200429-205849_384433336","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143719"},{"title":"9 - Execute the query using the write action","text":"%pyspark\n\naccountsDevsDF.write.mode(\"overwrite\").save(\"/devsh_loudacre/accounts_devices\")","user":"anonymous","dateUpdated":"2021-04-01T13:34:37-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1617284281485_1827871462","id":"20200429-205849_124172407","dateCreated":"2021-04-01T06:38:01-0700","dateStarted":"2021-04-01T13:34:37-0700","dateFinished":"2021-04-01T13:34:54-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:143720"},{"text":"%md\nExecute the same query as above using the write action instead of show.\n","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Execute the same query as above using the write action instead of show.</p>\n"}]},"apps":[],"jobName":"paragraph_1617284281486_-962545944","id":"20210121-222627_493708305","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143721"},{"title":"10 - Analyze the storage used with the new version of the query","text":"%md\nReload the Spark UI **Storage** tab.\n\n- What percentage of the data is cached? Why? How does this compare to the last time you persisted the data?\n- How much memory is the data taking up? How much disk space?","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Reload the Spark UI <strong>Storage</strong> tab.</p>\n<ul>\n<li>What percentage of the data is cached? Why? How does this compare to the last time you persisted the data?</li>\n<li>How much memory is the data taking up? How much disk space?</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1617284281486_195442678","id":"20200429-205848_1867896831","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143722"},{"text":"%md\n### Change the Storage Level for the Persisted DataFrame","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Change the Storage Level for the Persisted DataFrame</h3>\n"}]},"apps":[],"jobName":"paragraph_1617284281487_-2034756470","id":"20200429-205847_1965596134","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143723"},{"title":"11 - Unpersist the accountsDevsDF DataFrame","text":"%pyspark\n\naccountsDevsDF.unpersist()","user":"anonymous","dateUpdated":"2021-04-01T13:35:54-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"DataFrame[acct_num: int, acct_create_dt: timestamp, acct_close_dt: timestamp, first_name: string, last_name: string, address: string, city: string, state: string, zipcode: string, phone_number: string, created: timestamp, modified: timestamp, id: int, account_id: int, device_id: int, activation_date: bigint, account_device_id: string]"}]},"apps":[],"jobName":"paragraph_1617284281487_-751225984","id":"20200429-205847_1443153254","dateCreated":"2021-04-01T06:38:01-0700","dateStarted":"2021-04-01T13:35:54-0700","dateFinished":"2021-04-01T13:35:55-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:143724"},{"title":"12 - Verify that the cache has been removed","text":"%md\nView the Spark UI **Storage** to verify that the cache for `accountsDevsDF` has been removed.","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>View the Spark UI <strong>Storage</strong> to verify that the cache for <code>accountsDevsDF</code> has been removed.</p>\n"}]},"apps":[],"jobName":"paragraph_1617284281488_-317530468","id":"20200429-205845_471575397","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143725"},{"title":"13 - Persist the same DataFrame again","text":"%pyspark\n\nfrom pyspark import StorageLevel \n\naccountsDevsDF.persist(StorageLevel.DISK_ONLY_2)","user":"anonymous","dateUpdated":"2021-04-01T13:36:33-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"DataFrame[acct_num: int, acct_create_dt: timestamp, acct_close_dt: timestamp, first_name: string, last_name: string, address: string, city: string, state: string, zipcode: string, phone_number: string, created: timestamp, modified: timestamp, id: int, account_id: int, device_id: int, activation_date: bigint, account_device_id: string]"}]},"apps":[],"jobName":"paragraph_1617284281488_-287405222","id":"20200429-205845_961146902","dateCreated":"2021-04-01T06:38:01-0700","dateStarted":"2021-04-01T13:36:33-0700","dateFinished":"2021-04-01T13:36:34-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:143726"},{"text":"%md\nPersist the same DataFrame again, setting the storage level to save the data files on disk, replicated twice.\n","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Persist the same DataFrame again, setting the storage level to save the data files on disk, replicated twice.</p>\n"}]},"apps":[],"jobName":"paragraph_1617284281489_-1774357588","id":"20210121-222916_910677424","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143727"},{"title":"14 - Re-execute the previous query","text":"%pyspark\n\naccountsDevsDF.write.mode(\"overwrite\").save(\"/devsh_loudacre/accounts_devices\")","user":"anonymous","dateUpdated":"2021-04-01T13:36:50-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1617284281489_1163245961","id":"20200429-205844_451916861","dateCreated":"2021-04-01T06:38:01-0700","dateStarted":"2021-04-01T13:36:50-0700","dateFinished":"2021-04-01T13:37:07-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:143728"},{"title":"15 - Analyze how the data is stored","text":"%md\nReload the **Storage** tab to confirm that the storage level for the RDD is set correctly. Also consider these questions:\n\n- How much memory is the data taking up? How much disk space?\n- Which executors are storing the RDD's data files?\n- How many partitions are stored? Are they replicated? Where?","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Reload the <strong>Storage</strong> tab to confirm that the storage level for the RDD is set correctly. Also consider these questions:</p>\n<ul>\n<li>How much memory is the data taking up? How much disk space?</li>\n<li>Which executors are storing the RDD's data files?</li>\n<li>How many partitions are stored? Are they replicated? Where?</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1617284281490_-180101088","id":"20200429-205842_2001073669","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143729"},{"text":"%md\n# Tear Down\n---","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Tear Down</h1>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1617284281490_-1180023351","id":"20210121-214516_1274770284","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143730"},{"title":"Delete the Livy session","text":"%sh\n\nsessionId=$(curl -s localhost:8998/sessions | jq '.sessions[0].id')\ncurl -s localhost:8998/sessions/$sessionId -X DELETE\n","user":"anonymous","dateUpdated":"2021-04-01T13:12:04-0700","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"{\"msg\":\"deleted\"}"}]},"apps":[],"jobName":"paragraph_1617284281491_2112748833","id":"20210121-214556_496925412","dateCreated":"2021-04-01T06:38:01-0700","dateStarted":"2021-04-01T13:12:04-0700","dateFinished":"2021-04-01T13:12:07-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:143731"},{"title":"Additional Resources","text":"%md\nWe hope you've enjoyed this lab. Below are additional resources that you should find useful:\n\n1. [Cloudera Tutorials](http://cloudera.com/tutorials.html) are your natural next step where you can explore Spark in more depth.\n2. [Cloudera Community](https://community.cloudera.com) is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.\n3. [Apache Spark Documentation](https://spark.apache.org/documentation.html) - official Spark documentation.\n4. [Apache Zeppelin Project Home Page](https://zeppelin.apache.org) - official Zeppelin web site.","user":"anonymous","dateUpdated":"2021-04-01T06:38:01-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>We hope you've enjoyed this lab. Below are additional resources that you should find useful:</p>\n<ol>\n<li><a href=\"http://cloudera.com/tutorials.html\">Cloudera Tutorials</a> are your natural next step where you can explore Spark in more depth.</li>\n<li><a href=\"https://community.cloudera.com\">Cloudera Community</a> is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.</li>\n<li><a href=\"https://spark.apache.org/documentation.html\">Apache Spark Documentation</a> - official Spark documentation.</li>\n<li><a href=\"https://zeppelin.apache.org\">Apache Zeppelin Project Home Page</a> - official Zeppelin web site.</li>\n</ol>\n"}]},"apps":[],"jobName":"paragraph_1617284281491_1803979426","id":"20181126-133017_244739700","dateCreated":"2021-04-01T06:38:01-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:143732"}],"name":"/DevSH/Pyspark/DataFramePersisting","id":"2G3AMFR4R","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"angular:shared_process":[],"sh:shared_process":[],"livy:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}