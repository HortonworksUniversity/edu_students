{"paragraphs":[{"text":"%md\n# About This Lab\n**Objective:** Explore RDDs tranformations. Load a text file into a RDD. Then create a RDD based on website log data. Practice transforming this data. Manipulate \ndevice status data in a RDD.\n**Exercise files:** \n    Exercise directory: /home/training/training_materials/devsh/exercises/transform-rdds\n    Data (local): /home/training/training_materials/devsh/data/weblogs\n                  /home/training/training_materials/devsh/data/devicestatus.txt\n**Successful outcome:**\n**Before you begin:**\n**Related lessons:** Transforming Data with RDDs\n\n---","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>About This Lab</h1>\n<p><strong>Objective:</strong> Explore RDDs tranformations. Load a text file into a RDD. Then create a RDD based on website log data. Practice transforming this data. Manipulate\n<br  />device status data in a RDD.\n<br  /><strong>Exercise files:</strong></p>\n<pre><code>Exercise directory: /home/training/training_materials/devsh/exercises/transform-rdds\nData (local): /home/training/training_materials/devsh/data/weblogs\n              /home/training/training_materials/devsh/data/devicestatus.txt\n</code></pre>\n<p><strong>Successful outcome:</strong>\n<br  /><strong>Before you begin:</strong>\n<br  /><strong>Related lessons:</strong> Transforming Data with RDDs</p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1618065446532_-1271736691","id":"20171105-200834_1116095891","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:390732"},{"text":"%md\n# Setup\n---\nThe following cells ensure that this notebook can run from top to bottom without errors any number of times.","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Setup</h1>\n<hr />\n<p>The following cells ensure that this notebook can run from top to bottom without errors any number of times.</p>\n"}]},"apps":[],"jobName":"paragraph_1618065446542_2076068961","id":"20181114-164229_902436001","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390733"},{"title":"Delete HDFS files to prevent file exist errors","text":"%sh\n\nhdfs dfs -rm -r -f -skipTrash /devsh_loudacre/weblogs\nhdfs dfs -rm -r -f -skipTrash /devsh_loudacre/iplist\nhdfs dfs -rm -r -f -skipTrash /devsh_loudacre/userips_csv\nhdfs dfs -rm -r -f -skipTrash /devsh_loudacre/devicestatus.txt\nhdfs dfs -rm -r -f -skipTrash /devsh_loudacre/devicestatus_etl\nhdfs dfs -rm -r -f -skipTrash /devsh_loudacre/activations\nhdfs dfs -rm -r -f -skipTrash /devsh_loudacre/account-models","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1618065446543_1155801446","id":"20200120-002654_545000747","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390734"},{"title":"Set the environment variable to manage thread count","text":"%sh\n\nPYSPARK_PIN_THREAD=true","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1618065446545_-511939967","id":"20200830-163746_574851316","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390735"},{"title":"Start the Spark Context for Livy","text":"%pyspark\n\nsc = spark.sparkContext","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<font color=\"red\">Previous livy session is expired, new livy session is created. Paragraphs that depend on this paragraph need to be re-executed!</font>"}]},"apps":[],"jobName":"paragraph_1618065446546_1888861020","id":"20200830-163851_381275363","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390736"},{"text":"%md\n# Lab\n---","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Lab</h1>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1618065446548_-777847930","id":"20181114-164844_1661453681","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390737"},{"text":"%md\n### Explore the Loudacre Web Log Files","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Explore the Loudacre Web Log Files</h3>\n"}]},"apps":[],"jobName":"paragraph_1618065446549_-1188890968","id":"20210123-132633_1958534497","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390738"},{"title":"1 - View weblogs","text":"%sh\n\n","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1618065446550_798657715","id":"20210121-193211_824772981","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390739"},{"text":"%md\n### Clean Device Status Data\nIf you have more time, attempt this extra bonus exercise. One common use of core Spark RDDs is data scrubbing—converting the data into a format that can be \nused in Spark SQL. In this bonus exercise, you will process data in order to get it into a standardized format for later processing. Review the contents of \nthe file /home/trainingtraining_materials/devsh/data/devicestatus.txt. This file contains data collected from mobile devices on Loudacre’s network, including \ndevice ID, current status, location, and so on. Because Loudacre previously acquired other mobile providers’ networks, the data from different subnetworks \nhas different formats. \nNote that the records in this file have different field delimiters: some use commas, some use pipes (|), and so on. \n```pyspark\n2014-03-15:10:10:33,Ronin S2,1a7eca8d-60c9-4d25-8609-d6cfd1ac80a1,0,24,82,72,enabled,enabled,enabled,41,62,36.49259162,-121.003629078\n2014-03-15:10:10:33/Titanic 2300/d86dbb9d-ff3c-40c6-8685-01f1fac45d9f/59/83/9/3/28/0/enabled/disabled/enabled/34.3456792864/-117.768326105\n```\n\n\nYour task is the following:","user":"anonymous","dateUpdated":"2021-04-10T07:50:58-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Clean Device Status Data</h3>\n<p>If you have more time, attempt this extra bonus exercise. One common use of core Spark RDDs is data scrubbing—converting the data into a format that can be\n<br  />used in Spark SQL. In this bonus exercise, you will process data in order to get it into a standardized format for later processing. Review the contents of\n<br  />the file /home/trainingtraining_materials/devsh/data/devicestatus.txt. This file contains data collected from mobile devices on Loudacre’s network, including\n<br  />device ID, current status, location, and so on. Because Loudacre previously acquired other mobile providers’ networks, the data from different subnetworks\n<br  />has different formats.\n<br  />Note that the records in this file have different field delimiters: some use commas, some use pipes (|), and so on.</p>\n<pre><code class=\"pyspark\">2014-03-15:10:10:33,Ronin S2,1a7eca8d-60c9-4d25-8609-d6cfd1ac80a1,0,24,82,72,enabled,enabled,enabled,41,62,36.49259162,-121.003629078\n2014-03-15:10:10:33/Titanic 2300/d86dbb9d-ff3c-40c6-8685-01f1fac45d9f/59/83/9/3/28/0/enabled/disabled/enabled/34.3456792864/-117.768326105\n</code></pre>\n<p>Your task is the following:</p>\n"}]},"apps":[],"jobName":"paragraph_1618065446585_1604783144","id":"20200120-021127_1045532948","dateCreated":"2021-04-10T07:37:26-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:390767","dateFinished":"2021-04-10T07:50:59-0700","dateStarted":"2021-04-10T07:50:58-0700"},{"title":"1 - Upload the devicestatus.txt file to HDFS","text":"%sh\n\n","user":"anonymous","dateUpdated":"2021-04-10T07:51:06-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1618065446586_-560331107","id":"20200120-021126_2118624277","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390768"},{"text":"%md\nIn order to clean up  the data, you will have to perform the following tasks:\n\n* Determine which delimiter to use (the 20th character—position 19—is the first use of the delimiter).\n* Filter out any records which do not parse correctly (hint: each record should have exactly 14 values).\n* Extract the date (first field), model (second field), device ID (third field), and latitude and longitude (13th and 14th fields respectively).","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>In order to clean up  the data, you will have to perform the following tasks:</p>\n<ul>\n<li>Determine which delimiter to use (the 20th character—position 19—is the first use of the delimiter).</li>\n<li>Filter out any records which do not parse correctly (hint: each record should have exactly 14 values).</li>\n<li>Extract the date (first field), model (second field), device ID (third field), and latitude and longitude (13th and 14th fields respectively).</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1618065446587_-1968977703","id":"20200120-022616_1171418589","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390769"},{"title":"2 - Clean up  the data","text":"%pyspark\n\n","user":"anonymous","dateUpdated":"2021-04-10T07:51:23-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1618065446588_1614832503","id":"20200120-022211_1079196563","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390770"},{"text":"%md\nThe second field contains the device manufacturer and model name (such as Ronin S2). Split this field by spaces to separate the manufacturer from the model \n(for example, manufacturer Ronin, model S2). Keep just the manufacturer name.","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>The second field contains the device manufacturer and model name (such as Ronin S2). Split this field by spaces to separate the manufacturer from the model\n<br  />(for example, manufacturer Ronin, model S2). Keep just the manufacturer name.</p>\n"}]},"apps":[],"jobName":"paragraph_1618065446588_-944616763","id":"20200120-023344_707527528","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390771"},{"title":"3 - Create a new RDD containing date, manufacturer, device ID, latitude and longitude","text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-04-10T07:51:28-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1618065446589_1983453039","id":"20200120-023314_452836886","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390772"},{"title":"4 - Save the extracted data to comma-delimited text files in the /devsh_loudacre/devicestatus_etl directory on HDFS","text":"%pyspark\n\n","user":"anonymous","dateUpdated":"2021-04-10T07:51:33-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1618065446590_-1781176871","id":"20200120-023503_1615260981","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390773"},{"text":"%md\nThe lines in the file should all look similar to this, with all fields delimited by commas.\n```pyspark\n 2014-03-15:10:10:20,Sorrento,8cc3b47e-bd01-4482- b500-28f2342679af,33.6894754264,-117.543308253\n```","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>The lines in the file should all look similar to this, with all fields delimited by commas.</p>\n<pre><code class=\"pyspark\"> 2014-03-15:10:10:20,Sorrento,8cc3b47e-bd01-4482- b500-28f2342679af,33.6894754264,-117.543308253\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1618065446590_-1742177874","id":"20200120-023848_1552432120","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390774"},{"title":"5 - Confirm that the data in the file(s) was saved correctly.","text":"%sh\n\n","user":"anonymous","dateUpdated":"2021-04-10T07:51:47-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1618065446591_-1717782494","id":"20200120-023845_483737466","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390775"},{"text":"%md\n### Convert Multi-line XML files to CSV files\nOne of the common uses for RDDs in core Spark is to transform data from unstructured or semi-structured sources or formats that are not supported by Spark \nSQL to structured formats you can use with Spark SQL. In this bonus exercise, you will convert a set of whole-file XML records to a CSV file that can be \nread into a DataFrame. Review the data on the local Linux filesystem in the directory /home/training/training_materials/devsh/data/activations. Each XML \nfile contains data for all the devices activated by customers during a specific month.\nSample input data:\n```xml\n<activations>\n<activation timestamp=\"1225499258\" type=\"phone\">\n<account-number>316</account-number>\n<device-id> d61b6971-33e1-42f0-bb15-aa2ae3cd8680\n</device-id> <phone-number>5108307062</phone-number> <model>iFruit 1</model>\n   </activation>\n...\n</activations>\n```","user":"anonymous","dateUpdated":"2021-04-10T07:51:55-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Convert Multi-line XML files to CSV files</h3>\n<p>One of the common uses for RDDs in core Spark is to transform data from unstructured or semi-structured sources or formats that are not supported by Spark\n<br  />SQL to structured formats you can use with Spark SQL. In this bonus exercise, you will convert a set of whole-file XML records to a CSV file that can be\n<br  />read into a DataFrame. Review the data on the local Linux filesystem in the directory /home/training/training_materials/devsh/data/activations. Each XML\n<br  />file contains data for all the devices activated by customers during a specific month.\n<br  />Sample input data:</p>\n<pre><code class=\"xml\">&lt;activations&gt;\n&lt;activation timestamp=\"1225499258\" type=\"phone\"&gt;\n&lt;account-number&gt;316&lt;/account-number&gt;\n&lt;device-id&gt; d61b6971-33e1-42f0-bb15-aa2ae3cd8680\n&lt;/device-id&gt; &lt;phone-number&gt;5108307062&lt;/phone-number&gt; &lt;model&gt;iFruit 1&lt;/model&gt;\n   &lt;/activation&gt;\n...\n&lt;/activations&gt;\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1618065446592_1491916093","id":"20200120-024539_1586366154","dateCreated":"2021-04-10T07:37:26-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:390776","dateFinished":"2021-04-10T07:51:55-0700","dateStarted":"2021-04-10T07:51:55-0700"},{"title":"6 - Copy the entire activations directory to /devsh_loudacre in HDFS","text":"%sh\n\n","user":"anonymous","dateUpdated":"2021-04-10T07:52:30-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1618065446593_354598195","id":"20200120-024955_1346939274","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390777"},{"text":"%md\nCopy and paste the following code in the cell below to define convenience functions\n```pyspark\nimport xml.etree.ElementTree as ElementTree\n\n# Given a string containing XML, parse the string, and \n# return an iterator of activation XML records (Elements) contained in the string\n\ndef getActivations(s):\n    filetree = ElementTree.fromstring(s)\n    return filetree.getiterator('activation')\n    \n# Given an activation record (XML Element), return the model name\ndef getModel(activation):\n    return activation.find('model').text \n\n# Given an activation record (XML Element), return the account number \ndef getAccount(activation):\n    return activation.find('account-number').text \n```","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Copy and paste the following code in the cell below to define convenience functions</p>\n<pre><code class=\"pyspark\">import xml.etree.ElementTree as ElementTree\n\n# Given a string containing XML, parse the string, and \n# return an iterator of activation XML records (Elements) contained in the string\n\ndef getActivations(s):\n    filetree = ElementTree.fromstring(s)\n    return filetree.getiterator('activation')\n\n# Given an activation record (XML Element), return the model name\ndef getModel(activation):\n    return activation.find('model').text \n\n# Given an activation record (XML Element), return the account number \ndef getAccount(activation):\n    return activation.find('account-number').text \n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1618065446593_1976583218","id":"20200120-025508_282291001","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390778"},{"title":"7 - Define convenience functions","text":"%pyspark\n\n","user":"anonymous","dateUpdated":"2021-04-10T07:52:37-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1618065446594_1961883075","id":"20200120-025800_726122067","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390779"},{"text":"%md\nUse wholeTextFiles to create an RDD from the activations dataset. The resulting RDD will consist of tuples, in which the first value is the name of the \nfile, and the second value is the contents of the file (XML) as a string.","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Use wholeTextFiles to create an RDD from the activations dataset. The resulting RDD will consist of tuples, in which the first value is the name of the\n<br  />file, and the second value is the contents of the file (XML) as a string.</p>\n"}]},"apps":[],"jobName":"paragraph_1618065446595_120540109","id":"20200120-030018_1588727125","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390780"},{"title":"8 - Use wholeTextFiles to create an RDD from the activations dataset","text":"%pyspark\n\n","user":"anonymous","dateUpdated":"2021-04-10T07:52:42-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1618065446595_-356622900","id":"20200120-030100_1582491897","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390781"},{"text":"%md\nEach XML file can contain many activation records; use flatMap to map the contents of each file to a collection of XML records by calling the provided \n`getActivations` function. getActivations takes an XML string, parses it, and returns a collection of XML records; flatMap maps each record to a separate \nRDD element.","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Each XML file can contain many activation records; use flatMap to map the contents of each file to a collection of XML records by calling the provided\n<br  /><code>getActivations</code> function. getActivations takes an XML string, parses it, and returns a collection of XML records; flatMap maps each record to a separate\n<br  />RDD element.</p>\n"}]},"apps":[],"jobName":"paragraph_1618065446596_973115207","id":"20200120-030327_385020183","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390782"},{"title":"9 - Parse each file (as a string) into a collection of activation XML records","text":"%pyspark\n\n","user":"anonymous","dateUpdated":"2021-04-10T07:52:47-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1618065446597_281119422","id":"20200120-030432_330347850","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390783"},{"text":"%md\nMap each activation record to a string in the format account-number:model. Use the provided getAccount and getModel functions to find the values from the \nactivation record.","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Map each activation record to a string in the format account-number:model. Use the provided getAccount and getModel functions to find the values from the\n<br  />activation record.</p>\n"}]},"apps":[],"jobName":"paragraph_1618065446597_1066277646","id":"20200120-030631_196413858","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390784"},{"title":"10 - Map each activation record to a string in the format account-number:model","text":"%pyspark\n\n","user":"anonymous","dateUpdated":"2021-04-10T07:52:51-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1618065446598_1840640006","id":"20200120-030628_952569635","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390785"},{"title":"11 - Save the formatted strings to a text file in the directory /devsh_loudacre/ account-models","text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-04-10T07:53:01-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1618065446599_-2063848555","id":"20200120-030852_1771925889","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390786"},{"text":"%md\n# Result\n**You have now:** \n\n* loaded a simple text file into a Resilient Distributed Dataset (RDD),\n* created an RDD based on Loudacre’s website log data and \n* practiced transforming the data.\n\n---","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Result</h1>\n<p><strong>You have now:</strong></p>\n<ul>\n<li>loaded a simple text file into a Resilient Distributed Dataset (RDD),</li>\n<li>created an RDD based on Loudacre’s website log data and</li>\n<li>practiced transforming the data.</li>\n</ul>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1618065446599_-1656560952","id":"20181119-142716_792318228","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390787"},{"text":"%md\n# Solution\n---","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Solution</h1>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1618065446600_-249321301","id":"20171113-155535_1769142099","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390788"},{"text":"%md\n### Clean Device Status Data\nIf you have more time, attempt this extra bonus exercise.\n\nOne common use of core Spark RDDs is data scrubbing—converting the data into a format that can be used in Spark SQL. In this bonus exercise, you will process \ndata in order to get it into a standardized format for later processing.\n\nReview the contents of the file `/home/training/training_materials/devsh/data/devicestatus.txt`. This file contains data collected from mobile devices on \nLoudacre’s network, including device ID, current status, location, and so on. \n\nBecause Loudacre previously acquired other mobile providers’ networks, the data from different subnetworks has different formats. \nNote that the records in this file have different field delimiters: some use commas, some use pipes (|), and so on. \n```pyspark\n2014-03-15:10:10:33,Ronin S2,1a7eca8d-60c9-4d25-8609-d6cfd1ac80a1,0,24,82,72,enabled,enabled,enabled,41,62,36.49259162,-121.003629078\n2014-03-15:10:10:33/Titanic 2300/d86dbb9d-ff3c-40c6-8685-01f1fac45d9f/59/83/9/3/28/0/enabled/disabled/enabled/34.3456792864/-117.768326105\n```\n\n","user":"anonymous","dateUpdated":"2021-04-10T07:56:51-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Clean Device Status Data</h3>\n<p>If you have more time, attempt this extra bonus exercise.</p>\n<p>One common use of core Spark RDDs is data scrubbing—converting the data into a format that can be used in Spark SQL. In this bonus exercise, you will process\n<br  />data in order to get it into a standardized format for later processing.</p>\n<p>Review the contents of the file <code>/home/training/training_materials/devsh/data/devicestatus.txt</code>. This file contains data collected from mobile devices on\n<br  />Loudacre’s network, including device ID, current status, location, and so on.</p>\n<p>Because Loudacre previously acquired other mobile providers’ networks, the data from different subnetworks has different formats.\n<br  />Note that the records in this file have different field delimiters: some use commas, some use pipes (|), and so on.</p>\n<pre><code class=\"pyspark\">2014-03-15:10:10:33,Ronin S2,1a7eca8d-60c9-4d25-8609-d6cfd1ac80a1,0,24,82,72,enabled,enabled,enabled,41,62,36.49259162,-121.003629078\n2014-03-15:10:10:33/Titanic 2300/d86dbb9d-ff3c-40c6-8685-01f1fac45d9f/59/83/9/3/28/0/enabled/disabled/enabled/34.3456792864/-117.768326105\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1618065446623_1232860476","id":"20210121-200300_604174406","dateCreated":"2021-04-10T07:37:26-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:390826","dateFinished":"2021-04-10T07:56:51-0700","dateStarted":"2021-04-10T07:56:51-0700"},{"title":"1 - Upload the devicestatus.txt file to HDFS","text":"%sh\n\nhdfs dfs -rm -r -skipTrash /devsh_loudacre/devicestatus.txt\nhdfs dfs -put /home/training/training_materials/devsh/data/devicestatus.txt /devsh_loudacre\nhdfs dfs -ls /devsh_loudacre/","user":"anonymous","dateUpdated":"2021-04-10T07:57:03-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Deleted /devsh_loudacre/devicestatus.txt\nFound 10 items\ndrwxr-xr-x   - zeppelin supergroup          0 2021-03-30 14:13 /devsh_loudacre/accountdevice\ndrwxr-xr-x   - livy     supergroup          0 2021-03-30 11:44 /devsh_loudacre/accounts_zip94913\n-rw-r--r--   3 zeppelin supergroup       5483 2021-03-30 09:01 /devsh_loudacre/devices.json\ndrwxr-xr-x   - livy     supergroup          0 2021-03-30 12:17 /devsh_loudacre/devices_parquet\n-rw-r--r--   3 zeppelin supergroup   13954723 2021-03-31 11:52 /devsh_loudacre/devicestatus.txt\n-rw-r--r--   3 zeppelin supergroup        730 2021-03-31 09:45 /devsh_loudacre/frostroad.txt\ndrwxr-xr-x   - livy     supergroup          0 2021-03-31 10:28 /devsh_loudacre/iplist\ndrwxr-xr-x   - livy     supergroup          0 2021-03-30 14:32 /devsh_loudacre/top_devices\ndrwxr-xr-x   - livy     supergroup          0 2021-03-31 10:37 /devsh_loudacre/userips_csv\ndrwxr-xr-x   - zeppelin supergroup          0 2021-03-31 09:56 /devsh_loudacre/weblogs\n"}]},"apps":[],"jobName":"paragraph_1618065446623_1701818395","id":"20200120-021351_26802562","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390827"},{"title":"2 - Clean the device status data","text":"%pyspark\n\n# Load the data file\ndevstatus = sc.textFile(\"/devsh_loudacre/devicestatus.txt\")\n\n# Filter out lines with < 20 characters, use the 20th character as the delimiter, parse the line, and filter out bad lines\ncleanstatus = devstatus.filter(lambda line: len(line) > 20).map(lambda line: line.split(line[19:20])).filter(lambda values: len(values) == 14)","user":"anonymous","dateUpdated":"2021-04-10T07:57:12-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<font color=\"red\">Previous livy session is expired, new livy session is created. Paragraphs that depend on this paragraph need to be re-executed!</font>"}]},"apps":[],"jobName":"paragraph_1618065446624_1696027468","id":"20200120-022239_42556740","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390828"},{"text":"%md\nIn order to clean up  the data, you will have to perform the following tasks:\n\n* Determine which delimiter to use (the 20th character—position 19—is the first use of the delimiter).\n* Filter out any records which do not parse correctly (hint: each record should have exactly 14 values).\n* Extract the date (first field), model (second field), device ID (third field), and latitude and longitude (13th and 14th fields respectively).\n","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>In order to clean up  the data, you will have to perform the following tasks:</p>\n<ul>\n<li>Determine which delimiter to use (the 20th character—position 19—is the first use of the delimiter).</li>\n<li>Filter out any records which do not parse correctly (hint: each record should have exactly 14 values).</li>\n<li>Extract the date (first field), model (second field), device ID (third field), and latitude and longitude (13th and 14th fields respectively).</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1618065446624_-1387401861","id":"20210121-200453_372024787","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390829"},{"title":"3 - Create a new RDD containing date, manufacturer, device ID, latitude and longitude","text":"%pyspark\n\n# Create a new RDD containing date, manufacturer, device ID, latitude and longitude\ndevicedata = cleanstatus.map(lambda values: (values[0], values[1].split(' ')[0], values[2], values[12], values[13]))","user":"anonymous","dateUpdated":"2021-04-10T07:57:18-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1618065446625_1772964963","id":"20200120-023138_511337312","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390830"},{"text":"%md\nThe second field contains the device manufacturer and model name (such as Ronin S2). Split this field by spaces to separate the manufacturer from the model \n(for example, manufacturer Ronin, model S2). Keep just the manufacturer name.\n","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>The second field contains the device manufacturer and model name (such as Ronin S2). Split this field by spaces to separate the manufacturer from the model\n<br  />(for example, manufacturer Ronin, model S2). Keep just the manufacturer name.</p>\n"}]},"apps":[],"jobName":"paragraph_1618065446625_-211664879","id":"20210121-200700_2136882845","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390831"},{"title":"4 - Save the extracted data to comma-delimited text files in the /devsh_loudacre/devicestatus_etl directory on HDFS","text":"%pyspark\n\nsc.setJobGroup(\"Transforming data with RDDs\",\"Save to a CSV file as a comma-delimited string\")\ndevicedata.map(lambda values: ','.join(values)).saveAsTextFile(\"/devsh_loudacre/devicestatus_etl\")","user":"anonymous","dateUpdated":"2021-04-10T07:57:22-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1618065446626_-1961373098","id":"20200120-023531_1129507359","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390832"},{"title":"5 - Confirm that the data in the file(s) was saved correctly.","text":"%sh\n\nhdfs dfs -ls -h /devsh_loudacre/devicestatus_etl\n","user":"anonymous","dateUpdated":"2021-04-10T07:57:46-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Found 3 items\n-rw-r--r--   3 livy supergroup          0 2021-03-31 12:01 /devsh_loudacre/devicestatus_etl/_SUCCESS\n-rw-r--r--   3 livy supergroup      4.4 M 2021-03-31 12:01 /devsh_loudacre/devicestatus_etl/part-00000\n-rw-r--r--   3 livy supergroup      4.4 M 2021-03-31 12:01 /devsh_loudacre/devicestatus_etl/part-00001\n"}]},"apps":[],"jobName":"paragraph_1618065446626_-479198459","id":"20200120-024106_1698475884","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390833"},{"text":"%sh\n\nhdfs dfs -head /devsh_loudacre/devicestatus_etl/part-00000\n","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"2014-03-15:10:10:20,Sorrento,8cc3b47e-bd01-4482-b500-28f2342679af,33.6894754264,-117.543308253\n2014-03-15:10:10:20,MeeToo,ef8c7564-0a1a-4650-a655-c8bbd5f8f943,37.4321088904,-121.485029632\n2014-03-15:10:10:20,MeeToo,23eba027-b95a-4729-9a4b-a3cca51c5548,39.4378908349,-120.938978486\n2014-03-15:10:10:20,Sorrento,707daba1-5640-4d60-a6d9-1d6fa0645be0,39.3635186767,-119.400334708\n2014-03-15:10:10:20,Ronin,db66fe81-aa55-43b4-9418-fc6e7a00f891,33.1913581092,-116.448242643\n2014-03-15:10:10:20,Sorrento,ffa18088-69a0-433e-84b8-006b2b9cc1d0,33.8343543748,-117.330000857\n2014-03-15:10:10:20,Sorrento,66d678e6-9c87-48d2-a415-8d5035e54a23,37.3803954321,-121.840756755\n2014-03-15:10:10:20,MeeToo,673f7e4b-d52b-44fc-8826-aea460c3481a,34.1841062345,-117.9435329\n2014-03-15:10:10:20,Ronin,a678ccc3-b0d2-452d-bf89-85bd095e28ee,32.2850556785,-111.819583734\n2014-03-15:10:10:20,Sorrento,86bef6ae-2f1c-42ec-aa67-6acecd7b0675,45.2400522984,-122.377467861\n2014-03-15:10:10:20,iFruit,27178d24-3a61-42f7-a784-e3263f25cc6f,37.9248961741,-122.20686"}]},"apps":[],"jobName":"paragraph_1618065446627_1605547030","id":"20210129-192738_1127775813","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390834"},{"text":"%md\nThe lines in the file should all look similar to this, with all fields delimited by commas.\n```pyspark\n 2014-03-15:10:10:20,Sorrento,8cc3b47e-bd01-4482- b500-28f2342679af,33.6894754264,-117.543308253\n```\n","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>The lines in the file should all look similar to this, with all fields delimited by commas.</p>\n<pre><code class=\"pyspark\"> 2014-03-15:10:10:20,Sorrento,8cc3b47e-bd01-4482- b500-28f2342679af,33.6894754264,-117.543308253\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1618065446627_-967443720","id":"20210121-200803_1047825580","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390835"},{"text":"%md\n### Convert Multi-line XML files to CSV files\nOne of the common uses for RDDs in core Spark is to transform data from unstructured or semi-structured sources or formats that are not supported by Spark \nSQL to structured formats you can use with Spark SQL. In this exercise, you will convert a set of whole-file XML records to a CSV file that can be read into \na DataFrame. Review the data on the local Linux filesystem in the directory /home/training/training_materials/devsh/data/activations. Each XML file contains \ndata for all the devices activated by customers during a specific month. Sample input data:\n```xml\n<activations>\n<activation timestamp=\"1225499258\" type=\"phone\">\n<account-number>316</account-number>\n<device-id> d61b6971-33e1-42f0-bb15-aa2ae3cd8680</device-id> \n<phone-number>5108307062</phone-number> \n<model>iFruit 1</model>\n   </activation>\n...\n</activations>\n```\n","user":"anonymous","dateUpdated":"2021-04-10T07:58:05-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Convert Multi-line XML files to CSV files</h3>\n<p>One of the common uses for RDDs in core Spark is to transform data from unstructured or semi-structured sources or formats that are not supported by Spark\n<br  />SQL to structured formats you can use with Spark SQL. In this exercise, you will convert a set of whole-file XML records to a CSV file that can be read into\n<br  />a DataFrame. Review the data on the local Linux filesystem in the directory /home/training/training_materials/devsh/data/activations. Each XML file contains\n<br  />data for all the devices activated by customers during a specific month. Sample input data:</p>\n<pre><code class=\"xml\">&lt;activations&gt;\n&lt;activation timestamp=\"1225499258\" type=\"phone\"&gt;\n&lt;account-number&gt;316&lt;/account-number&gt;\n&lt;device-id&gt; d61b6971-33e1-42f0-bb15-aa2ae3cd8680&lt;/device-id&gt; \n&lt;phone-number&gt;5108307062&lt;/phone-number&gt; \n&lt;model&gt;iFruit 1&lt;/model&gt;\n   &lt;/activation&gt;\n...\n&lt;/activations&gt;\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1618065446628_-1621583438","id":"20210121-200905_1197593010","dateCreated":"2021-04-10T07:37:26-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:390836","dateFinished":"2021-04-10T07:58:05-0700","dateStarted":"2021-04-10T07:58:05-0700"},{"title":"6 - Copy the entire activations directory to /devsh_loudacre in HDFS","text":"%sh\n\nhdfs dfs -rm -r -skipTrash /devsh_loudacre/activations\nhdfs dfs -put /home/training/training_materials/devsh/data/activations /devsh_loudacre\nhdfs dfs -ls /devsh_loudacre/activations","user":"anonymous","dateUpdated":"2021-04-10T07:58:45-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rm: `/devsh_loudacre/activations': No such file or directory\nFound 66 items\n-rw-r--r--   3 zeppelin supergroup      19044 2021-03-31 12:23 /devsh_loudacre/activations/2008-10.xml\n-rw-r--r--   3 zeppelin supergroup      73748 2021-03-31 12:23 /devsh_loudacre/activations/2008-11.xml\n-rw-r--r--   3 zeppelin supergroup      68764 2021-03-31 12:23 /devsh_loudacre/activations/2008-12.xml\n-rw-r--r--   3 zeppelin supergroup      90337 2021-03-31 12:23 /devsh_loudacre/activations/2009-01.xml\n-rw-r--r--   3 zeppelin supergroup      67655 2021-03-31 12:23 /devsh_loudacre/activations/2009-02.xml\n-rw-r--r--   3 zeppelin supergroup      86243 2021-03-31 12:23 /devsh_loudacre/activations/2009-03.xml\n-rw-r--r--   3 zeppelin supergroup      82718 2021-03-31 12:23 /devsh_loudacre/activations/2009-04.xml\n-rw-r--r--   3 zeppelin supergroup      90148 2021-03-31 12:23 /devsh_loudacre/activations/2009-05.xml\n-rw-r--r--   3 zeppelin supergroup      88713 2021-03-31 12:23 /devsh_loudacre/activations/2009-06.xml\n-rw-r--r--   3 zeppelin supergroup      86835 2021-03-31 12:23 /devsh_loudacre/activations/2009-07.xml\n-rw-r--r--   3 zeppelin supergroup      79114 2021-03-31 12:23 /devsh_loudacre/activations/2009-08.xml\n-rw-r--r--   3 zeppelin supergroup      83012 2021-03-31 12:23 /devsh_loudacre/activations/2009-09.xml\n-rw-r--r--   3 zeppelin supergroup      91007 2021-03-31 12:23 /devsh_loudacre/activations/2009-10.xml\n-rw-r--r--   3 zeppelin supergroup      93132 2021-03-31 12:23 /devsh_loudacre/activations/2009-11.xml\n-rw-r--r--   3 zeppelin supergroup      96328 2021-03-31 12:23 /devsh_loudacre/activations/2009-12.xml\n-rw-r--r--   3 zeppelin supergroup     192394 2021-03-31 12:23 /devsh_loudacre/activations/2010-01.xml\n-rw-r--r--   3 zeppelin supergroup     191631 2021-03-31 12:23 /devsh_loudacre/activations/2010-02.xml\n-rw-r--r--   3 zeppelin supergroup     200690 2021-03-31 12:23 /devsh_loudacre/activations/2010-03.xml\n-rw-r--r--   3 zeppelin supergroup     200510 2021-03-31 12:23 /devsh_loudacre/activations/2010-04.xml\n-rw-r--r--   3 zeppelin supergroup     227033 2021-03-31 12:23 /devsh_loudacre/activations/2010-05.xml\n-rw-r--r--   3 zeppelin supergroup     235350 2021-03-31 12:23 /devsh_loudacre/activations/2010-06.xml\n-rw-r--r--   3 zeppelin supergroup     230267 2021-03-31 12:23 /devsh_loudacre/activations/2010-07.xml\n-rw-r--r--   3 zeppelin supergroup     241761 2021-03-31 12:23 /devsh_loudacre/activations/2010-08.xml\n-rw-r--r--   3 zeppelin supergroup     234168 2021-03-31 12:23 /devsh_loudacre/activations/2010-09.xml\n-rw-r--r--   3 zeppelin supergroup     237083 2021-03-31 12:23 /devsh_loudacre/activations/2010-10.xml\n-rw-r--r--   3 zeppelin supergroup     209493 2021-03-31 12:23 /devsh_loudacre/activations/2010-11.xml\n-rw-r--r--   3 zeppelin supergroup     235910 2021-03-31 12:23 /devsh_loudacre/activations/2010-12.xml\n-rw-r--r--   3 zeppelin supergroup     441580 2021-03-31 12:23 /devsh_loudacre/activations/2011-01.xml\n-rw-r--r--   3 zeppelin supergroup     421089 2021-03-31 12:23 /devsh_loudacre/activations/2011-02.xml\n-rw-r--r--   3 zeppelin supergroup     472902 2021-03-31 12:23 /devsh_loudacre/activations/2011-03.xml\n-rw-r--r--   3 zeppelin supergroup     456871 2021-03-31 12:23 /devsh_loudacre/activations/2011-04.xml\n-rw-r--r--   3 zeppelin supergroup     466384 2021-03-31 12:23 /devsh_loudacre/activations/2011-05.xml\n-rw-r--r--   3 zeppelin supergroup     454844 2021-03-31 12:23 /devsh_loudacre/activations/2011-06.xml\n-rw-r--r--   3 zeppelin supergroup     466854 2021-03-31 12:23 /devsh_loudacre/activations/2011-07.xml\n-rw-r--r--   3 zeppelin supergroup     483014 2021-03-31 12:23 /devsh_loudacre/activations/2011-08.xml\n-rw-r--r--   3 zeppelin supergroup     464367 2021-03-31 12:23 /devsh_loudacre/activations/2011-09.xml\n-rw-r--r--   3 zeppelin supergroup     500909 2021-03-31 12:23 /devsh_loudacre/activations/2011-10.xml\n-rw-r--r--   3 zeppelin supergroup     477224 2021-03-31 12:23 /devsh_loudacre/activations/2011-11.xml\n-rw-r--r--   3 zeppelin supergroup     506646 2021-03-31 12:23 /devsh_loudacre/activations/2011-12.xml\n-rw-r--r--   3 zeppelin supergroup     979534 2021-03-31 12:23 /devsh_loudacre/activations/2012-01.xml\n-rw-r--r--   3 zeppelin supergroup     945789 2021-03-31 12:23 /devsh_loudacre/activations/2012-02.xml\n-rw-r--r--   3 zeppelin supergroup    1010401 2021-03-31 12:23 /devsh_loudacre/activations/2012-03.xml\n-rw-r--r--   3 zeppelin supergroup     994863 2021-03-31 12:23 /devsh_loudacre/activations/2012-04.xml\n-rw-r--r--   3 zeppelin supergroup    1005624 2021-03-31 12:23 /devsh_loudacre/activations/2012-05.xml\n-rw-r--r--   3 zeppelin supergroup     957156 2021-03-31 12:23 /devsh_loudacre/activations/2012-06.xml\n-rw-r--r--   3 zeppelin supergroup    1028510 2021-03-31 12:23 /devsh_loudacre/activations/2012-07.xml\n-rw-r--r--   3 zeppelin supergroup    1055421 2021-03-31 12:23 /devsh_loudacre/activations/2012-08.xml\n-rw-r--r--   3 zeppelin supergroup    1003936 2021-03-31 12:23 /devsh_loudacre/activations/2012-09.xml\n-rw-r--r--   3 zeppelin supergroup    1066257 2021-03-31 12:23 /devsh_loudacre/activations/2012-10.xml\n-rw-r--r--   3 zeppelin supergroup    1000719 2021-03-31 12:23 /devsh_loudacre/activations/2012-11.xml\n-rw-r--r--   3 zeppelin supergroup    1045239 2021-03-31 12:23 /devsh_loudacre/activations/2012-12.xml\n-rw-r--r--   3 zeppelin supergroup    1081374 2021-03-31 12:23 /devsh_loudacre/activations/2013-01.xml\n-rw-r--r--   3 zeppelin supergroup     984057 2021-03-31 12:23 /devsh_loudacre/activations/2013-02.xml\n-rw-r--r--   3 zeppelin supergroup    1115803 2021-03-31 12:23 /devsh_loudacre/activations/2013-03.xml\n-rw-r--r--   3 zeppelin supergroup    1079565 2021-03-31 12:23 /devsh_loudacre/activations/2013-04.xml\n-rw-r--r--   3 zeppelin supergroup    1092603 2021-03-31 12:23 /devsh_loudacre/activations/2013-05.xml\n-rw-r--r--   3 zeppelin supergroup    1066438 2021-03-31 12:23 /devsh_loudacre/activations/2013-06.xml\n-rw-r--r--   3 zeppelin supergroup    1133909 2021-03-31 12:23 /devsh_loudacre/activations/2013-07.xml\n-rw-r--r--   3 zeppelin supergroup    1137010 2021-03-31 12:23 /devsh_loudacre/activations/2013-08.xml\n-rw-r--r--   3 zeppelin supergroup    1059769 2021-03-31 12:23 /devsh_loudacre/activations/2013-09.xml\n-rw-r--r--   3 zeppelin supergroup    1132497 2021-03-31 12:23 /devsh_loudacre/activations/2013-10.xml\n-rw-r--r--   3 zeppelin supergroup    6816957 2021-03-31 12:23 /devsh_loudacre/activations/2013-11.xml\n-rw-r--r--   3 zeppelin supergroup    3734204 2021-03-31 12:23 /devsh_loudacre/activations/2013-12.xml\n-rw-r--r--   3 zeppelin supergroup    3516581 2021-03-31 12:23 /devsh_loudacre/activations/2014-01.xml\n-rw-r--r--   3 zeppelin supergroup    2878103 2021-03-31 12:23 /devsh_loudacre/activations/2014-02.xml\n-rw-r--r--   3 zeppelin supergroup    1316093 2021-03-31 12:23 /devsh_loudacre/activations/2014-03.xml\n"}]},"apps":[],"jobName":"paragraph_1618065446629_-295964775","id":"20200120-025020_1285199608","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390837"},{"text":"%sh\nhdfs dfs -head /devsh_loudacre/activations/2008-10.xml","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"<activations>\n\t  <activation timestamp=\"1225462088\" type=\"phone\">\n\t    <account-number>9763</account-number>\n\t    <device-id>debea35e-3ecd-4ee7-b0dd-ad428d953f32</device-id>\n\t    <phone-number>7600763387</phone-number>\n\t    <model>MeeToo 1.0</model>\n\t  </activation>\n\t  \t\t  <activation timestamp=\"1225461447\" type=\"phone\">\n\t    <account-number>426</account-number>\n\t    <device-id>38a1566d-524e-4137-bad8-b597d09b54b0</device-id>\n\t    <phone-number>5102521038</phone-number>\n\t    <model>Titanic 1000</model>\n\t  </activation>\n\t  \t\t  <activation timestamp=\"1225446947\" type=\"phone\">\n\t    <account-number>383</account-number>\n\t    <device-id>513024a3-a828-4674-9ff6-041e9a851f18</device-id>\n\t    <phone-number>9162206560</phone-number>\n\t    <model>Sorrento F00L</model>\n\t  </activation>\n\t  \t\t  <activation timestamp=\"1225445908\" type=\"phone\">\n\t    <account-number>404</account-number>\n\t    <device-id>93d7d0eb-7551-4e11-ab59-91f34c04378f</device-id>\n\t    <phone-number>6506862748</phone-number>\n\t    <model>MeeToo 1.0</model>\n\t"}]},"apps":[],"jobName":"paragraph_1618065446629_1086111563","id":"20210123-142203_648237880","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390838"},{"title":"7 - Define convenience functions","text":"%pyspark\n\nimport xml.etree.ElementTree as ElementTree\n\n# Given a string containing XML, parse the string, and \n# return an iterator of activation XML records (Elements) contained in the string\n\ndef getActivations(s):\n    filetree = ElementTree.fromstring(s)\n    return filetree.getiterator('activation')\n    \n# Given an activation record (XML Element), return the model name\ndef getModel(activation):\n    return activation.find('model').text \n\n# Given an activation record (XML Element), return the account number \ndef getAccount(activation):\n    return activation.find('account-number').text \n","user":"anonymous","dateUpdated":"2021-04-10T07:58:30-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1618065446630_673645499","id":"20200120-025849_1625267335","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390839"},{"text":"%md\n#### Defining functions\nPython can create a function to help programmers break a program intoo smaller and more modular, more organized, and more manageable program.\nSyntax\n    def function_name(parameters):\n        \"\"\"docstring\"\"\"\n        statement(s)\n        \nThe keyword is def. The function name must be unique. A colon (:) marks the end of the function header. The docsttring is optional. One or more valid \nPython statements make up the function. All statements must have the same indentation. An optional return statementt to return a value from the function.\n","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Defining functions</h4>\n<p>Python can create a function to help programmers break a program intoo smaller and more modular, more organized, and more manageable program.\n<br  />Syntax</p>\n<pre><code>def function_name(parameters):\n    \"\"\"docstring\"\"\"\n    statement(s)\n</code></pre>\n<p>The keyword is def. The function name must be unique. A colon (:) marks the end of the function header. The docsttring is optional. One or more valid\n<br  />Python statements make up the function. All statements must have the same indentation. An optional return statementt to return a value from the function.</p>\n"}]},"apps":[],"jobName":"paragraph_1618065446630_-2014226917","id":"20210123-135713_537762701","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390840"},{"text":"%md\nCopy and paste this code in the cell below to define convenience functions\n\n```pyspark\nimport xml.etree.ElementTree as ElementTree\n\n# Given a string containing XML, parse the string, and \n# return an iterator of activation XML records (Elements) contained in the string\n\ndef getActivations(s):\n    filetree = ElementTree.fromstring(s)\n    return filetree.getiterator('activation')\n    \n# Given an activation record (XML Element), return the model name\ndef getModel(activation):\n    return activation.find('model').text \n\n# Given an activation record (XML Element), return the account number \ndef getAccount(activation):\n    return activation.find('account-number').text \n```\n","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Copy and paste this code in the cell below to define convenience functions</p>\n<pre><code class=\"pyspark\">import xml.etree.ElementTree as ElementTree\n\n# Given a string containing XML, parse the string, and \n# return an iterator of activation XML records (Elements) contained in the string\n\ndef getActivations(s):\n    filetree = ElementTree.fromstring(s)\n    return filetree.getiterator('activation')\n\n# Given an activation record (XML Element), return the model name\ndef getModel(activation):\n    return activation.find('model').text \n\n# Given an activation record (XML Element), return the account number \ndef getAccount(activation):\n    return activation.find('account-number').text \n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1618065446631_-1913314977","id":"20210121-201202_1917379932","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390841"},{"title":"8 - Use wholeTextFiles to create an RDD from the activations dataset","text":"%pyspark\n\n# Read XML files into an RDD \nfiles=\"/devsh_loudacre/activations\"\nactivationFiles = sc.wholeTextFiles(files)\n\n# Take 5 activation file rows from the RDD\nsc.setJobGroup(\"Transforming data with RDDs\",\"Take 5 rows from the activationFiles RDD\")\nactivationFilesRows = activationFiles.take(5)\n\n# Display the fields in the rows\nfor row in activationFilesRows:\n    print(\"---------\")\n    # Field is truncated to the first 100 characters to prevent hitting zeppelin output limit\n    for field in row: print(field[0:99])","user":"anonymous","dateUpdated":"2021-04-10T07:59:36-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"---------\nhdfs://localhost.localdomain:8020/devsh_loudacre/activations/2008-10.xml\n<activations>\n\t  <activation timestamp=\"1225462088\" type=\"phone\">\n\t    <account-number>9763</accoun\n---------\nhdfs://localhost.localdomain:8020/devsh_loudacre/activations/2008-11.xml\n<activations>\n\t  <activation timestamp=\"1228068581\" type=\"phone\">\n\t    <account-number>93893</accou\n---------\nhdfs://localhost.localdomain:8020/devsh_loudacre/activations/2008-12.xml\n<activations>\n\t  <activation timestamp=\"1230755877\" type=\"phone\">\n\t    <account-number>179</account\n---------\nhdfs://localhost.localdomain:8020/devsh_loudacre/activations/2009-01.xml\n<activations>\n\t  <activation timestamp=\"1233382836\" type=\"phone\">\n\t    <account-number>1234</accoun\n---------\nhdfs://localhost.localdomain:8020/devsh_loudacre/activations/2009-02.xml\n<activations>\n\t  <activation timestamp=\"1235811351\" type=\"phone\">\n\t    <account-number>1051</accoun"}]},"apps":[],"jobName":"paragraph_1618065446632_-1396043109","id":"20200120-030152_1371790066","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390842"},{"title":"9 - Parse each file (as a string) into a collection of activation XML records","text":"%pyspark\n\nactivationRecords = activationFiles.flatMap(lambda pair: getActivations(pair[1]))\n","user":"anonymous","dateUpdated":"2021-04-10T07:59:49-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1618065446632_1085825204","id":"20200120-030459_712323819","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390843"},{"text":"%md\nThe Spark `map` transformation creates a new RDD after applying the function on every element in the RDD. This transformation always returns the same number \nof elements as input. The Spark `flatMap` transformation also creates a new RDD after applying the function on every element in the RDD. This transformation \ncan have the same count or more number of elements. A common use of `flatMap` is to split records by a space and then flatten the RDD to list of single words.\n","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>The Spark <code>map</code> transformation creates a new RDD after applying the function on every element in the RDD. This transformation always returns the same number\n<br  />of elements as input. The Spark <code>flatMap</code> transformation also creates a new RDD after applying the function on every element in the RDD. This transformation\n<br  />can have the same count or more number of elements. A common use of <code>flatMap</code> is to split records by a space and then flatten the RDD to list of single words.</p>\n"}]},"apps":[],"jobName":"paragraph_1618065446633_1392874108","id":"20210123-140905_373751837","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390844"},{"text":"%md\nEach XML file can contain many activation records; use `flatMap` to map the contents of each file to a collection of XML records by calling the provided \n`getActivations` function. `getActivations` takes an XML string, parses it, and returns a collection of XML records; `flatMap` maps each record to a separate \nRDD element.\n","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Each XML file can contain many activation records; use <code>flatMap</code> to map the contents of each file to a collection of XML records by calling the provided\n<br  /><code>getActivations</code> function. <code>getActivations</code> takes an XML string, parses it, and returns a collection of XML records; <code>flatMap</code> maps each record to a separate\n<br  />RDD element.</p>\n"}]},"apps":[],"jobName":"paragraph_1618065446633_-789334700","id":"20210121-201504_557218695","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390845"},{"title":"10 - Map each activation record to a string in the format account-number:model","text":"%pyspark\n\nmodels = activationRecords.map(lambda record: getAccount(record) + \":\" + getModel(record))","user":"anonymous","dateUpdated":"2021-04-10T07:59:54-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1618065446634_1836208509","id":"20200120-030718_323721915","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390846"},{"text":"%md\nMap each activation record to a string in the format account-number:model. Use the provided `getAccount` and `getModel` functions to find the values from \nthe activation record.\n","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Map each activation record to a string in the format account-number:model. Use the provided <code>getAccount</code> and <code>getModel</code> functions to find the values from\n<br  />the activation record.</p>\n"}]},"apps":[],"jobName":"paragraph_1618065446638_1552669016","id":"20210121-201717_189950136","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390847"},{"title":"11 - Save the formatted strings to a text file in the directory /devsh_loudacre/ account-models","text":"%pyspark\n\nsc.setJobGroup(\"Transforming data with RDDs - Bonus Exercise 2\",\"Save the formatted strings to a text file\")\nmodels.saveAsTextFile(\"/devsh_loudacre/account-models\")","user":"anonymous","dateUpdated":"2021-04-10T08:00:11-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1618065446638_1274115637","id":"20200120-030915_1401739400","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390848"},{"text":"%sh\nhdfs dfs -rm -r -skipTrash /devsh_loudacre/account-models\nhdfs dfs -ls /devsh_loudacre/account-models\n","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Deleted /devsh_loudacre/account-models\nls: `/devsh_loudacre/account-models': No such file or directory\n"},{"type":"TEXT","data":"ExitValue: 1"}]},"apps":[],"jobName":"paragraph_1618065446639_753306781","id":"20210123-142429_1219685940","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390849"},{"text":"%sh\nhdfs dfs -head /devsh_loudacre/account-models/part-00000","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"9763:MeeToo 1.0\n426:Titanic 1000\n383:Sorrento F00L\n404:MeeToo 1.0\n393:iFruit 1\n53:MeeToo 1.0\n96:iFruit 1\n283:Sorrento F00L\n464:MeeToo 1.0\n475:Titanic 1000\n479:iFruit 1\n306:Titanic 1000\n14045:MeeToo 1.0\n6482:Sorrento F00L\n349:MeeToo 1.0\n124:MeeToo 1.0\n247:MeeToo 1.0\n88:Sorrento F00L\n2939:Titanic 1000\n314:MeeToo 1.0\n396:MeeToo 1.0\n6881:MeeToo 1.0\n234:iFruit 1\n34209:Titanic 1000\n369:MeeToo 1.0\n255:iFruit 1\n13:iFruit 1\n142:Titanic 1000\n11:iFruit 1\n61:iFruit 1\n1554:MeeToo 1.0\n165:Titanic 1000\n128224:MeeToo 1.0\n394:MeeToo 1.0\n433:MeeToo 1.0\n448:iFruit 1\n440:Sorrento F00L\n240:MeeToo 1.0\n460:MeeToo 1.0\n275:Sorrento F00L\n4638:Titanic 1000\n171:Titanic 1000\n213:Sorrento F00L\n324:Sorrento F00L\n98121:MeeToo 1.0\n363:iFruit 1\n52:Titanic 1000\n286:iFruit 1\n13702:Titanic 1000\n345:MeeToo 1.0\n36906:Titanic 1000\n413:iFruit 1\n459:Titanic 1000\n144:Sorrento F00L\n373:Titanic 1000\n46849:Sorrento F00L\n252:Titanic 1000\n1:Titanic 1000\n21566:Titanic 1000\n154:Titanic 1000\n46168:iFruit 1\n3838:Titanic 1000\n21821:MeeToo 1.0\n204:iFruit 1\n131:M"}]},"apps":[],"jobName":"paragraph_1618065446639_1757486975","id":"20210123-142455_1526667445","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390850"},{"text":"%md\n# Tear Down\n---","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Tear Down</h1>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1618065446640_1923127361","id":"20200830-194854_838260781","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390851"},{"title":"Delete Livy session","text":"%sh\n\nsessionId=$(curl -s localhost:8998/sessions | jq '.sessions[0].id')\ncurl -s localhost:8998/sessions/$sessionId -X DELETE","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"{\"msg\":\"deleted\"}"}]},"apps":[],"jobName":"paragraph_1618065446640_-1883023167","id":"20200830-195039_518625763","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390852"},{"title":"Additional resources","text":"%md\nWe hope you've enjoyed this lab. Below are additional resources that you should find useful:\n\n1. [Cloudera Tutorials](http://cloudera.com/tutorials.html) are your natural next step where you can explore Spark in more depth.\n2. [Cloudera Community](https://community.cloudera.com) is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.\n3. [Apache Spark Documentation](https://spark.apache.org/documentation.html) - official Spark documentation.\n4. [Apache Zeppelin Project Home Page](https://zeppelin.apache.org) - official Zeppelin web site.\n","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":10,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>We hope you've enjoyed this lab. Below are additional resources that you should find useful:</p>\n<ol>\n<li><a href=\"http://cloudera.com/tutorials.html\">Cloudera Tutorials</a> are your natural next step where you can explore Spark in more depth.</li>\n<li><a href=\"https://community.cloudera.com\">Cloudera Community</a> is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.</li>\n<li><a href=\"https://spark.apache.org/documentation.html\">Apache Spark Documentation</a> - official Spark documentation.</li>\n<li><a href=\"https://zeppelin.apache.org\">Apache Zeppelin Project Home Page</a> - official Zeppelin web site.</li>\n</ol>\n"}]},"apps":[],"jobName":"paragraph_1618065446641_1546599234","id":"20181116-135131_93712280","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390853"},{"text":"%angular\n</br>\n</br>\n</br>\n</br>\n<center>\n<a href=\"https://www.cloudera.com/about/training/courses.html\">\n  <img src=\"https://www.cloudera.com/content/dam/www/marketing/media-kit/logo-assets/cloudera_logo_darkorange.png\" alt=\"Cloudera Educational Services\" style=\"width:280px;height:40px;border:0;\" align=\"middle\">\n</a>\n</center>\n</br>\n</br>","user":"anonymous","dateUpdated":"2021-04-10T07:37:26-0700","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":2,"editorMode":"ace/mode/undefined","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"ANGULAR","data":"</br>\n</br>\n</br>\n</br>\n<center>\n<a href=\"https://www.cloudera.com/about/training/courses.html\">\n  <img src=\"https://www.cloudera.com/content/dam/www/marketing/media-kit/logo-assets/cloudera_logo_darkorange.png\" alt=\"Cloudera Educational Services\" style=\"width:280px;height:40px;border:0;\" align=\"middle\">\n</a>\n</center>\n</br>\n</br>"}]},"apps":[],"jobName":"paragraph_1618065446641_1794252089","id":"20200110-154537_1406191376","dateCreated":"2021-04-10T07:37:26-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:390854"}],"name":"/DevSH/Pyspark/RDDConvertXML","id":"2G246XKPF","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"angular:shared_process":[],"sh:shared_process":[],"livy:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}