{"paragraphs":[{"text":"%md\n# About This Lab\n**Objective:** Explore data using Pair RDDs. Explore the web server log files, and the user account data, using key-value pair RDDs.\n**File locations:** \n    Exercise directory: /home/training/training_materials/devsh/exercises/pair-rdds\n    Data (HDFS): /warehouse/tablespace/external/hive/devsh.db/accounts\n                 /devsh_loudacre/weblogs\n**Successful outcome:**\n**Before you begin:**\n**Related lessons:** Aggregating Data with Pair RDDs\n\n---","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>About This Lab</h1>\n<p><strong>Objective:</strong> Explore data using Pair RDDs. Explore the web server log files, and the user account data, using key-value pair RDDs.\n<br  /><strong>File locations:</strong></p>\n<pre><code>Exercise directory: /home/training/training_materials/devsh/exercises/pair-rdds\nData (HDFS): /warehouse/tablespace/external/hive/devsh.db/accounts\n             /devsh_loudacre/weblogs\n</code></pre>\n<p><strong>Successful outcome:</strong>\n<br  /><strong>Before you begin:</strong>\n<br  /><strong>Related lessons:</strong> Aggregating Data with Pair RDDs</p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1617116697745_816133661","id":"20171105-200834_1116095891","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:447287"},{"text":"%md\n# Setup\n\n\n","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Setup</h1>\n"}]},"apps":[],"jobName":"paragraph_1617116697745_235906914","id":"20181114-164229_902436001","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447288"},{"title":"Load data in HDFS if it does not exist","text":"%sh\n\nhdfs dfs -ls /devsh_loudacre/weblogs\n#hdfs dfs -put -f /home/training/training_materials/devsh/data/weblogs /devsh_loudacre\n","user":"anonymous","dateUpdated":"2021-03-31T12:45:36-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Found 182 items\n-rw-r--r--   3 zeppelin supergroup     521343 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-09-15.log\n-rw-r--r--   3 zeppelin supergroup     484079 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-09-16.log\n-rw-r--r--   3 zeppelin supergroup     527399 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-09-17.log\n-rw-r--r--   3 zeppelin supergroup     485105 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-09-18.log\n-rw-r--r--   3 zeppelin supergroup     508553 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-09-19.log\n-rw-r--r--   3 zeppelin supergroup     492134 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-09-20.log\n-rw-r--r--   3 zeppelin supergroup     489117 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-09-21.log\n-rw-r--r--   3 zeppelin supergroup     535780 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-09-22.log\n-rw-r--r--   3 zeppelin supergroup     501768 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-09-23.log\n-rw-r--r--   3 zeppelin supergroup     489344 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-09-24.log\n-rw-r--r--   3 zeppelin supergroup     487857 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-09-25.log\n-rw-r--r--   3 zeppelin supergroup     523186 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-09-26.log\n-rw-r--r--   3 zeppelin supergroup     506195 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-09-27.log\n-rw-r--r--   3 zeppelin supergroup     492600 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-09-28.log\n-rw-r--r--   3 zeppelin supergroup     481479 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-09-29.log\n-rw-r--r--   3 zeppelin supergroup     525367 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-09-30.log\n-rw-r--r--   3 zeppelin supergroup     484920 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-01.log\n-rw-r--r--   3 zeppelin supergroup     527452 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-02.log\n-rw-r--r--   3 zeppelin supergroup     521262 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-03.log\n-rw-r--r--   3 zeppelin supergroup     498950 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-04.log\n-rw-r--r--   3 zeppelin supergroup     510510 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-05.log\n-rw-r--r--   3 zeppelin supergroup     489554 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-06.log\n-rw-r--r--   3 zeppelin supergroup     489616 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-07.log\n-rw-r--r--   3 zeppelin supergroup     523298 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-08.log\n-rw-r--r--   3 zeppelin supergroup     529434 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-09.log\n-rw-r--r--   3 zeppelin supergroup     521604 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-10.log\n-rw-r--r--   3 zeppelin supergroup     524138 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-11.log\n-rw-r--r--   3 zeppelin supergroup     517782 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-12.log\n-rw-r--r--   3 zeppelin supergroup     522873 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-13.log\n-rw-r--r--   3 zeppelin supergroup     496593 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-14.log\n-rw-r--r--   3 zeppelin supergroup     495224 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-15.log\n-rw-r--r--   3 zeppelin supergroup     521024 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-16.log\n-rw-r--r--   3 zeppelin supergroup     500818 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-17.log\n-rw-r--r--   3 zeppelin supergroup     501154 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-18.log\n-rw-r--r--   3 zeppelin supergroup     527543 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-19.log\n-rw-r--r--   3 zeppelin supergroup     518589 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-20.log\n-rw-r--r--   3 zeppelin supergroup     512893 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-21.log\n-rw-r--r--   3 zeppelin supergroup     518030 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-22.log\n-rw-r--r--   3 zeppelin supergroup     492463 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-23.log\n-rw-r--r--   3 zeppelin supergroup     492054 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-24.log\n-rw-r--r--   3 zeppelin supergroup     533207 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-25.log\n-rw-r--r--   3 zeppelin supergroup     503777 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-26.log\n-rw-r--r--   3 zeppelin supergroup     503420 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-27.log\n-rw-r--r--   3 zeppelin supergroup     524048 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-28.log\n-rw-r--r--   3 zeppelin supergroup     510800 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-29.log\n-rw-r--r--   3 zeppelin supergroup     523180 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-30.log\n-rw-r--r--   3 zeppelin supergroup     524277 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-10-31.log\n-rw-r--r--   3 zeppelin supergroup     969586 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-01.log\n-rw-r--r--   3 zeppelin supergroup    1061868 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-02.log\n-rw-r--r--   3 zeppelin supergroup    1093742 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-03.log\n-rw-r--r--   3 zeppelin supergroup     956153 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-04.log\n-rw-r--r--   3 zeppelin supergroup    1085429 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-05.log\n-rw-r--r--   3 zeppelin supergroup    1071334 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-06.log\n-rw-r--r--   3 zeppelin supergroup    1038115 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-07.log\n-rw-r--r--   3 zeppelin supergroup    1078367 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-08.log\n-rw-r--r--   3 zeppelin supergroup     970029 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-09.log\n-rw-r--r--   3 zeppelin supergroup    1095755 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-10.log\n-rw-r--r--   3 zeppelin supergroup     977765 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-11.log\n-rw-r--r--   3 zeppelin supergroup     970149 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-12.log\n-rw-r--r--   3 zeppelin supergroup    1039116 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-13.log\n-rw-r--r--   3 zeppelin supergroup    1081771 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-14.log\n-rw-r--r--   3 zeppelin supergroup     982380 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-15.log\n-rw-r--r--   3 zeppelin supergroup    1009713 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-16.log\n-rw-r--r--   3 zeppelin supergroup    1086494 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-17.log\n-rw-r--r--   3 zeppelin supergroup     978348 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-18.log\n-rw-r--r--   3 zeppelin supergroup    1083789 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-19.log\n-rw-r--r--   3 zeppelin supergroup    1009470 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-20.log\n-rw-r--r--   3 zeppelin supergroup    1057086 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-21.log\n-rw-r--r--   3 zeppelin supergroup     975288 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-22.log\n-rw-r--r--   3 zeppelin supergroup    1063118 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-23.log\n-rw-r--r--   3 zeppelin supergroup    1048393 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-24.log\n-rw-r--r--   3 zeppelin supergroup     974776 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-25.log\n-rw-r--r--   3 zeppelin supergroup     962392 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-26.log\n-rw-r--r--   3 zeppelin supergroup     976234 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-27.log\n-rw-r--r--   3 zeppelin supergroup     976027 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-28.log\n-rw-r--r--   3 zeppelin supergroup    1081953 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-29.log\n-rw-r--r--   3 zeppelin supergroup    1006926 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-11-30.log\n-rw-r--r--   3 zeppelin supergroup    1014795 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-01.log\n-rw-r--r--   3 zeppelin supergroup    1093271 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-02.log\n-rw-r--r--   3 zeppelin supergroup    1068328 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-03.log\n-rw-r--r--   3 zeppelin supergroup    1070066 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-04.log\n-rw-r--r--   3 zeppelin supergroup    1028342 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-05.log\n-rw-r--r--   3 zeppelin supergroup    1031373 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-06.log\n-rw-r--r--   3 zeppelin supergroup    1018063 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-07.log\n-rw-r--r--   3 zeppelin supergroup    1039394 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-08.log\n-rw-r--r--   3 zeppelin supergroup    1101053 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-09.log\n-rw-r--r--   3 zeppelin supergroup    1009430 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-10.log\n-rw-r--r--   3 zeppelin supergroup    1061891 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-11.log\n-rw-r--r--   3 zeppelin supergroup    1030641 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-12.log\n-rw-r--r--   3 zeppelin supergroup    1028946 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-13.log\n-rw-r--r--   3 zeppelin supergroup     985819 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-14.log\n-rw-r--r--   3 zeppelin supergroup    1080787 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-15.log\n-rw-r--r--   3 zeppelin supergroup    1004498 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-16.log\n-rw-r--r--   3 zeppelin supergroup    1078566 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-17.log\n-rw-r--r--   3 zeppelin supergroup    1069630 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-18.log\n-rw-r--r--   3 zeppelin supergroup    1050695 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-19.log\n-rw-r--r--   3 zeppelin supergroup    1108042 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-20.log\n-rw-r--r--   3 zeppelin supergroup     986692 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-21.log\n-rw-r--r--   3 zeppelin supergroup    1045723 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-22.log\n-rw-r--r--   3 zeppelin supergroup     990531 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-23.log\n-rw-r--r--   3 zeppelin supergroup    1059352 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-24.log\n-rw-r--r--   3 zeppelin supergroup     980457 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-25.log\n-rw-r--r--   3 zeppelin supergroup    1054182 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-26.log\n-rw-r--r--   3 zeppelin supergroup    1017134 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-27.log\n-rw-r--r--   3 zeppelin supergroup    1064484 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-28.log\n-rw-r--r--   3 zeppelin supergroup    1022151 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-29.log\n-rw-r--r--   3 zeppelin supergroup    1070391 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-30.log\n-rw-r--r--   3 zeppelin supergroup     992528 2021-03-31 09:56 /devsh_loudacre/weblogs/2013-12-31.log\n-rw-r--r--   3 zeppelin supergroup    1057534 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-01.log\n-rw-r--r--   3 zeppelin supergroup    1053566 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-02.log\n-rw-r--r--   3 zeppelin supergroup     981998 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-03.log\n-rw-r--r--   3 zeppelin supergroup    1100898 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-04.log\n-rw-r--r--   3 zeppelin supergroup    1012644 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-05.log\n-rw-r--r--   3 zeppelin supergroup    1094868 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-06.log\n-rw-r--r--   3 zeppelin supergroup    1094753 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-07.log\n-rw-r--r--   3 zeppelin supergroup    1037422 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-08.log\n-rw-r--r--   3 zeppelin supergroup    1032385 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-09.log\n-rw-r--r--   3 zeppelin supergroup     977679 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-10.log\n-rw-r--r--   3 zeppelin supergroup     993697 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-11.log\n-rw-r--r--   3 zeppelin supergroup    1073307 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-12.log\n-rw-r--r--   3 zeppelin supergroup    1048789 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-13.log\n-rw-r--r--   3 zeppelin supergroup    1001350 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-14.log\n-rw-r--r--   3 zeppelin supergroup    1048617 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-15.log\n-rw-r--r--   3 zeppelin supergroup     996816 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-16.log\n-rw-r--r--   3 zeppelin supergroup    1044827 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-17.log\n-rw-r--r--   3 zeppelin supergroup     972872 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-18.log\n-rw-r--r--   3 zeppelin supergroup     975136 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-19.log\n-rw-r--r--   3 zeppelin supergroup    1020891 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-20.log\n-rw-r--r--   3 zeppelin supergroup    1011424 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-21.log\n-rw-r--r--   3 zeppelin supergroup    1109304 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-22.log\n-rw-r--r--   3 zeppelin supergroup     976011 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-23.log\n-rw-r--r--   3 zeppelin supergroup    1061764 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-24.log\n-rw-r--r--   3 zeppelin supergroup    1072204 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-25.log\n-rw-r--r--   3 zeppelin supergroup    1065979 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-26.log\n-rw-r--r--   3 zeppelin supergroup    1096363 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-27.log\n-rw-r--r--   3 zeppelin supergroup    1083865 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-28.log\n-rw-r--r--   3 zeppelin supergroup    1012968 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-29.log\n-rw-r--r--   3 zeppelin supergroup    1081064 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-30.log\n-rw-r--r--   3 zeppelin supergroup    1101529 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-01-31.log\n-rw-r--r--   3 zeppelin supergroup    1053099 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-01.log\n-rw-r--r--   3 zeppelin supergroup    1067044 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-02.log\n-rw-r--r--   3 zeppelin supergroup    1003003 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-03.log\n-rw-r--r--   3 zeppelin supergroup    1017259 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-04.log\n-rw-r--r--   3 zeppelin supergroup    1005783 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-05.log\n-rw-r--r--   3 zeppelin supergroup    1065257 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-06.log\n-rw-r--r--   3 zeppelin supergroup     996107 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-07.log\n-rw-r--r--   3 zeppelin supergroup    1035289 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-08.log\n-rw-r--r--   3 zeppelin supergroup    1065078 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-09.log\n-rw-r--r--   3 zeppelin supergroup    1044403 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-10.log\n-rw-r--r--   3 zeppelin supergroup    1057235 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-11.log\n-rw-r--r--   3 zeppelin supergroup    1091711 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-12.log\n-rw-r--r--   3 zeppelin supergroup    1096726 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-13.log\n-rw-r--r--   3 zeppelin supergroup    1072065 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-14.log\n-rw-r--r--   3 zeppelin supergroup    1010563 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-15.log\n-rw-r--r--   3 zeppelin supergroup    1056078 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-16.log\n-rw-r--r--   3 zeppelin supergroup     994481 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-17.log\n-rw-r--r--   3 zeppelin supergroup    1019882 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-18.log\n-rw-r--r--   3 zeppelin supergroup     992774 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-19.log\n-rw-r--r--   3 zeppelin supergroup     992721 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-20.log\n-rw-r--r--   3 zeppelin supergroup    1024612 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-21.log\n-rw-r--r--   3 zeppelin supergroup    1060506 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-22.log\n-rw-r--r--   3 zeppelin supergroup    1017947 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-23.log\n-rw-r--r--   3 zeppelin supergroup    1104389 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-24.log\n-rw-r--r--   3 zeppelin supergroup    1018667 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-25.log\n-rw-r--r--   3 zeppelin supergroup    1076821 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-26.log\n-rw-r--r--   3 zeppelin supergroup    1090745 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-27.log\n-rw-r--r--   3 zeppelin supergroup     975382 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-02-28.log\n-rw-r--r--   3 zeppelin supergroup    1004630 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-03-01.log\n-rw-r--r--   3 zeppelin supergroup    1005688 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-03-02.log\n-rw-r--r--   3 zeppelin supergroup     981270 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-03-03.log\n-rw-r--r--   3 zeppelin supergroup     968023 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-03-04.log\n-rw-r--r--   3 zeppelin supergroup    1006960 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-03-05.log\n-rw-r--r--   3 zeppelin supergroup    1014931 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-03-06.log\n-rw-r--r--   3 zeppelin supergroup    1103088 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-03-07.log\n-rw-r--r--   3 zeppelin supergroup    1001566 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-03-08.log\n-rw-r--r--   3 zeppelin supergroup     995517 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-03-09.log\n-rw-r--r--   3 zeppelin supergroup    1091560 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-03-10.log\n-rw-r--r--   3 zeppelin supergroup    1038692 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-03-11.log\n-rw-r--r--   3 zeppelin supergroup    1047117 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-03-12.log\n-rw-r--r--   3 zeppelin supergroup     997473 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-03-13.log\n-rw-r--r--   3 zeppelin supergroup     994147 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-03-14.log\n-rw-r--r--   3 zeppelin supergroup    1074872 2021-03-31 09:56 /devsh_loudacre/weblogs/2014-03-15.log\n"}]},"apps":[],"jobName":"paragraph_1617116697745_-844448285","id":"20200117-005924_766635286","dateCreated":"2021-03-30T08:04:57-0700","dateStarted":"2021-03-31T12:45:36-0700","dateFinished":"2021-03-31T12:45:38-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:447289"},{"title":"Set the environment variable to manage thread count","text":"%sh\n\nPYSPARK_PIN_THREAD=true","user":"anonymous","dateUpdated":"2021-03-31T12:45:45-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1617116697746_294720367","id":"20200830-173902_1816559311","dateCreated":"2021-03-30T08:04:57-0700","dateStarted":"2021-03-31T12:45:45-0700","dateFinished":"2021-03-31T12:45:45-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:447290"},{"title":"Start the Spark Context for Livy","text":"%pyspark\n\nsc = spark.sparkContext","user":"anonymous","dateUpdated":"2021-03-31T12:45:47-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<font color=\"red\">Previous livy session is expired, new livy session is created. Paragraphs that depend on this paragraph need to be re-executed!</font>"}]},"apps":[],"jobName":"paragraph_1617116697746_-1471929226","id":"20200830-174107_430995257","dateCreated":"2021-03-30T08:04:57-0700","dateStarted":"2021-03-31T12:45:47-0700","dateFinished":"2021-03-31T12:46:35-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:447291"},{"text":"%md\n# Lab\n---","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Lab</h1>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1617116697746_-2045049157","id":"20181114-164844_1661453681","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447292"},{"text":"%md\n### Explore Web Log Files\n\nIn this section, you will create a pair RDD based on data in the weblogs data files, and use that RDD to explore the data.\n\n**Tip:** In this exercise, you will be reducing and joining large datasets, which can take a lot of time and may result in memory errors resulting \nfrom the limited resources available in the course exercise environment. To avoid this problem, perform these exercises with a subset of the web \nlog files by using a wildcard: textFile(\"/ devsh_loudacre/weblogs/*2.log\") includes only filenames ending with 2.log.\n\nUsing map-reduce logic, count the number of requests from each user.\n\na. Use map to create a pair RDD with the user ID as the key and the integer 1 as the value. (The user ID is the third field in each line.) Your data will \nlook something like this:\n\n```pyspark\n(373,1)\n(373,1)\n(373,1)\n(924,1)\n(924,1)\n...\n```\n\nb. Use reduceByKey to sum the values for each user ID.\nYour RDD data will be similar to this:\n```pyspark\n(373,3)\n(924,2)\n(userid,7)\n(userid,5)\n...\n```","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Explore Web Log Files</h3>\n<p>In this section, you will create a pair RDD based on data in the weblogs data files, and use that RDD to explore the data.</p>\n<p><strong>Tip:</strong> In this exercise, you will be reducing and joining large datasets, which can take a lot of time and may result in memory errors resulting\n<br  />from the limited resources available in the course exercise environment. To avoid this problem, perform these exercises with a subset of the web\n<br  />log files by using a wildcard: textFile(&ldquo;/ devsh_loudacre/weblogs/*2.log&rdquo;) includes only filenames ending with 2.log.</p>\n<p>Using map-reduce logic, count the number of requests from each user.</p>\n<p>a. Use map to create a pair RDD with the user ID as the key and the integer 1 as the value. (The user ID is the third field in each line.) Your data will\n<br  />look something like this:</p>\n<pre><code class=\"pyspark\">(373,1)\n(373,1)\n(373,1)\n(924,1)\n(924,1)\n...\n</code></pre>\n<p>b. Use reduceByKey to sum the values for each user ID.\n<br  />Your RDD data will be similar to this:</p>\n<pre><code class=\"pyspark\">(373,3)\n(924,2)\n(userid,7)\n(userid,5)\n...\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617116697746_-505103543","id":"20200117-003727_1887180227","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447293"},{"title":"1 - Count the number of requests from each user","text":"%pyspark\n\n","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617116697746_-1303646756","id":"20200117-005302_91523840","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447294"},{"text":"%md\nUse countByKey to determine how many users visited the site for each frequency. That is, how many users visited once, twice, three times, and so on.\na. Use map to reverse the key and value, like this:\n\n```pyspark\n(5,userid)\n(7,userid)\n(2,userid)\n...\n```\n\nb. Use the countByKey action to return a map of frequency: user-count pairs.","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Use countByKey to determine how many users visited the site for each frequency. That is, how many users visited once, twice, three times, and so on.\n<br  />a. Use map to reverse the key and value, like this:</p>\n<pre><code class=\"pyspark\">(5,userid)\n(7,userid)\n(2,userid)\n...\n</code></pre>\n<p>b. Use the countByKey action to return a map of frequency: user-count pairs.</p>\n"}]},"apps":[],"jobName":"paragraph_1617116697746_-2016096064","id":"20200117-010502_1114454940","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447295"},{"title":"2 - Determine how many users visited the site for each frequency","text":"%pyspark\n\n","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617116697746_-1507449600","id":"20200117-010805_1450618394","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447296"},{"text":"%md\nCreate an RDD where the user ID is the key, and the value is the list of all the IP addresses that user has connected from. (IP address is the first field \nin each request line.)\n**Hint:** Map to (userid,ipaddress) and then use groupByKey.\n```pyspark\n(userid,20.1.34.55)\n(userid,245.33.1.1)\n(userid,65.50.196.141)\n...\n```\n```pyspark\n(userid,[20.1.34.55, 74.125.239.98])\n(userid,[75.175.32.10, 245.33.1.1, 66.79.233.99])\n(userid,[65.50.196.141])\n...\n```","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Create an RDD where the user ID is the key, and the value is the list of all the IP addresses that user has connected from. (IP address is the first field\n<br  />in each request line.)\n<br  /><strong>Hint:</strong> Map to (userid,ipaddress) and then use groupByKey.</p>\n<pre><code class=\"pyspark\">(userid,20.1.34.55)\n(userid,245.33.1.1)\n(userid,65.50.196.141)\n...\n</code></pre>\n<pre><code class=\"pyspark\">(userid,[20.1.34.55, 74.125.239.98])\n(userid,[75.175.32.10, 245.33.1.1, 66.79.233.99])\n(userid,[65.50.196.141])\n...\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617116697747_1665797913","id":"20200117-011050_1975747792","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447297"},{"title":"3 - Create an RDD where the user ID is the key, and the value is the list of all the IP addresses that user has connected from","text":"%pyspark\n\n","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617116697747_614966537","id":"20200117-011347_475883542","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447298"},{"text":"%md\n### Join Web Log Data with Account Data\nReview the accounts data located in /user/hive/warehouse/devsh.db/ accounts, which contains the data in the Hive devsh.accounts table. The first field in each \nline is the user ID, which corresponds to the user ID in the web server logs. The other fields include account details such as creation date, first and last \nname, and so on.\n\nJoin the accounts data with the weblog data to produce a dataset keyed by user ID which contains the user account information and the number of website hits \nfor that user.\n\na. Create an RDD, based on the accounts data, consisting of key/value-array pairs: (userid,[values...])\n```pyspark\n(9012,[9012,2008-11-24 10:04:08,\\N,Cheryl,West, 4905 Olive Street,...])\n(2312,[2312,2008-11-23 14:05:07,\\N,Elizabeth,Kerns, 4703 Eva Pearl Street,Richmond,CA,...])\n(1195,[1195,2008-11-02 17:12:12,2013-07-18 16:42:36,Melissa, Roman,3539 James Martin Circle,Oakland,CA,...])\n...\n```\nb. Join the pair RDD with the set of user-id/hit-count pairs calculated in the first step.\n```pyspark\n(9012,([9012,2008-11-24 10:04:08,\\N,Cheryl,West, 4905 Olive Street,San Francisco,CA,...],4))\n(2312,([2312,2008-11-23 14:05:07,\\N,Elizabeth,Kerns, 4703 Eva Pearl Street,Richmond,CA,...],8))\n(1195,([1195,2008-11-02 17:12:12,2013-07-18 16:42:36,Melissa, Roman,3539 James Martin Circle,Oakland,CA,...],2))\n```\nDisplay the user ID, hit count, and first name (4th value) and last name (5th value) for the first five elements. \nThe output should look similar to this (but your example data may be different):\n```pyspark\n9012 4 Cheryl West\n1123 8 Elizabeth Kerns\n1093 2 Melissa Roman\n...\n```","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Join Web Log Data with Account Data</h3>\n<p>Review the accounts data located in /user/hive/warehouse/devsh.db/ accounts, which contains the data in the Hive devsh.accounts table. The first field in each\n<br  />line is the user ID, which corresponds to the user ID in the web server logs. The other fields include account details such as creation date, first and last\n<br  />name, and so on.</p>\n<p>Join the accounts data with the weblog data to produce a dataset keyed by user ID which contains the user account information and the number of website hits\n<br  />for that user.</p>\n<p>a. Create an RDD, based on the accounts data, consisting of key/value-array pairs: (userid,[values&hellip;])</p>\n<pre><code class=\"pyspark\">(9012,[9012,2008-11-24 10:04:08,\\N,Cheryl,West, 4905 Olive Street,...])\n(2312,[2312,2008-11-23 14:05:07,\\N,Elizabeth,Kerns, 4703 Eva Pearl Street,Richmond,CA,...])\n(1195,[1195,2008-11-02 17:12:12,2013-07-18 16:42:36,Melissa, Roman,3539 James Martin Circle,Oakland,CA,...])\n...\n</code></pre>\n<p>b. Join the pair RDD with the set of user-id/hit-count pairs calculated in the first step.</p>\n<pre><code class=\"pyspark\">(9012,([9012,2008-11-24 10:04:08,\\N,Cheryl,West, 4905 Olive Street,San Francisco,CA,...],4))\n(2312,([2312,2008-11-23 14:05:07,\\N,Elizabeth,Kerns, 4703 Eva Pearl Street,Richmond,CA,...],8))\n(1195,([1195,2008-11-02 17:12:12,2013-07-18 16:42:36,Melissa, Roman,3539 James Martin Circle,Oakland,CA,...],2))\n</code></pre>\n<p>Display the user ID, hit count, and first name (4th value) and last name (5th value) for the first five elements.\n<br  />The output should look similar to this (but your example data may be different):</p>\n<pre><code class=\"pyspark\">9012 4 Cheryl West\n1123 8 Elizabeth Kerns\n1093 2 Melissa Roman\n...\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617116697747_-1176736844","id":"20200117-011743_666063642","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447299"},{"title":"4 - Join the accounts data with the weblog data to produce a dataset keyed by user ID","text":"%pyspark\n\n","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617116697747_98894749","id":"20200117-011855_1432753489","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447300"},{"text":"%md\n### Bonus Exercises\n\nIf you have more time, attempt the following extra bonus exercises:","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Bonus Exercises</h3>\n<p>If you have more time, attempt the following extra bonus exercises:</p>\n"}]},"apps":[],"jobName":"paragraph_1617116697747_1344428207","id":"20200117-013230_460158553","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447301"},{"title":"5 - Use keyBy to create an RDD of account data with the postal code (9th field in the CSV file) as the key","text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617116697747_-882858660","id":"20200117-013314_98050276","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447302"},{"text":"%md\nCreate a pair RDD with postal code as the key and a list of names (Last Name,First Name) in that postal code as the value.\n\n* **Hint:** First name and last name are the 4th and 5th fields respectively.\n* Optional: Try using the mapValues operation.","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Create a pair RDD with postal code as the key and a list of names (Last Name,First Name) in that postal code as the value.</p>\n<ul>\n<li><strong>Hint:</strong> First name and last name are the 4th and 5th fields respectively.</li>\n<li>Optional: Try using the mapValues operation.</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1617116697748_2057513561","id":"20200117-014601_570000018","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447303"},{"title":"6 - Create a pair RDD with postal code as the key and a list of names (Last Name,First Name) in that postal code as the value","text":"%pyspark\n\n","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617116697748_141975046","id":"20200117-014557_1061955362","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447304"},{"text":"%md\nSort the data by postal code, then for the first five postal codes, display the code and list the names in that postal zone. For example:\n```pyspark\n--- 85003 \nJenkins,Thad \nRick,Edward \nLindsay,Ivy \n...\n--- 85004 \nMorris,Eric \nReiser,Hazel \nGregg,Alicia \nPreston,Elizabeth \n...\n```\n","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Sort the data by postal code, then for the first five postal codes, display the code and list the names in that postal zone. For example:</p>\n<pre><code class=\"pyspark\">--- 85003 \nJenkins,Thad \nRick,Edward \nLindsay,Ivy \n...\n--- 85004 \nMorris,Eric \nReiser,Hazel \nGregg,Alicia \nPreston,Elizabeth \n...\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617116697748_2079238242","id":"20200117-014913_2008282954","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447305"},{"title":"7 - Sort the data by postal code, then for the first five postal codes, display the code and list the names in that postal zone","text":"%pyspark\n","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1617116697748_-2109835121","id":"20200117-014911_64851727","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447306"},{"text":"%md\n# Result\n**You have now:** explored the Loudacre web server log files, as well as the Loudacre user account data, using key-value pair RDDs.\n\n---","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Result</h1>\n<p><strong>You have now:</strong> explored the Loudacre web server log files, as well as the Loudacre user account data, using key-value pair RDDs.</p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1617116697748_760084450","id":"20181119-142716_792318228","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447307"},{"text":"%md\n# Solution\n---","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Solution</h1>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1617116697748_-705908717","id":"20171113-155535_1769142099","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447308"},{"text":"%md\n#### Spark Pair RDD\nIn Spark a key-value pair (KVP) are called a paired RDD. There are a number of pair RDD transformations. These include `groupbyKey`, `reduceByKey`, and `join`. \nThere are also pair RDD actions, such as `countByKey`.","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Spark Pair RDD</h4>\n<p>In Spark a key-value pair (KVP) are called a paired RDD. There are a number of pair RDD transformations. These include <code>groupbyKey</code>, <code>reduceByKey</code>, and <code>join</code>.\n<br  />There are also pair RDD actions, such as <code>countByKey</code>.</p>\n"}]},"apps":[],"jobName":"paragraph_1617116697748_1921001866","id":"20210123-143658_782381848","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447309"},{"text":"%md\n### Explore Web Log Files\n\nIn this section, you will create a pair RDD based on data in the weblogs data files, and use that RDD to explore the data.\n\n**Tip:** In this exercise, you will be reducing and joining large datasets, which can take a lot of time and may result in memory errors resulting from \nthe limited resources available in the course exercise environment. To avoid this problem, perform these exercises with a subset of the web log files by \nusing a wildcard: textFile(\"/ devsh_loudacre/weblogs/*2.log\") includes only filenames ending with 2.log.\n\nUsing map-reduce logic, count the number of requests from each user.\n\na. Use map to create a pair RDD with the user ID as the key and the integer 1 as the value. (The user ID is the third field in each line.) Your data will look \nsomething like this:\n\n```pyspark\n(373,1)\n(373,1)\n(373,1)\n(924,1)\n(924,1)\n...\n```\n\nb. Use reduceByKey to sum the values for each user ID.\nYour RDD data will be similar to this:\n```pyspark\n(373,3)\n(924,2)\n(userid,7)\n(userid,5)\n...\n```","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Explore Web Log Files</h3>\n<p>In this section, you will create a pair RDD based on data in the weblogs data files, and use that RDD to explore the data.</p>\n<p><strong>Tip:</strong> In this exercise, you will be reducing and joining large datasets, which can take a lot of time and may result in memory errors resulting from\n<br  />the limited resources available in the course exercise environment. To avoid this problem, perform these exercises with a subset of the web log files by\n<br  />using a wildcard: textFile(&ldquo;/ devsh_loudacre/weblogs/*2.log&rdquo;) includes only filenames ending with 2.log.</p>\n<p>Using map-reduce logic, count the number of requests from each user.</p>\n<p>a. Use map to create a pair RDD with the user ID as the key and the integer 1 as the value. (The user ID is the third field in each line.) Your data will look\n<br  />something like this:</p>\n<pre><code class=\"pyspark\">(373,1)\n(373,1)\n(373,1)\n(924,1)\n(924,1)\n...\n</code></pre>\n<p>b. Use reduceByKey to sum the values for each user ID.\n<br  />Your RDD data will be similar to this:</p>\n<pre><code class=\"pyspark\">(373,3)\n(924,2)\n(userid,7)\n(userid,5)\n...\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617116697749_1653319563","id":"20210121-202523_1289148079","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447310"},{"text":"%sh\n\nhdfs dfs -head /devsh_loudacre/weblogs/2013-09-22.log\n","user":"anonymous","dateUpdated":"2021-03-31T13:15:26-0700","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"131.166.169.114 - 67858 [23/Sep/2013:00:00:00 +0100] \"GET /ifruit_3a_sales.html HTTP/1.0\" 200 9509 \"http://www.loudacre.com\"  \"Loudacre Mobile Browser Sorrento F01L\"\n131.166.169.114 - 67858 [23/Sep/2013:00:00:00 +0100] \"GET /theme.css HTTP/1.0\" 200 13428 \"http://www.loudacre.com\"  \"Loudacre Mobile Browser Sorrento F01L\"\n131.166.169.114 - 67858 [23/Sep/2013:00:00:00 +0100] \"GET /code.js HTTP/1.0\" 200 5497 \"http://www.loudacre.com\"  \"Loudacre Mobile Browser Sorrento F01L\"\n131.166.169.114 - 67858 [23/Sep/2013:00:00:00 +0100] \"GET /ifruit_3a.jpg HTTP/1.0\" 200 19623 \"http://www.loudacre.com\"  \"Loudacre Mobile Browser Sorrento F01L\"\n254.253.248.193 - 3579 [22/Sep/2013:23:58:17 +0100] \"GET /ifruit_2_sales.html HTTP/1.0\" 200 19309 \"http://www.loudacre.com\"  \"Loudacre Mobile Browser MeeToo 1.0\"\n254.253.248.193 - 3579 [22/Sep/2013:23:58:17 +0100] \"GET /theme.css HTTP/1.0\" 200 18173 \"http://www.loudacre.com\"  \"Loudacre Mobile Browser MeeToo 1.0\"\n254.253.248.193 - 3579 [22/Sep/2013:23:58:17 +0100] \"GET /code.js HTTP/1.0\""}]},"apps":[],"jobName":"paragraph_1617116697749_466372054","id":"20210123-144843_424524821","dateCreated":"2021-03-30T08:04:57-0700","dateStarted":"2021-03-31T13:15:26-0700","dateFinished":"2021-03-31T13:15:28-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:447311"},{"title":"1 - Count the number of requests from each user","text":"%pyspark\n\n# Create an RDD based on a subset of weblogs (those ending in digit 2)\nlogsRDD = sc.textFile(\"/devsh_loudacre/weblogs/*2.log\")\n\n# map each request (line) to a pair (userid, 1), then sum the values\nuserReqsRDD = logsRDD.map(lambda line: line.split(' ')).map(lambda words: (words[2],1)).reduceByKey(lambda count1,count2: count1 + count2)","user":"anonymous","dateUpdated":"2021-03-31T13:17:24-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1617116697749_1306689171","id":"20200117-005516_1434443054","dateCreated":"2021-03-30T08:04:57-0700","dateStarted":"2021-03-31T13:17:24-0700","dateFinished":"2021-03-31T13:17:25-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:447312"},{"text":"%pyspark\n\nuserReqs = userReqsRDD.take(5)\nfor line in userReqs: print(line)","user":"anonymous","dateUpdated":"2021-03-31T13:17:29-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"(u'3922', 6)\n(u'104959', 2)\n(u'90396', 2)\n(u'62733', 4)\n(u'30390', 2)"}]},"apps":[],"jobName":"paragraph_1617116697749_1054073213","id":"20210123-144530_878988692","dateCreated":"2021-03-30T08:04:57-0700","dateStarted":"2021-03-31T13:17:29-0700","dateFinished":"2021-03-31T13:17:34-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:447313"},{"text":"%md\n#### Creating tuples\nUse textFiles to create an RDD from the dataset. The resulting RDD will consist of tuples. In Python a tuple is an immutable list.","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Creating tuples</h4>\n<p>Use textFiles to create an RDD from the dataset. The resulting RDD will consist of tuples. In Python a tuple is an immutable list.</p>\n"}]},"apps":[],"jobName":"paragraph_1617116697749_1128971997","id":"20210129-194119_2017442765","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447314"},{"title":"2 - Determine how many users visited the site for each frequency","text":"%pyspark\n\nsc.setJobGroup(\"JoiningDataUsingPairRDDs\", \"Show the count frequencies\")\nfreqCountMap = userReqsRDD.map(lambda pair: (pair[1],pair[0])).countByKey()\nprint(freqCountMap)","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"defaultdict(<type 'int'>, {128: 9, 2: 7239, 3: 36, 4: 4155, 5: 26, 6: 2162, 7: 14, 8: 1409, 9: 14, 10: 878, 11: 12, 12: 549, 13: 7, 14: 308, 15: 8, 16: 155, 17: 4, 146: 8, 19: 2, 20: 41, 21: 1, 22: 17, 150: 11, 152: 11, 132: 12, 154: 5, 27: 1, 156: 5, 158: 6, 160: 8, 162: 5, 164: 3, 134: 9, 166: 3, 168: 4, 170: 3, 172: 6, 174: 2, 24: 6, 176: 2, 136: 11, 178: 1, 188: 1, 138: 6, 190: 1, 130: 10, 140: 14, 142: 8, 86: 1, 144: 7, 100: 1, 104: 1, 106: 1, 18: 76, 110: 4, 112: 1, 116: 1, 118: 4, 120: 5, 148: 2, 122: 4, 124: 7, 126: 5})"}]},"apps":[],"jobName":"paragraph_1617116697749_1203587748","id":"20200117-010932_956520230","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447315"},{"text":"%md\nUse `countByKey` to determine for each frequency how many users visited the site. That is, how many users visited once, twice, three times, and so on.\n\na. Use map to reverse the key and value, like this:\n\n```pyspark\n(5,userid)\n(7,userid)\n(2,userid)\n...\n```\n\nb. Use the `countByKey` action to return a map of frequency: user-count pairs.\n\nSyntax\n`freqCountMap = userReqsRDD.map(lambda (userid,freq): (freq,userid)).countByKey()`\n","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Use <code>countByKey</code> to determine for each frequency how many users visited the site. That is, how many users visited once, twice, three times, and so on.</p>\n<p>a. Use map to reverse the key and value, like this:</p>\n<pre><code class=\"pyspark\">(5,userid)\n(7,userid)\n(2,userid)\n...\n</code></pre>\n<p>b. Use the <code>countByKey</code> action to return a map of frequency: user-count pairs.</p>\n<p>Syntax\n<br  /><code>freqCountMap = userReqsRDD.map(lambda (userid,freq): (freq,userid)).countByKey()</code></p>\n"}]},"apps":[],"jobName":"paragraph_1617116697750_-499654224","id":"20210121-202739_559835955","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447316"},{"title":"3 - Create an RDD where the user ID is the key, and the value is the list of all the IP addresses that user has connected from","text":"%pyspark\n\n# Group IPs by user ID\nsc.setJobGroup(\"JoiningDataUsingPairRDDs\", \"Create an RDD where the user ID is the key, and the value is the list of all the IP addresses that user has connected from\")\nuserIPsRDD = logsRDD.map(lambda line: line.split(' ')).map(lambda words: (words[2],words[0])).groupByKey()\n\n# print out the first 10 user ids, and their IP list\nfor (userid,ips) in userIPsRDD.take(10):\n   print(userid, \":\")\n   for ip in ips: print(\"\\t\",ip)","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"(u'3922', ':')\n('\\t', u'195.220.211.104')\n('\\t', u'195.220.211.104')\n('\\t', u'138.217.174.182')\n('\\t', u'138.217.174.182')\n('\\t', u'138.217.174.182')\n('\\t', u'138.217.174.182')\n(u'104959', ':')\n('\\t', u'183.123.205.115')\n('\\t', u'183.123.205.115')\n(u'90396', ':')\n('\\t', u'191.120.254.24')\n('\\t', u'191.120.254.24')\n(u'62733', ':')\n('\\t', u'93.120.232.94')\n('\\t', u'93.120.232.94')\n('\\t', u'92.75.142.64')\n('\\t', u'92.75.142.64')\n(u'30390', ':')\n('\\t', u'235.242.157.100')\n('\\t', u'235.242.157.100')\n(u'84780', ':')\n('\\t', u'148.5.198.57')\n('\\t', u'148.5.198.57')\n('\\t', u'148.5.198.57')\n('\\t', u'148.5.198.57')\n('\\t', u'240.70.72.108')\n('\\t', u'240.70.72.108')\n(u'54217', ':')\n('\\t', u'236.59.12.138')\n('\\t', u'236.59.12.138')\n('\\t', u'121.125.136.169')\n('\\t', u'121.125.136.169')\n('\\t', u'122.72.182.201')\n('\\t', u'122.72.182.201')\n('\\t', u'85.209.207.112')\n('\\t', u'85.209.207.112')\n('\\t', u'212.95.104.25')\n('\\t', u'212.95.104.25')\n('\\t', u'212.95.104.25')\n('\\t', u'212.95.104.25')\n('\\t', u'5.82.216.41')\n('\\t', u'5.82.216.41')\n('\\t', u'5.82.216.41')\n('\\t', u'5.82.216.41')\n('\\t', u'218.169.205.19')\n('\\t', u'218.169.205.19')\n('\\t', u'218.169.205.19')\n('\\t', u'218.169.205.19')\n(u'60986', ':')\n('\\t', u'81.217.213.96')\n('\\t', u'81.217.213.96')\n('\\t', u'44.89.72.134')\n('\\t', u'44.89.72.134')\n('\\t', u'249.13.225.46')\n('\\t', u'249.13.225.46')\n('\\t', u'249.13.225.46')\n('\\t', u'249.13.225.46')\n('\\t', u'88.110.41.147')\n('\\t', u'88.110.41.147')\n(u'44490', ':')\n('\\t', u'83.100.72.186')\n('\\t', u'83.100.72.186')\n(u'54604', ':')\n('\\t', u'159.112.48.88')\n('\\t', u'159.112.48.88')\n('\\t', u'110.199.28.152')\n('\\t', u'110.199.28.152')\n('\\t', u'197.162.156.152')\n('\\t', u'197.162.156.152')\n('\\t', u'41.69.4.131')\n('\\t', u'41.69.4.131')\n('\\t', u'144.133.38.146')\n('\\t', u'144.133.38.146')\n('\\t', u'144.133.38.146')\n('\\t', u'144.133.38.146')"}]},"apps":[],"jobName":"paragraph_1617116697750_260923147","id":"20200117-011549_208751082","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447317"},{"text":"%md\nCreate an RDD where the user ID is the key, and the value is the list of all the IP addresses that user has connected from. (IP address is the first field \nin each request line.)\n**Hint:** Map to (userid,ipaddress) and then use `groupByKey`.\n\n```pyspark\n(userid,20.1.34.55)\n(userid,245.33.1.1)\n(userid,65.50.196.141)\n...\n```\n```pyspark\n(userid,[20.1.34.55, 74.125.239.98])\n(userid,[75.175.32.10, 245.33.1.1, 66.79.233.99])\n(userid,[65.50.196.141])\n...\n```\n","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Create an RDD where the user ID is the key, and the value is the list of all the IP addresses that user has connected from. (IP address is the first field\n<br  />in each request line.)\n<br  /><strong>Hint:</strong> Map to (userid,ipaddress) and then use <code>groupByKey</code>.</p>\n<pre><code class=\"pyspark\">(userid,20.1.34.55)\n(userid,245.33.1.1)\n(userid,65.50.196.141)\n...\n</code></pre>\n<pre><code class=\"pyspark\">(userid,[20.1.34.55, 74.125.239.98])\n(userid,[75.175.32.10, 245.33.1.1, 66.79.233.99])\n(userid,[65.50.196.141])\n...\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617116697750_-983765660","id":"20210121-203056_386412740","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447318"},{"text":"%md\n#### Creating tuples\nThe resulting RDD will consist of tuples, in which the first value is the id of the device, and the second value is the IP address.","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Creating tuples</h4>\n<p>The resulting RDD will consist of tuples, in which the first value is the id of the device, and the second value is the IP address.</p>\n"}]},"apps":[],"jobName":"paragraph_1617116697750_-1478386779","id":"20210129-194415_1538732555","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447319"},{"text":"%md\n### Join Web Log Data with Account Data\nReview the accounts data located in `/user/hive/warehouse/devsh.db/` accounts, which contains the data in the Hive `devsh.accounts` table. The first field \nin each line is the user ID, which corresponds to the user ID in the web server logs. The other fields include account details such as creation date, \nfirst and last name, and so on.\n\nJoin the accounts data with the weblog data to produce a dataset keyed by user ID which contains the user account information and the number of website hits \nfor that user.\n\na. Create an RDD, based on the accounts data, consisting of key/value-array pairs: (userid,[values...])\n```pyspark\n(9012,[9012,2008-11-24 10:04:08,\\N,Cheryl,West, 4905 Olive Street,...])\n(2312,[2312,2008-11-23 14:05:07,\\N,Elizabeth,Kerns, 4703 Eva Pearl Street,Richmond,CA,...])\n(1195,[1195,2008-11-02 17:12:12,2013-07-18 16:42:36,Melissa, Roman,3539 James Martin Circle,Oakland,CA,...])\n...\n```\nb. Join the pair RDD with the set of user-id/hit-count pairs calculated in the first step.\n```pyspark\n(9012,([9012,2008-11-24 10:04:08,\\N,Cheryl,West, 4905 Olive Street,San Francisco,CA,...],4))\n(2312,([2312,2008-11-23 14:05:07,\\N,Elizabeth,Kerns, 4703 Eva Pearl Street,Richmond,CA,...],8))\n(1195,([1195,2008-11-02 17:12:12,2013-07-18 16:42:36,Melissa, Roman,3539 James Martin Circle,Oakland,CA,...],2))\n```\nDisplay the user ID, hit count, and first name (4th value) and last name (5th value) for the first five elements. \nThe output should look similar to this (but your example data may be different):\n```pyspark\n9012 4 Cheryl West\n1123 8 Elizabeth Kerns\n1093 2 Melissa Roman\n...\n```\n","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Join Web Log Data with Account Data</h3>\n<p>Review the accounts data located in <code>/user/hive/warehouse/devsh.db/</code> accounts, which contains the data in the Hive <code>devsh.accounts</code> table. The first field\n<br  />in each line is the user ID, which corresponds to the user ID in the web server logs. The other fields include account details such as creation date,\n<br  />first and last name, and so on.</p>\n<p>Join the accounts data with the weblog data to produce a dataset keyed by user ID which contains the user account information and the number of website hits\n<br  />for that user.</p>\n<p>a. Create an RDD, based on the accounts data, consisting of key/value-array pairs: (userid,[values&hellip;])</p>\n<pre><code class=\"pyspark\">(9012,[9012,2008-11-24 10:04:08,\\N,Cheryl,West, 4905 Olive Street,...])\n(2312,[2312,2008-11-23 14:05:07,\\N,Elizabeth,Kerns, 4703 Eva Pearl Street,Richmond,CA,...])\n(1195,[1195,2008-11-02 17:12:12,2013-07-18 16:42:36,Melissa, Roman,3539 James Martin Circle,Oakland,CA,...])\n...\n</code></pre>\n<p>b. Join the pair RDD with the set of user-id/hit-count pairs calculated in the first step.</p>\n<pre><code class=\"pyspark\">(9012,([9012,2008-11-24 10:04:08,\\N,Cheryl,West, 4905 Olive Street,San Francisco,CA,...],4))\n(2312,([2312,2008-11-23 14:05:07,\\N,Elizabeth,Kerns, 4703 Eva Pearl Street,Richmond,CA,...],8))\n(1195,([1195,2008-11-02 17:12:12,2013-07-18 16:42:36,Melissa, Roman,3539 James Martin Circle,Oakland,CA,...],2))\n</code></pre>\n<p>Display the user ID, hit count, and first name (4th value) and last name (5th value) for the first five elements.\n<br  />The output should look similar to this (but your example data may be different):</p>\n<pre><code class=\"pyspark\">9012 4 Cheryl West\n1123 8 Elizabeth Kerns\n1093 2 Melissa Roman\n...\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617116697750_-895963338","id":"20210121-203233_146680014","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447320"},{"title":"4 - Join the accounts data with the weblog data to produce a dataset keyed by user ID","text":"%pyspark\n\n# Map account data to (userid,[values....])\naccountsData = \"/warehouse/tablespace/external/hive/devsh.db/accounts\"\naccountsRDD = sc.textFile(accountsData).map(lambda s: s.split(',')).map(lambda account: (account[0],account))\n\n# Join account data with userreqs then merge hit count into valuelist   \naccountHitsRDD = accountsRDD.join(userReqsRDD)\n\n# Display userid, hit count, first name, last name for the first 5 elements\nsc.setJobGroup(\"JoiningDataUsingPairRDDs\", \"Join the accounts data with the weblog data to produce a dataset keyed by user ID\")\nfor (userid,(values,count)) in accountHitsRDD.take(5) : \n    print(userid, count, values[3], values[4])\n","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"(u'89371', 4, u'Ricky', u'Pope')\n(u'99996', 2, u'Garrett', u'Allen')\n(u'69171', 6, u'Richard', u'Tarver')\n(u'90311', 2, u'David', u'Rosenberg')\n(u'36848', 6, u'Aaron', u'Hutson')"}]},"apps":[],"jobName":"paragraph_1617116697750_590019552","id":"20200117-013059_733352759","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447321"},{"text":"%md\n### Bonus Exercises\n\nIf you have more time, attempt the following extra bonus exercises:","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Bonus Exercises</h3>\n<p>If you have more time, attempt the following extra bonus exercises:</p>\n"}]},"apps":[],"jobName":"paragraph_1617116697751_-1654585522","id":"20210121-203400_717288040","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447322"},{"title":"5 - Use keyBy to create an RDD of account data with the postal code (9th field in the CSV file) as the key","text":"%pyspark\n\naccountsByPCode = sc.textFile(accountsData).map(lambda s: s.split(',')).keyBy(lambda account: account[8])","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1617116697751_-589563621","id":"20200117-013516_1552283233","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447323"},{"title":"6 - Create a pair RDD with postal code as the key and a list of names (Last Name,First Name) in that postal code as the value","text":"%pyspark\n\nnamesByPCode = accountsByPCode.mapValues(lambda account: account[4] + ',' + account[3]).groupByKey()","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1617116697751_965394635","id":"20200117-014659_1109568109","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447324"},{"text":"%md\nCreate a pair RDD with postal code as the key and a list of names (Last Name,First Name) in that postal code as the value.\n\n* **Hint:** First name and last name are the 4th and 5th fields respectively.\n* Optional: Try using the mapValues operation.\n","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Create a pair RDD with postal code as the key and a list of names (Last Name,First Name) in that postal code as the value.</p>\n<ul>\n<li><strong>Hint:</strong> First name and last name are the 4th and 5th fields respectively.</li>\n<li>Optional: Try using the mapValues operation.</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1617116697751_-1844348204","id":"20210121-203446_875013265","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447325"},{"title":"7 - Sort the data by postal code, then for the first five postal codes, display the code and list the names in that postal zone","text":"%pyspark\n\nsc.setJobGroup(\"JoiningDataUsingPairRDDs\", \"Sort the data by postal code, then for the first five postal codes, display the code and list the names in that postal zone\")\nfor (pcode,names) in namesByPCode.sortByKey().take(5):\n   print(\"---\" ,pcode)\n   for name in names: print(name)","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"('---', u'85000')\nAllen,Harvey\nPrinz,Daniel\nPascale,Robert\nBrookes,Donna\nMackenzie,James\nChamberlain,Robert\nCunningham,Richard\nSewell,Bailey\nMarin,Daniel\n('---', u'85001')\nMendelsohn,Frances\nWatson,Mary\nBrookover,Donald\nHathaway,Brandon\nLeonard,Crystal\nMoran,Carrie\nKirksey,Marie\nLance,Issac\nBarnes,Vesta\nFiore,Eva\nTucker,Keith\nMedford,Danielle\nSpell,Norman\nSoto,Shelley\nFrantz,Kathy\nWilkins,Timothy\nSnyder,Joseph\nFlores,Delbert\nEakes,Gail\nDaniels,Bert\nCarpenter,Vincent\n('---', u'85002')\nWhitney,Ruby\nPerry,David\nJames,Marianne\nHoliman,Nancy\nRoman,Allen\nManus,Donna\nReed,Nancy\nBaird,Estella\nGilbert,James\nMcKay,David\nClark,Laura\nHorn,John\nPayne,Jessica\nStewart,Bryant\nJones,Jose\nRobinson,Wesley\n('---', u'85003')\nMartin,Mark\nRoss,Vivian\nTabor,Harry\nStrickland,Kyle\nDvorak,Kevin\nWisniewski,Virginia\nGibson,Catherine\nThies,Lindsey\n('---', u'85004')\nKitts,Mary\nViola,Kevin\nMeadows,Tonya\nRoyalty,Sherry\nCollins,Greg\nShirley,Joseph\nWhite,Sandra\nStern,Timothy\nJohnson,Dominic\nDewitt,Mary\nCarpenter,Matthew\nBall,Annie\nPate,Kathleen\nLish,Carrie"}]},"apps":[],"jobName":"paragraph_1617116697751_958987982","id":"20200117-014943_557010225","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447326"},{"text":"%md\nSort the data by postal code, then for the first five postal codes, display the code and list the names in that postal zone. For example:\n\n```pyspark\n--- 85003 \nJenkins,Thad \nRick,Edward \nLindsay,Ivy \n...\n--- 85004 \nMorris,Eric \nReiser,Hazel \nGregg,Alicia \nPreston,Elizabeth \n...\n```\n","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Sort the data by postal code, then for the first five postal codes, display the code and list the names in that postal zone. For example:</p>\n<pre><code class=\"pyspark\">--- 85003 \nJenkins,Thad \nRick,Edward \nLindsay,Ivy \n...\n--- 85004 \nMorris,Eric \nReiser,Hazel \nGregg,Alicia \nPreston,Elizabeth \n...\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1617116697752_-1319450368","id":"20210121-203541_2145689673","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447327"},{"text":"%md\n# Tear Down\n---","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Tear Down</h1>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1617116697752_208845033","id":"20200830-181832_535629868","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447328"},{"title":"Delete the Livy session","text":"%sh\n\nsessionId=$(curl -s localhost:8998/sessions | jq '.sessions[0].id')\ncurl -s localhost:8998/sessions/$sessionId -X DELETE","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"{\"msg\":\"deleted\"}"}]},"apps":[],"jobName":"paragraph_1617116697752_1569249720","id":"20200830-181904_1043067519","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447329"},{"title":"Additional resources","text":"%md\nWe hope you've enjoyed this lab. Below are additional resources that you should find useful:\n\n1. [Cloudera Tutorials](http://cloudera.com/tutorials.html) are your natural next step where you can explore Spark in more depth.\n2. [Cloudera Community](https://community.cloudera.com) is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.\n3. [Apache Spark Documentation](https://spark.apache.org/documentation.html) - official Spark documentation.\n4. [Apache Zeppelin Project Home Page](https://zeppelin.apache.org) - official Zeppelin web site.","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":10,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>We hope you've enjoyed this lab. Below are additional resources that you should find useful:</p>\n<ol>\n<li><a href=\"http://cloudera.com/tutorials.html\">Cloudera Tutorials</a> are your natural next step where you can explore Spark in more depth.</li>\n<li><a href=\"https://community.cloudera.com\">Cloudera Community</a> is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.</li>\n<li><a href=\"https://spark.apache.org/documentation.html\">Apache Spark Documentation</a> - official Spark documentation.</li>\n<li><a href=\"https://zeppelin.apache.org\">Apache Zeppelin Project Home Page</a> - official Zeppelin web site.</li>\n</ol>\n"}]},"apps":[],"jobName":"paragraph_1617116697752_-1737509901","id":"20181116-135131_93712280","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447330"},{"text":"%angular\n</br>\n</br>\n</br>\n</br>\n<center>\n<a href=\"https://www.cloudera.com/about/training/courses.html\">\n  <img src=\"https://www.cloudera.com/content/dam/www/marketing/media-kit/logo-assets/cloudera_logo_darkorange.png\" alt=\"Cloudera University\" style=\"width:280px;height:40px;border:0;\" align=\"middle\">\n</a>\n</center>\n</br>\n</br>","user":"anonymous","dateUpdated":"2021-03-30T08:04:57-0700","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":2,"editorMode":"ace/mode/undefined","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"ANGULAR","data":"</br>\n</br>\n</br>\n</br>\n<center>\n<a href=\"https://www.cloudera.com/about/training/courses.html\">\n  <img src=\"https://www.cloudera.com/content/dam/www/marketing/media-kit/logo-assets/cloudera_logo_darkorange.png\" alt=\"Cloudera University\" style=\"width:280px;height:40px;border:0;\" align=\"middle\">\n</a>\n</center>\n</br>\n</br>"}]},"apps":[],"jobName":"paragraph_1617116697752_-358657816","id":"20200110-154537_1406191376","dateCreated":"2021-03-30T08:04:57-0700","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447331"}],"name":"/DevSH/Pyspark/RDDJoinPairData","id":"2G28ZV8WR","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"angular:shared_process":[],"sh:shared_process":[],"livy:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}