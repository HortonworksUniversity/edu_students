{"paragraphs":[{"text":"%md\n# About\n**Lab:** Hive and Spark\n**Objective:** Become familiar with using Hive and Spark tabl\n**File locations:** \n                    /home/devuser/data/telco \n                    hdfs:///data/telco\n**Successful outcome:** Understanding Hive and Spark integration\n**Before you begin:** N/A\n**Related lessons:** Spark Overview \n\n---","user":"sysadmin","dateUpdated":"2020-06-02T22:45:40+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>About</h1>\n<p><strong>Lab:</strong> Hive and Spark\n<br  /><strong>Objective:</strong> Become familiar with using Hive and Spark tabl\n<br  /><strong>File locations:</strong> /home/devuser/data/telco</p>\n<pre><code>                hdfs:///data/telco\n</code></pre>\n<p><strong>Successful outcome:</strong> Understanding Hive and Spark integration\n<br  /><strong>Before you begin:</strong> N/A\n<br  /><strong>Related lessons:</strong> Spark Overview</p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1590949505176_2111427970","id":"20181126-092644_1457476546","dateCreated":"2020-05-31T18:25:05+0000","dateStarted":"2020-06-02T22:45:16+0000","dateFinished":"2020-06-02T22:45:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:207016"},{"text":"%md\n# Setup","user":"sysadmin","dateUpdated":"2020-05-31T18:25:05+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Setup</h1>\n"}]},"apps":[],"jobName":"paragraph_1590949505177_580973462","id":"20181201-044336_178705192","dateCreated":"2020-05-31T18:25:05+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:207017"},{"title":"Get the data and store it into /tmp/telco","text":"%sh\nrm -r /tmp/telco\nmkdir /tmp/telco\ncp -r /home/devuser/data/telco/static_data/accounts /tmp/telco/accounts\n","user":"sysadmin","dateUpdated":"2020-06-02T18:03:31+0000","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1590949505177_916050063","id":"20190606-160133_895901190","dateCreated":"2020-05-31T18:25:05+0000","dateStarted":"2020-06-02T18:03:31+0000","dateFinished":"2020-06-02T18:03:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:207018"},{"title":"List the directory /tmp/dc","text":"%sh\nls /tmp/telco/accounts","user":"sysadmin","dateUpdated":"2020-06-02T18:03:37+0000","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"part-m-00000\npart-m-00001\npart-m-00002\npart-m-00003\npart-m-00004\n"}]},"apps":[],"jobName":"paragraph_1590949505177_-591362868","id":"20200521-192918_1828095082","dateCreated":"2020-05-31T18:25:05+0000","dateStarted":"2020-06-02T18:03:38+0000","dateFinished":"2020-06-02T18:03:38+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:207019"},{"title":"Move the data into HDFS /data/telco","text":"%sh\nsudo -u hdfs hdfs dfs -rm -r -skipTrash /data/telco\nsudo -u hdfs hdfs dfs -mkdir -p /data/telco/accounts\nsudo -u hdfs hdfs dfs -put /tmp/telco/accounts/* /data/telco/accounts/","user":"sysadmin","dateUpdated":"2020-06-02T18:03:57+0000","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Deleted /data/telco\n"}]},"apps":[],"jobName":"paragraph_1590949505178_1856128588","id":"20200521-074204_1405413536","dateCreated":"2020-05-31T18:25:05+0000","dateStarted":"2020-06-02T18:03:57+0000","dateFinished":"2020-06-02T18:04:02+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:207020"},{"title":"Grant Hive access to the data","text":"%sh\nsudo -u hdfs hdfs dfs -chown -R hive /data/telco","user":"sysadmin","dateUpdated":"2020-06-02T18:04:05+0000","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1590949505178_-1656507046","id":"20200521-074249_792694423","dateCreated":"2020-05-31T18:25:05+0000","dateStarted":"2020-06-02T18:04:05+0000","dateFinished":"2020-06-02T18:04:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:207021"},{"title":"List the contents of HDFS /data/telco/accounts","text":"%sh\nhdfs dfs -ls /data/telco/accounts","user":"sysadmin","dateUpdated":"2020-06-02T18:04:16+0000","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Found 5 items\n-rw-r--r--   3 hive hdfs    4706617 2020-06-02 18:04 /data/telco/accounts/part-m-00000\n-rw-r--r--   3 hive hdfs    4693530 2020-06-02 18:04 /data/telco/accounts/part-m-00001\n-rw-r--r--   3 hive hdfs    4674529 2020-06-02 18:04 /data/telco/accounts/part-m-00002\n-rw-r--r--   3 hive hdfs    4662646 2020-06-02 18:04 /data/telco/accounts/part-m-00003\n-rw-r--r--   3 hive hdfs        129 2020-06-02 18:04 /data/telco/accounts/part-m-00004\n"}]},"apps":[],"jobName":"paragraph_1590949505178_-594833981","id":"20191112-224241_1478925112","dateCreated":"2020-05-31T18:25:05+0000","dateStarted":"2020-06-02T18:04:16+0000","dateFinished":"2020-06-02T18:04:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:207022"},{"text":"%md\n# Lab\n","user":"sysadmin","dateUpdated":"2020-05-31T18:25:05+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Lab</h1>\n"}]},"apps":[],"jobName":"paragraph_1590949505178_992215408","id":"20181126-093358_358613711","dateCreated":"2020-05-31T18:25:05+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:207023"},{"text":"%md\nWe are going to create an Hive external table\n~~~\nDROP TABLE IF EXISTS telco.accounts;\n\nCREATE EXTERNAL TABLE telco.accounts (\n    acct_num INT,\n    acct_create_dt TIMESTAMP,\n    acct_close_dt  TIMESTAMP,\n    first_name VARCHAR(255)  ,\n    last_name VARCHAR(255) ,\n    address  VARCHAR(255) ,\n    city  VARCHAR(255) ,\n    state VARCHAR(255) ,\n    zipcode VARCHAR(255) ,\n    phone_number VARCHAR(255) ,\n    created TIMESTAMP  ,\n    modified TIMESTAMP\n    )\nROW FORMAT DELIMITED \nFIELDS TERMINATED BY ',' \nSTORED AS TEXTFILE\nLOCATION '/user/zeppelin/hive/telco.db/accounts';\n\n~~~\n\nBut first we need to drop the table if it already exists.","user":"sysadmin","dateUpdated":"2020-06-02T22:47:30+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>We are going to create an Hive external table</p>\n<pre><code>DROP TABLE IF EXISTS telco.accounts_stage;\n\nCREATE EXTERNAL TABLE telco.accounts_stage (\n    acct_num INT,\n    acct_create_dt TIMESTAMP,\n    acct_close_dt  TIMESTAMP,\n    first_name VARCHAR(255)  ,\n    last_name VARCHAR(255) ,\n    address  VARCHAR(255) ,\n    city  VARCHAR(255) ,\n    state VARCHAR(255) ,\n    zipcode VARCHAR(255) ,\n    phone_number VARCHAR(255) ,\n    created TIMESTAMP  ,\n    modified TIMESTAMP\n    )\nROW FORMAT DELIMITED \nFIELDS TERMINATED BY ',' \nSTORED AS TEXTFILE\nLOCATION '/warehouse/tablespace/external/hive/telco_stage.db/accounts_stage';\n</code></pre>\n<p>But first we need to drop the table if it already exists.</p>\n"}]},"apps":[],"jobName":"paragraph_1590949505178_1479523883","id":"20181203-225219_1680906315","dateCreated":"2020-05-31T18:25:05+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:207024"},{"title":"1 - Drop, create and use database telco","text":"\n","user":"sysadmin","dateUpdated":"2020-05-31T18:25:05+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590949505178_-134478006","id":"20200522-171226_474294558","dateCreated":"2020-05-31T18:25:05+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:207025"},{"title":"2 - Use HDFS to compare the external and managed tablespace for hive","text":"\n","user":"sysadmin","dateUpdated":"2020-05-31T18:25:05+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590949505178_-77240289","id":"20200522-171257_127966538","dateCreated":"2020-05-31T18:25:05+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:207026"},{"title":"3 - Drop and create external table accounts","text":"\n","user":"sysadmin","dateUpdated":"2020-06-02T22:46:12+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590949505179_101071260","id":"20200522-171445_596281506","dateCreated":"2020-05-31T18:25:05+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:207027"},{"title":"4 - Load data into accounts","text":"\n","user":"sysadmin","dateUpdated":"2020-06-02T22:46:19+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590949505179_-1160154119","id":"20200522-171551_1871528564","dateCreated":"2020-05-31T18:25:05+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:207028"},{"title":"5 - Query the table limit 5","text":"\n","user":"sysadmin","dateUpdated":"2020-05-31T18:25:05+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590949505179_251142278","id":"20200522-171506_678964170","dateCreated":"2020-05-31T18:25:05+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:207029"},{"text":"%md\n# Result\n**You have now:** You have now successfully created a Hive tabled to be used by Spark. The instructor will now assign you Zeppelin notebooks that will use Spark and this table.\n\n---","user":"sysadmin","dateUpdated":"2020-05-31T18:25:05+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Result</h1>\n<p><strong>You have now:</strong> You have now successfully created a Hive tabled to be used by Spark. The instructor will now assign you Zeppelin notebooks that will use Spark and this table.</p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1590949505180_-1796403841","id":"20181126-133507_1472573213","dateCreated":"2020-05-31T18:25:05+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:207030"},{"text":"%md\n# Solution\n---","user":"sysadmin","dateUpdated":"2020-05-31T18:25:05+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Solution</h1>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1590949505180_1648048726","id":"20181018-125200_1133281582","dateCreated":"2020-05-31T18:25:05+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:207031"},{"title":"1 - Drop, create and use database telco","text":"%jdbc(hive_interactive)\nDROP DATABASE IF EXISTS telco CASCADE;\n\nCREATE DATABASE telco;\n\nUSE telco;\n","user":"sysadmin","dateUpdated":"2020-06-02T18:17:28+0000","config":{"tableHide":false,"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"},{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"},{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"}]},"apps":[],"jobName":"paragraph_1590949505180_1771045239","id":"20200522-001729_283317934","dateCreated":"2020-05-31T18:25:05+0000","dateStarted":"2020-06-02T18:17:28+0000","dateFinished":"2020-06-02T18:17:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:207032"},{"title":"2 - Use HDFS to compare the external and managed tablespace for hive","text":"%sh\nsudo -u hive hdfs dfs -ls /warehouse/tablespace/external/hive\nsudo -u hive hdfs dfs -ls /warehouse/tablespace/managed/hive\n","user":"sysadmin","dateUpdated":"2020-05-31T18:28:55+0000","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Found 5 items\ndrwxrwxrwx+  - hive hadoop          0 2020-05-24 03:59 /warehouse/tablespace/external/hive/cloudair.db\ndrwxrwxrwx+  - hive hadoop          0 2020-05-20 20:51 /warehouse/tablespace/external/hive/information_schema.db\ndrwxr-xr-t+  - hive hadoop          0 2020-05-20 20:51 /warehouse/tablespace/external/hive/sys.db\ndrwxrwxrwx+  - hive hadoop          0 2020-05-31 18:28 /warehouse/tablespace/external/hive/telco.db\ndrwxr-xr-x+  - hive hadoop          0 2020-05-22 00:56 /warehouse/tablespace/external/hive/telco_stage.db\nFound 4 items\ndrwxrwx---+  - hive hadoop          0 2020-05-24 04:10 /warehouse/tablespace/managed/hive/cloudair.db\ndrwxrwx---+  - hive hadoop          0 2020-05-20 20:51 /warehouse/tablespace/managed/hive/information_schema.db\ndrwxrwx---+  - hive hadoop          0 2020-05-20 20:51 /warehouse/tablespace/managed/hive/sys.db\ndrwxrwx---+  - hive hadoop          0 2020-05-31 18:28 /warehouse/tablespace/managed/hive/telco.db\n"}]},"apps":[],"jobName":"paragraph_1590949505180_1891040398","id":"20200522-005450_1172603067","dateCreated":"2020-05-31T18:25:05+0000","dateStarted":"2020-05-31T18:28:55+0000","dateFinished":"2020-05-31T18:28:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:207033"},{"text":"%sh\nhdfs dfs -ls /user/zeppelin/hive/telco.db/accounts/","user":"sysadmin","dateUpdated":"2020-06-02T18:17:42+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1591121465155_324584976","id":"20200602-181105_922481367","dateCreated":"2020-06-02T18:11:05+0000","dateStarted":"2020-06-02T18:17:42+0000","dateFinished":"2020-06-02T18:17:44+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:207034"},{"title":"3 - Drop and create external table accounts","text":"%jdbc(hive_interactive)\nDROP TABLE IF EXISTS telco.accounts;\n\nCREATE EXTERNAL TABLE telco.accounts (\n    acct_num INT,\n    acct_create_dt TIMESTAMP,\n    acct_close_dt  TIMESTAMP,\n    first_name VARCHAR(255)  ,\n    last_name VARCHAR(255) ,\n    address  VARCHAR(255) ,\n    city  VARCHAR(255) ,\n    state VARCHAR(255) ,\n    zipcode VARCHAR(255) ,\n    phone_number VARCHAR(255) ,\n    created TIMESTAMP  ,\n    modified TIMESTAMP)\nROW FORMAT DELIMITED FIELDS TERMINATED BY ',' \nSTORED AS TEXTFILE\nLOCATION '/user/zeppelin/hive/telco.db/accounts';","user":"sysadmin","dateUpdated":"2020-06-02T18:17:39+0000","config":{"tableHide":false,"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"},{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"}]},"apps":[],"jobName":"paragraph_1590949505180_-1887749982","id":"20190606-120655_1271724769","dateCreated":"2020-05-31T18:25:05+0000","dateStarted":"2020-06-02T18:17:39+0000","dateFinished":"2020-06-02T18:17:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:207035"},{"title":"4 - Load data into accounts","text":"%jdbc(hive_interactive)\nLOAD DATA  INPATH '/data/telco/accounts' OVERWRITE INTO TABLE telco.accounts;","user":"sysadmin","dateUpdated":"2020-06-02T22:46:23+0000","config":{"tableHide":false,"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"}]},"apps":[],"jobName":"paragraph_1590949505180_-1605542245","id":"20200521-074449_881545980","dateCreated":"2020-05-31T18:25:05+0000","dateStarted":"2020-06-02T18:18:00+0000","dateFinished":"2020-06-02T18:18:00+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:207036"},{"title":"5 - Query the table limit 5","text":"%jdbc(hive_interactive)\nSELECT * FROM telco.accounts LIMIT 5;","user":"sysadmin","dateUpdated":"2020-06-02T18:18:16+0000","config":{"tableHide":false,"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"accounts.acct_num":"string","accounts.acct_create_dt":"string","accounts.acct_close_dt":"string","accounts.first_name":"string","accounts.last_name":"string","accounts.address":"string","accounts.city":"string","accounts.state":"string","accounts.zipcode":"string","accounts.phone_number":"string","accounts.created":"string","accounts.modified":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"accounts.acct_num\taccounts.acct_create_dt\taccounts.acct_close_dt\taccounts.first_name\taccounts.last_name\taccounts.address\taccounts.city\taccounts.state\taccounts.zipcode\taccounts.phone_number\taccounts.created\taccounts.modified\n1\t2008-10-23 16:05:05.0\tnull\tDonald\tBecton\t2275 Washburn Street\tOakland\tCA\t94660\t5100032418\t2014-03-18 13:29:47.0\t2014-03-18 13:29:47.0\n2\t2008-11-12 03:00:01.0\tnull\tDonna\tJones\t3885 Elliott Street\tSan Francisco\tCA\t94171\t4150835799\t2014-03-18 13:29:47.0\t2014-03-18 13:29:47.0\n3\t2008-12-21 09:19:50.0\tnull\tDorthy\tChalmers\t4073 Whaley Lane\tSan Mateo\tCA\t94479\t6506877757\t2014-03-18 13:29:47.0\t2014-03-18 13:29:47.0\n4\t2008-11-28 00:08:09.0\tnull\tLeila\tSpencer\t1447 Ross Street\tSan Mateo\tCA\t94444\t6503198619\t2014-03-18 13:29:47.0\t2014-03-18 13:29:47.0\n5\t2008-11-15 23:06:06.0\tnull\tAnita\tLaughlin\t2767 Hill Street\tRichmond\tCA\t94872\t5107754354\t2014-03-18 13:29:47.0\t2014-03-18 13:29:47.0\n"}]},"apps":[],"jobName":"paragraph_1590949505180_-978263601","id":"20200521-074347_535490632","dateCreated":"2020-05-31T18:25:05+0000","dateStarted":"2020-06-02T18:18:14+0000","dateFinished":"2020-06-02T18:18:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:207037"},{"text":"%md\nWe hope you've enjoyed this lab. Below are additional resources that you should find useful:\n\n1. [Cloudera Apache Spark Tutorials](http://hortonworks.com/tutorials/#tuts-developers) are your natural next step where you can explore Spark in more depth.\n2. [Cloudera Community Connection (HCC)](https://community.hortonworks.com/spaces/85/data-science.html?type=question) is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.\n3. [Cloudera Apache Spark Docs](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/spark-overview/content/analyzing_data_with_apache_spark.html) - official Spark documentation.\n4. [Cloudera Apache Zeppelin Docs](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/zeppelin-overview/content/overview.html) - official Zeppelin documentation.\n","user":"sysadmin","dateUpdated":"2020-06-02T18:18:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>We hope you've enjoyed this lab. Below are additional resources that you should find useful:</p>\n<ol>\n<li><a href=\"http://hortonworks.com/tutorials/#tuts-developers\">Cloudera Apache Spark Tutorials</a> are your natural next step where you can explore Spark in more depth.</li>\n<li><a href=\"https://community.hortonworks.com/spaces/85/data-science.html?type=question\">Cloudera Community Connection (HCC)</a> is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.</li>\n<li><a href=\"https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/spark-overview/content/analyzing_data_with_apache_spark.html\">Cloudera Apache Spark Docs</a> - official Spark documentation.</li>\n<li><a href=\"https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/zeppelin-overview/content/overview.html\">Cloudera Apache Zeppelin Docs</a> - official Zeppelin documentation.</li>\n</ol>\n"}]},"apps":[],"jobName":"paragraph_1590949505181_1327725561","id":"20181126-133017_244739700","dateCreated":"2020-05-31T18:25:05+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:207038"}],"name":"PYSPARK/20-Supplement:CreatingAndLoadingHiveDatabase","id":"2F8UKXXV2","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"angular:shared_process":[],"sh:shared_process":[],"jdbc:shared_process":[],"spark2:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}