{"paragraphs":[{"text":" %md\n# About\n**Lab:** Analyzing Data with DataFrame Queries\n**Objective:** Analyze account data and mobile device data using DataFrame queries\n**File locations:**\n- Data files (local): \n    - /home/devuser/data/telco/accountdevice\n    - /home/devuser/data/telco/base_stations.parquet\n- Data files (HDFS): /user/zeppelin/devices.json\n- Hive Tables: telco.accounts\n\n**Successful outcome:** \n**Before you begin:** \n**Related lessons:** \n\n---","user":"sysadmin","dateUpdated":"2020-06-02T19:00:58+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>About</h1>\n<p><strong>Lab:</strong> Analyzing Data with DataFrame Queries\n<br  /><strong>Objective:</strong> Analyze account data and mobile device data using DataFrame queries\n<br  /><strong>File locations:</strong></p>\n<ul>\n<li>Data files (local):<ul>\n<li>$DEVDATA/accountdevice</li>\n<li>$DEVDATA/base_stations.parquet</li>\n</ul>\n</li>\n<li>Data files (HDFS): /devsh_loudacre/devices.json</li>\n<li>Hive Tables: devsh.accounts</li>\n</ul>\n<p><strong>Successful outcome:</strong>\n<br  /><strong>Before you begin:</strong>\n<br  /><strong>Related lessons:</strong></p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1590357630432_399062527","id":"20181126-092644_1457476546","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:140568"},{"text":"%md\n# Setup","user":"sysadmin","dateUpdated":"2020-06-02T19:01:19+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Setup</h1>\n<p><strong>Important:</strong> This exercise depends on <strong><em> ***Insert previous exercise title here (with link?)*** </em></strong>. If you did not complete that exercise, run the course catch-up script and advance to the current exercise:</p>\n<pre><code>$ $DEVSH/scripts/catchup.sh\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1590357630433_1842661322","id":"20181201-044336_178705192","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140569"},{"text":"%md\n# Lab\n","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Lab</h1>\n"}]},"apps":[],"jobName":"paragraph_1590357630433_1342716488","id":"20181126-093358_358613711","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140570"},{"text":"%md\n### Query DataFrames Using Column Expressions","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Query DataFrames Using Column Expressions</h3>\n"}]},"apps":[],"jobName":"paragraph_1590357630434_472676588","id":"20200428-000319_1418615856","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140571"},{"title":"1 - Review the API documentation for the Spark Column class","text":"%md\n*Optional:* Review the API docs for the `Column` class (which is in the Python module `pyspark.sql`). Take note of the various options available.","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p><em>Optional:</em> Review the API docs for the <code>Column</code> class (which is in the Python module\n<br  /><code>pyspark.sql</code> and the Scala package <code>org.apache.spark.sql</code>). Take note of\n<br  />the various options available.</p>\n"}]},"apps":[],"jobName":"paragraph_1590357630434_536659020","id":"20200424-212509_1688232409","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140572"},{"title":"2 - Create a new DataFrame called accountsDF","text":"%md\nCreate a new DataFrame called `accountsDF` based on the Hive `telco.accounts` table.","user":"sysadmin","dateUpdated":"2020-06-02T19:01:39+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Create a new DataFrame called <code>accountsDF</code> based on the Hive <code>devsh.accounts</code> table.</p>\n"}]},"apps":[],"jobName":"paragraph_1590357630435_875259139","id":"20200424-212208_1992391573","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140573"},{"text":"%pyspark\n","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630435_449713833","id":"20200424-212305_1976759900","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140574"},{"title":"3 - Practice using both column reference syntaxes","text":"%md\nTry a simple query with `select`, using both column reference syntaxes.","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Try a simple query with <code>select</code>, using both column reference syntaxes.</p>\n"}]},"apps":[],"jobName":"paragraph_1590357630435_-646139621","id":"20200424-212125_1404990380","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140575"},{"text":"%pyspark\n# Syntax 1\naccountsDF.select(accountsDF[\"first_name\"]).show()\n\n# Syntax 2\n#accountsDF.select(accountsDF.first_name).show()","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630435_1419495593","id":"20200424-212055_1017943498","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140576"},{"title":"4 - Create a column object","text":"%md\nTo explore column expressions, create a column object to work with, based on the `first_name` column in the `accountsDF` DataFrame.","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>To explore column expressions, create a column object to work with, based on the\n<br  /><code>first_name</code> column in the <code>accountsDF</code> DataFrame.</p>\n"}]},"apps":[],"jobName":"paragraph_1590357630436_353748727","id":"20200424-211342_2102011750","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140577"},{"text":"%pyspark\nfncol = accountsDF.first_name","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630436_-2132036954","id":"20200424-211535_1918581691","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140578"},{"title":"5 - View available methods and attributes of the Column class","text":"%md\nNote that the object type is `Column`. To see available methods and attributes, use tab completion--that is, enter `fnCol`. followed by `TAB`.","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Note that the object type is <code>Column</code>. To see available methods and attributes, use\n<br  />tab completion&ndash;that is, enter <code>fnCol</code>. followed by <code>TAB</code>.</p>\n"}]},"apps":[],"jobName":"paragraph_1590357630436_1561089198","id":"20200424-211341_2090534806","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140579"},{"text":"%pyspark\n#fnCol.","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630436_-2095261829","id":"20200428-024431_1568395373","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140580"},{"title":"6 - Use a column expression to create a new column object","text":"%md\nNew `Column` objects are created when you perform operations on existing columns. Create a new `Column` object based on a column expression that identifies users whose first name is Lucy using the equality operator on the `fnCol` object you created above.","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>New <code>Column</code> objects are created when you perform operations on existing\n<br  />columns. Create a new <code>Column</code> object based on a column expression that identifies\n<br  />users whose first name is Lucy using the equality operator on the <code>fnCol</code> object you\n<br  />created above.</p>\n"}]},"apps":[],"jobName":"paragraph_1590357630436_-584109762","id":"20200424-211259_1439234654","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140581"},{"text":"%pyspark\nlucyCol = (fnCol == \"Lucy\")","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630437_-1469960403","id":"20200424-211140_1331293844","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140582"},{"title":"7 - Use the lucyCol column expression in a select statement","text":"%md\nUse the `lucyCol` column expression in a `select` statement. Because `lucyCol` is based on a boolean expression, the column values will be `true` or `false` depending on the value of the `first_name` column. Confirm that users named Lucy are identified with the value `true`.","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Use the <code>lucyCol</code> column expression in a <code>select</code> statement. Because <code>lucyCol</code>\n<br  />is based on a boolean expression, the column values will be <code>true</code> or <code>false</code>\n<br  />depending on the value of the <code>first_name</code> column. Confirm that users named\n<br  />Lucy are identified with the value <code>true</code>.</p>\n"}]},"apps":[],"jobName":"paragraph_1590357630437_-1526511616","id":"20200424-211010_1767236609","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140583"},{"text":"%pyspark\naccountsDF. \\\nselect(accountsDF.first_name, \\\naccountsDF.last_name,lucyCol).show()","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630437_-1031108090","id":"20200424-210944_441417371","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140584"},{"title":"8 - Use the where operation","text":"%md\nThe `where` operation requires a boolean-based column expression. Use the `lucyCol` column expression in a where transformation and view the data in the resulting DataFrame. Confirm that only users named Lucy are in the data.","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>The <code>where</code> operation requires a boolean-based column expression. Use the\n<br  /><code>lucyCol</code> column expression in a where transformation and view the data in the\n<br  />resulting DataFrame. Confirm that only users named Lucy are in the data.</p>\n"}]},"apps":[],"jobName":"paragraph_1590357630438_1845676285","id":"20200424-210842_326461687","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140585"},{"text":"%pyspark\naccountsDF.where(lucyCol).show(5)","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630438_1815211833","id":"20200424-210819_197116283","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140586"},{"title":"9 - Try a query without assigning the result to a variable","text":"%md\nColumn expressions do not need to be assigned to a variable. Try the same query without using the `lucyCol` variable.","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Column expressions do not need to be assigned to a variable. Try the same query\n<br  />without using the <code>lucyCol</code> variable.</p>\n"}]},"apps":[],"jobName":"paragraph_1590357630438_995282702","id":"20200424-210740_808874803","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140587"},{"text":"%pyspark\naccountsDF.where(fnCol == \"Lucy\").show(5)","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630438_791011103","id":"20200424-210713_2131753087","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140588"},{"title":"10 - Column expressions can be used wherever a column could be used","text":"%md\nColumn expressions are not limited to where operations like those above. They can be used in any transformation for which a simple column could be used, such as a `select`. Try selecting the `city` and `state` columns, and the first three characters of the `phone_number` column (in the U.S., the first three digits of a phone number are known as the area code). Use the `substr` operator on the `phone_number` column to extract the area code.","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Column expressions are not limited to where operations like those above. They can\n<br  />be used in any transformation for which a simple column could be used, such as a\n<br  /><code>select</code>. Try selecting the <code>city</code> and <code>state</code> columns, and the first three characters\n<br  />of the <code>phone_number</code> column (in the U.S., the first three digits of a phone number\n<br  />are known as the area code). Use the <code>substr</code> operator on the <code>phone_number</code>\n<br  />column to extract the area code.</p>\n"}]},"apps":[],"jobName":"paragraph_1590357630439_732453853","id":"20200424-210538_1418669039","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140589"},{"text":"%pyspark\naccountsDF. \\\nselect(\"city\", \"state\", \\\naccountsDF.phone_number.substr(1,3)). \\\nshow(5)","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630439_417915317","id":"20200424-210506_2050598948","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140590"},{"title":"11 - Use the alias operator to rename a column","text":"%md\nNotice that in the last step, the values returned by the query were correct, but the column name was `substring(phone_number, 1, 3)`, which is long and hard to work with. Repeat the same query, using the alias operator to rename that column as `area_code`.","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Notice that in the last step, the values returned by the query were correct, but the\n<br  />column name was <code>substring(phone_number, 1, 3)</code>, which is long and\n<br  />hard to work with. Repeat the same query, using the alias operator to rename that\n<br  />column as <code>area_code</code>.</p>\n"}]},"apps":[],"jobName":"paragraph_1590357630439_307384641","id":"20200424-205240_2041304491","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140591"},{"text":"%pyspark\naccountsDF. \\\nselect(\"city\", \"state\", \\\naccountsDF.phone_number. \\\nsubstr(1,3).alias(\"area_code\")). \\\nshow(5)","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630439_-910175891","id":"20200424-205156_136439727","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140592"},{"title":"12 - Practice using transformations","text":"%md\nPerform a query that results in a DataFrame with just `first_name` and `last_name` columns, and only includes users whose first and last names both begin with the same two letters. (For example, the user Roberta Roget would be included, because both her first and last names begin with\"Ro\".)","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630440_-832923580","id":"20200424-205004_811241468","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140593"},{"text":"%pyspark\n","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630440_1936893270","id":"20200424-205103_2140068119","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140594"},{"text":"%md\n### Group and Count Data by Name","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Group and Count Data by Name</h3>\n"}]},"apps":[],"jobName":"paragraph_1590357630440_2028803702","id":"20200428-021130_74434274","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140595"},{"title":"13 - Query the DataFrame using groupBy with the count aggregation transformation","text":"%md\nQuery the `accountsDF` DataFrame using `groupBy` with count to find out the total number people sharing each last name. (Note that the count aggregation transformation returns a DataFrame, unlike the `count` DataFrame action, which returns a single value to the driver.)","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Query the <code>accountsDF</code> DataFrame using <code>groupBy</code> with count to find out the\n<br  />total number people sharing each last name. (Note that the count aggregation\n<br  />transformation returns a DataFrame, unlike the <code>count</code> DataFrame action, which\n<br  />returns a single value to the driver.)</p>\n"}]},"apps":[],"jobName":"paragraph_1590357630440_-1139767369","id":"20200424-204838_1865108814","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140596"},{"text":"%pyspark\naccountsDF.groupBy(\"last_name\").count().show(5)","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630441_-638195263","id":"20200424-204814_258444822","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140597"},{"title":"14 - Use groupBy on multiple columns","text":"%md\nYou can also group by multiple columns. Query `accountsDF` again, this time counting the number of people who share the same last and first name.","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>You can also group by multiple columns. Query <code>accountsDF</code> again, this time\n<br  />counting the number of people who share the same last and first name.</p>\n"}]},"apps":[],"jobName":"paragraph_1590357630441_1244045415","id":"20200424-204728_710380328","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140598"},{"text":"%pyspark\naccountsDF. \\\ngroupBy(\"last_name\",\"first_name\").count().show(5)","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630441_-849038461","id":"20200424-204702_186191411","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140599"},{"text":"%md\n### Join Account Data with Cellular Towers by Zip Code","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Join Account Data with Cellular Towers by Zip Code</h3>\n"}]},"apps":[],"jobName":"paragraph_1590357630441_-519899892","id":"20200428-023308_165587244","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140600"},{"title":"15 - Review the base_stations.parquet file","text":"%md\nIn this section, you will join the accounts data that you have been using with data about cell tower base station locations, which is in the `base_stations.parquet` file. Start by reviewing the schema and a few records of the data. Use the `parquet-tools` command in a separate terminal window (not the one running the Spark shell).\n\n    $ parquet-tools schema /home/devuser/data/telco/base_stations.parquet\n    $ parquet-tools head /home/devuser/data/telco/base_stations.parquet","user":"sysadmin","dateUpdated":"2020-06-02T19:04:19+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>In this section, you will join the accounts data that you have been using with data\n<br  />about cell tower base station locations, which is in the <code>base_stations.parquet</code>\n<br  />file. Start by reviewing the schema and a few records of the data. Use the\n<br  /><code>parquet-tools</code> command in a separate terminal window (not the one running\n<br  />the Spark shell).</p>\n<pre><code>$ parquet-tools schema $DEVDATA/base_stations.parquet\n$ parquet-tools head $DEVDATA/base_stations.parquet\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1590357630442_-1340115094","id":"20200424-204523_175092546","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140601"},{"title":"16 - Upload the data file to HDFS","text":"%sh\nhdfs dfs -put /home/devuser/data/telco/base_stations.parquet /user/zeppelin/","user":"sysadmin","dateUpdated":"2020-06-02T19:04:42+0000","config":{"tableHide":true,"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<pre><code>$ hdfs dfs -put $DEVDATA/base_stations.parquet devsh_loudacre/\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1590357630442_-1592665349","id":"20200424-204412_257827029","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140602"},{"title":"17 - Create a new DataFrame using the base stations data","text":"%md\nIn your Spark shell, create a new DataFrame called `baseDF` using the base stations data. Review the `baseDF` schema and data to ensure it matches the data in the Parquet file.","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>In your Spark shell, create a new DataFrame called <code>baseDF</code> using the base stations\n<br  />data. Review the <code>baseDF</code> schema and data to ensure it matches the data in the\n<br  />Parquet file.</p>\n"}]},"apps":[],"jobName":"paragraph_1590357630442_-1699353251","id":"20200424-204225_363142431","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140603"},{"text":"%pyspark\n","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630442_-557629161","id":"20200428-024608_162427147","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140604"},{"title":"18 - Perform a join on baseDF and accountsDF","text":"%md\nSome account holders live in zip codes that have a base station. Join `baseDF` and `accountsDF` to find those users. For each of those users, include their account ID, first name, last name, and the ID and location data (latitude and longitude) for the base station in their zip code.","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Some account holders live in zip codes that have a base station. Join <code>baseDF</code> and\n<br  /><code>accountsDF</code> to find those users. For each of those users, include their account ID,\n<br  />first name, last name, and the ID and location data (latitude and longitude) for the\n<br  />base station in their zip code.</p>\n"}]},"apps":[],"jobName":"paragraph_1590357630443_-44185808","id":"20200424-204225_1650611891","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140605"},{"text":"%pyspark\naccountsDF. \\\nselect(\"acct_num\",\"first_name\",\"last_name\",\"zipcode\"). \\\njoin(baseDF, baseDF.zip == accountsDF.zipcode). \\\nshow()","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630443_-1176770273","id":"20200424-204205_958335764","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140606"},{"text":"%md\n### Count Active Devices","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Count Active Devices</h3>\n"}]},"apps":[],"jobName":"paragraph_1590357630443_-1343668604","id":"20200428-023757_1155572954","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140607"},{"title":"19 - Review the account device data and upload it to HDFS","text":"%md\nThe `accountdevice` CSV dataset contains a list of all the devices used by all accounts. Each row in the data set includes a row ID, an account ID, an ID for the type of device, the date the device was activated for the account, and the specific device ID.\n\nThe CSV data file is in the `/home/devuser/data/telco/accountdevice` directory. Review the data in the data set, then upload the directory and its contents to the HDFS directory `/user/zeppelin/accountdevice`.","user":"sysadmin","dateUpdated":"2020-06-02T19:05:06+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>The <code>accountdevice</code> CSV dataset contains a list of all the devices used by all\n<br  />accounts. Each row in the data set includes a row ID, an account ID, an ID for the\n<br  />type of device, the date the device was activated for the account, and the specific\n<br  />device ID.</p>\n<p>The CSV data file is in the <code>$DEVDATA/accountdevice</code> directory. Review the data\n<br  />in the data set, then upload the directory and its contents to the HDFS directory\n<br  /><code>/devsh_loudacre/accountdevice</code>.</p>\n"}]},"apps":[],"jobName":"paragraph_1590357630443_-1124663284","id":"20200424-203930_1058017229","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140608"},{"text":"%pyspark\n","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630444_-2075119661","id":"20200521-201713_1902770408","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140609"},{"title":"20 - Create a DataFrame based on the account device data","text":"%md\nCreate a DataFrame based on the `accountdevice` data files.","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Create a DataFrame based on the <code>accountdevice</code> data files.</p>\n"}]},"apps":[],"jobName":"paragraph_1590357630444_985140892","id":"20200424-203906_1000568790","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140610"},{"text":"%pyspark\n","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630444_1101633973","id":"20200428-024633_1113292222","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140611"},{"title":"21 - Analyze the data presented in this exercise","text":"%md\nUse the account device data and the DataFrames you created previously in this exercise to find the total number of each device model across all *active* accounts -- that is, accounts that have not been closed. The new DataFrame should be sorted from most to least common model. Save the data as Parquet files in a directory called `/user/zeppelin/top_devices` with the following columns:\n\n```\n| Column Name | Description                                                                                  | Example Value  |\n|-------------|----------------------------------------------------------------------------------------------|----------------|\n| device_id   | The ID number of each known device (including those that might not be in use by any account) | 18             |\n| make        | The manufacturer name for the device                                                         | Ronin          |\n| model       | The model name for the device                                                                | Novelty Note 2 |\n| active_num  | The total number of the model used by active accounts                                        | 2092           |\n```\n\nHints:\n- Active accounts are those with a null value for `acct_close_dt` (account close date) in the `accounts` table.\n- The `account_id` column in the device accounts data corresponds to the `acct_num` column in `accounts` table.\n- The `device_id` column in the device accounts data corresponds to the devnum column in the list of known devices in the `/devsh_loudacre/devices.json` file.\n- When you count devices, use `withColumnRenamed` to rename the count column to `active_num`. (The `count` column name is ambiguous because it is both a function and a column.)\n- The query to complete this exercise is somewhat complicated and includes a sequence of many transformations. You may wish to assign variables to the intermediate DataFrames resulting from the transformations that make up the query to make the code easier to work with and debug.","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Use the account device data and the DataFrames you created previously in this exercise to find the total number of each device model across all <em>active</em> accounts &ndash; that is, accounts that have not been closed. The new DataFrame should be sorted from most to least common model. Save the data as Parquet files in a directory called <code>/user/zeppelin/top_devices</code> with the following columns:</p>\n<pre><code>| Column Name | Description                                                                                  | Example Value  |\n|-------------|----------------------------------------------------------------------------------------------|----------------|\n| device_id   | The ID number of each known device (including those that might not be in use by any account) | 18             |\n| make        | The manufacturer name for the device                                                         | Ronin          |\n| model       | The model name for the device                                                                | Novelty Note 2 |\n| active_num  | The total number of the model used by active accounts                                        | 2092           |\n</code></pre>\n<p>Hints:</p>\n<ul>\n<li>Active accounts are those with a null value for <code>acct_close_dt</code> (account close date) in the <code>accounts</code> table.</li>\n<li>The <code>account_id</code> column in the device accounts data corresponds to the <code>acct_num</code> column in <code>accounts</code> table.</li>\n<li>The <code>device_id</code> column in the device accounts data corresponds to the devnum column in the list of known devices in the <code>/devsh_loudacre/devices.json</code> file.</li>\n<li>When you count devices, use <code>withColumnRenamed</code> to rename the count column to <code>active_num</code>. (The <code>count</code> column name is ambiguous because it is both a function and a column.)</li>\n<li>The query to complete this exercise is somewhat complicated and includes a sequence of many transformations. You may wish to assign variables to the intermediate DataFrames resulting from the transformations that make up the query to make the code easier to work with and debug.</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1590357630444_1179107678","id":"20200424-202645_1446658215","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140612"},{"text":"%pyspark\n","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630445_2135391464","id":"20200428-024202_845661804","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140613"},{"title":"Review the resulting file","text":"%sh\nhdfs dfs -get /user/zeppelin/top_devices /tmp/\n\nparquet-tools head /tmp/top_devices","user":"sysadmin","dateUpdated":"2020-06-02T19:10:11+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591124947621_1606011542","id":"20200602-190907_1352716578","dateCreated":"2020-06-02T19:09:07+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:140614"},{"text":"%md\n# Result\n**You have now:** \n\n---","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Result</h1>\n<p><strong>You have now:</strong></p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1590357630445_1020914414","id":"20181126-133507_1472573213","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140615"},{"text":"%md\n# Solution\n---","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Solution</h1>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1590357630445_73792114","id":"20181018-125200_1133281582","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140616"},{"text":"%md\n### Query DataFrames Using Column Expressions","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Query DataFrames Using Column Expressions</h3>\n"}]},"apps":[],"jobName":"paragraph_1590357630445_-2098624498","id":"20200428-232253_1213291613","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140617"},{"title":"1 - Review the API documentation for the Spark Column class","text":"","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630446_418297507","id":"20200428-232312_1160155618","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140618"},{"title":"2 - Create a new DataFrame called accountsDF","text":"%pyspark\naccountsDF = spark.read.table(\"telco.accounts\")\naccountsDF.printSchema()\naccountsDF.show()","user":"sysadmin","dateUpdated":"2020-06-02T03:23:31+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630446_756271251","id":"20200428-232339_1779103463","dateCreated":"2020-05-24T22:00:30+0000","dateStarted":"2020-05-31T20:34:37+0000","dateFinished":"2020-05-31T20:34:51+0000","status":"ABORT","progressUpdateIntervalMs":500,"$$hashKey":"object:140619"},{"title":"3 - Practice using both column reference syntaxes","text":"%pyspark\n# Syntax 1\naccountsDF.select(accountsDF[\"first_name\"]).show()\n\n# Syntax 2\n#accountsDF.select(accountsDF.first_name).show()","user":"sysadmin","dateUpdated":"2020-05-26T04:06:39+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+\n|first_name|\n+----------+\n|    Donald|\n|     Donna|\n|    Dorthy|\n|     Leila|\n|     Anita|\n|    Stevie|\n|     David|\n|   Dorothy|\n|      Kara|\n|     Diane|\n|    Robert|\n|    Marcia|\n|    Andres|\n|       Ann|\n|    Joseph|\n|     Sarah|\n|      Lucy|\n|    Roland|\n|     Leona|\n|   Forrest|\n+----------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1590357630446_202616013","id":"20200428-232337_600421207","dateCreated":"2020-05-24T22:00:30+0000","dateStarted":"2020-05-26T04:06:26+0000","dateFinished":"2020-05-26T04:06:26+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140620"},{"title":"4 - Create a column object","text":"%pyspark\nfnCol = accountsDF.first_name","user":"sysadmin","dateUpdated":"2020-05-26T04:06:45+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1590357630446_1417706668","id":"20200428-232337_398231540","dateCreated":"2020-05-24T22:00:30+0000","dateStarted":"2020-05-26T04:06:45+0000","dateFinished":"2020-05-26T04:06:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140621"},{"title":"5 - View the available methods and attributes of the Column class","text":"%pyspark\n#fnCol.","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630447_-1314152789","id":"20200428-232336_2041671728","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140622"},{"title":"6 - Use a column expression to create a new column object","text":"%pyspark\nlucyCol = (fnCol == \"Lucy\")","user":"sysadmin","dateUpdated":"2020-05-26T04:06:49+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1590357630447_-1310015781","id":"20200428-232336_254950066","dateCreated":"2020-05-24T22:00:30+0000","dateStarted":"2020-05-26T04:06:49+0000","dateFinished":"2020-05-26T04:06:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140623"},{"title":"7 - Use the lucyCol column expression in a select statement","text":"%pyspark\naccountsDF.select(accountsDF.first_name,accountsDF.last_name,lucyCol).show()","user":"sysadmin","dateUpdated":"2020-05-26T04:06:50+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+---------+-------------------+\n|first_name|last_name|(first_name = Lucy)|\n+----------+---------+-------------------+\n|    Donald|   Becton|              false|\n|     Donna|    Jones|              false|\n|    Dorthy| Chalmers|              false|\n|     Leila|  Spencer|              false|\n|     Anita| Laughlin|              false|\n|    Stevie|   Bridge|              false|\n|     David|   Eggers|              false|\n|   Dorothy|  Koopman|              false|\n|      Kara|     Kohl|              false|\n|     Diane|   Nelson|              false|\n|    Robert|   Fisher|              false|\n|    Marcia|  Roberts|              false|\n|    Andres|    Cruse|              false|\n|       Ann|    Moore|              false|\n|    Joseph|   Lackey|              false|\n|     Sarah|   Duvall|              false|\n|      Lucy|   Corley|               true|\n|    Roland| Crawford|              false|\n|     Leona|     Bray|              false|\n|   Forrest|   Becker|              false|\n+----------+---------+-------------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1590357630447_-140701405","id":"20200428-232335_334373975","dateCreated":"2020-05-24T22:00:30+0000","dateStarted":"2020-05-26T04:06:51+0000","dateFinished":"2020-05-26T04:06:51+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140624"},{"title":"8 - Use the where operation","text":"%pyspark\naccountsDF.where(lucyCol).show(5)","user":"sysadmin","dateUpdated":"2020-05-26T04:06:54+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+-------------------+-------------------+----------+---------+--------------------+----------+-----+-------+------------+-------------------+-------------------+\n|acct_num|     acct_create_dt|      acct_close_dt|first_name|last_name|             address|      city|state|zipcode|phone_number|            created|           modified|\n+--------+-------------------+-------------------+----------+---------+--------------------+----------+-----+-------+------------+-------------------+-------------------+\n|      17|2008-12-27 23:31:40|               null|      Lucy|   Corley|   4834 Brown Street|Santa Rosa|   CA|  94980|  7076068290|2014-03-18 13:29:47|2014-03-18 13:29:47|\n|    1762|2009-03-19 23:43:00|               null|      Lucy|    Davis|2195 Riverside Drive|Sacramento|   CA|  95620|  9169959437|2014-03-18 13:29:50|2014-03-18 13:29:50|\n|    6551|2010-09-04 19:28:22|2014-02-14 19:19:16|      Lucy|  Casiano|2821 Wood Duck Drive|  Alhambra|   CA|  91810|  6261078791|2014-03-18 13:29:59|2014-03-18 13:29:59|\n|    6978|2010-09-22 07:13:16|               null|      Lucy|      Lee|4781 Shadowmar Drive|   Salinas|   CA|  93961|  8315367970|2014-03-18 13:30:00|2014-03-18 13:30:00|\n|    7107|2010-02-10 00:23:38|2014-01-23 22:55:06|      Lucy| Hastings|   4759 Gateway Road|    Fresno|   CA|  93692|  5595001084|2014-03-18 13:30:00|2014-03-18 13:30:00|\n+--------+-------------------+-------------------+----------+---------+--------------------+----------+-----+-------+------------+-------------------+-------------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1590357630447_699834775","id":"20200428-232335_471510672","dateCreated":"2020-05-24T22:00:30+0000","dateStarted":"2020-05-26T04:06:55+0000","dateFinished":"2020-05-26T04:06:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140625"},{"title":"9 - Try a query without assigning the result to a variable","text":"%pyspark\naccountsDF.where(fnCol == \"Lucy\").show(5)","user":"sysadmin","dateUpdated":"2020-05-26T04:06:56+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+-------------------+-------------------+----------+---------+--------------------+----------+-----+-------+------------+-------------------+-------------------+\n|acct_num|     acct_create_dt|      acct_close_dt|first_name|last_name|             address|      city|state|zipcode|phone_number|            created|           modified|\n+--------+-------------------+-------------------+----------+---------+--------------------+----------+-----+-------+------------+-------------------+-------------------+\n|      17|2008-12-27 23:31:40|               null|      Lucy|   Corley|   4834 Brown Street|Santa Rosa|   CA|  94980|  7076068290|2014-03-18 13:29:47|2014-03-18 13:29:47|\n|    1762|2009-03-19 23:43:00|               null|      Lucy|    Davis|2195 Riverside Drive|Sacramento|   CA|  95620|  9169959437|2014-03-18 13:29:50|2014-03-18 13:29:50|\n|    6551|2010-09-04 19:28:22|2014-02-14 19:19:16|      Lucy|  Casiano|2821 Wood Duck Drive|  Alhambra|   CA|  91810|  6261078791|2014-03-18 13:29:59|2014-03-18 13:29:59|\n|    6978|2010-09-22 07:13:16|               null|      Lucy|      Lee|4781 Shadowmar Drive|   Salinas|   CA|  93961|  8315367970|2014-03-18 13:30:00|2014-03-18 13:30:00|\n|    7107|2010-02-10 00:23:38|2014-01-23 22:55:06|      Lucy| Hastings|   4759 Gateway Road|    Fresno|   CA|  93692|  5595001084|2014-03-18 13:30:00|2014-03-18 13:30:00|\n+--------+-------------------+-------------------+----------+---------+--------------------+----------+-----+-------+------------+-------------------+-------------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1590357630447_107382378","id":"20200428-232335_698368359","dateCreated":"2020-05-24T22:00:30+0000","dateStarted":"2020-05-26T04:06:56+0000","dateFinished":"2020-05-26T04:06:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140626"},{"title":"10 - Column expressions can be used wherever a column could be used","text":"%pyspark\naccountsDF.select(\"city\", \"state\", accountsDF.phone_number.substr(1,3)).show(5)","user":"sysadmin","dateUpdated":"2020-05-26T04:07:02+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------+-----+-----------------------------+\n|         city|state|substring(phone_number, 1, 3)|\n+-------------+-----+-----------------------------+\n|      Oakland|   CA|                          510|\n|San Francisco|   CA|                          415|\n|    San Mateo|   CA|                          650|\n|    San Mateo|   CA|                          650|\n|     Richmond|   CA|                          510|\n+-------------+-----+-----------------------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1590357630448_-1792047289","id":"20200428-232335_1184100242","dateCreated":"2020-05-24T22:00:30+0000","dateStarted":"2020-05-26T04:07:02+0000","dateFinished":"2020-05-26T04:07:02+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140627"},{"title":"11 - Use the alias operator to rename a column","text":"%pyspark\naccountsDF.select(\"city\", \"state\", accountsDF.phone_number.substr(1,3).alias(\"area_code\")).show(5)","user":"sysadmin","dateUpdated":"2020-05-26T04:07:04+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------+-----+---------+\n|         city|state|area_code|\n+-------------+-----+---------+\n|      Oakland|   CA|      510|\n|San Francisco|   CA|      415|\n|    San Mateo|   CA|      650|\n|    San Mateo|   CA|      650|\n|     Richmond|   CA|      510|\n+-------------+-----+---------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1590357630448_428346124","id":"20200428-232334_1233728225","dateCreated":"2020-05-24T22:00:30+0000","dateStarted":"2020-05-26T04:07:05+0000","dateFinished":"2020-05-26T04:07:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140628"},{"title":"12 - Practice using transformations","text":"%pyspark\naccountsDF.where(accountsDF.first_name.substr(1,2) == accountsDF.last_name.substr(1,2)).select(\"first_name\",\"last_name\").show(5)","user":"sysadmin","dateUpdated":"2020-05-26T04:07:07+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+---------+\n|first_name|last_name|\n+----------+---------+\n|   Johnnie|    Jones|\n|    Robert|   Roller|\n|   Michael|  Minnick|\n| Rosemarie|Robertson|\n|     Keith|   Kemble|\n+----------+---------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1590357630448_-903599959","id":"20200428-232334_1759454808","dateCreated":"2020-05-24T22:00:30+0000","dateStarted":"2020-05-26T04:07:07+0000","dateFinished":"2020-05-26T04:07:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140629"},{"text":"%md\n### Group and Count Data by Name","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Group and Count Data by Name</h3>\n"}]},"apps":[],"jobName":"paragraph_1590357630448_-768405120","id":"20200428-232334_821188933","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140630"},{"title":"13 - Query the DataFrame using groupBy with the count aggregation transformation","text":"%pyspark\naccountsDF.groupBy(\"last_name\").count().show(5)","user":"sysadmin","dateUpdated":"2020-05-26T04:07:17+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+-----+\n|last_name|count|\n+---------+-----+\n|   Pinder|    8|\n|  Carlson|   75|\n|    Olson|   67|\n|  Rodgers|   41|\n| Ferguson|   83|\n+---------+-----+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1590357630449_1772631612","id":"20200428-232334_1509899401","dateCreated":"2020-05-24T22:00:30+0000","dateStarted":"2020-05-26T04:07:17+0000","dateFinished":"2020-05-26T04:07:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140631"},{"title":"14 - Use groupBy on multiple columns","text":"%pyspark\naccountsDF.groupBy(\"last_name\",\"first_name\").count().show(5)","user":"sysadmin","dateUpdated":"2020-05-26T04:07:20+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+----------+-----+\n|last_name|first_name|count|\n+---------+----------+-----+\n|     Ruiz|     Duane|    2|\n|    Smith| Christina|    5|\n|    Smith|    Bobbie|    2|\n|    Jones|    Carole|    2|\n|     King|     Edgar|    2|\n+---------+----------+-----+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1590357630449_427869527","id":"20200428-232334_896687392","dateCreated":"2020-05-24T22:00:30+0000","dateStarted":"2020-05-26T04:07:20+0000","dateFinished":"2020-05-26T04:07:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140632"},{"text":"%md\n### Join Account Data with Cellular Towers by Zip Code","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Join Account Data with Cellular Towers by Zip Code</h3>\n"}]},"apps":[],"jobName":"paragraph_1590357630449_-441846641","id":"20200428-232334_931178343","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140633"},{"title":"15 - Review the base_stations.parquet file","text":"","user":"sysadmin","dateUpdated":"2020-06-02T19:03:59+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionSupport":true,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630449_779737929","id":"20200428-232334_1714620989","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140634"},{"title":"16 - Upload the data file to HDFS","text":"%sh\nhdfs dfs -put /home/devuser/data/telco/base_stations.parquet /user/zeppelin/","user":"sysadmin","dateUpdated":"2020-05-26T04:07:45+0000","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1590357630450_-1728980348","id":"20200428-232333_209687192","dateCreated":"2020-05-24T22:00:30+0000","dateStarted":"2020-05-26T04:07:45+0000","dateFinished":"2020-05-26T04:07:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140635"},{"title":"17 - Create a new DataFrame using the base stations data","text":"%pyspark\nbaseDF = spark.read.parquet(\"/user/zeppelin/base_stations.parquet\")","user":"sysadmin","dateUpdated":"2020-05-26T04:07:50+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1590357630450_-175028085","id":"20200428-232333_92654281","dateCreated":"2020-05-24T22:00:30+0000","dateStarted":"2020-05-26T04:07:50+0000","dateFinished":"2020-05-26T04:07:50+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140636"},{"title":"18 - Perform a join on baseDF and accountsDF","text":"%pyspark\naccountsDF.select(\"acct_num\",\"first_name\",\"last_name\",\"zipcode\").join(baseDF, baseDF.zip==accountsDF.zipcode).show()","user":"sysadmin","dateUpdated":"2020-05-26T04:07:52+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+----------+-----------+-------+---+-----+-------------+-----+-------+---------+\n|acct_num|first_name|  last_name|zipcode| id|  zip|         city|state|    lat|      lon|\n+--------+----------+-----------+-------+---+-----+-------------+-----+-------+---------+\n|      37|    Cheryl|       West|  94622|231|94622|      Oakland|   CA| 37.799|-122.2337|\n|      56|   Terrell|   Hardiman|  94261|127|94261|   Sacramento|   CA|38.3774|-121.4444|\n|      60|     Irwin|Clatterbuck|  94403|185|94403|    San Mateo|   CA|37.5395|-122.2998|\n|      68|    Walter|    Greiner|  94701| 35|94701|     Berkeley|   CA|37.8606|-122.2967|\n|     126|     Keith|     Branan|  94623| 34|94623|      Oakland|   CA|37.6802|-121.9215|\n|     130|   Maynard|     Penley|  94120|165|94120|San Francisco|   CA|37.7848|-122.7278|\n|     179|     Julia|    Nowicki|  94059|182|94059| Redwood City|   CA|37.3811|-122.3348|\n|     183| Elizabeth|   McMillan|  94150|173|94150|San Francisco|   CA|37.7848|-122.7278|\n|     196|     Bruce|     Vargas|  94975|211|94975|     Petaluma|   CA|38.4631|  -122.99|\n|     233|     Arden|      Black|  94088|190|94088|    Sunnyvale|   CA|37.1894|-121.7053|\n|     241|    Conrad|  Fairchild|  94116|164|94116|San Francisco|   CA|37.7441|-122.4863|\n|     275|   Chelsea|      Gaona|  94040|189|94040|Mountain View|   CA|37.3855| -122.088|\n|     410|   Kenneth|    Nowicki|  94110|163|94110|San Francisco|   CA|37.7509|-122.4153|\n|     415|     Jason|       King|  94529| 39|94529|      Concord|   CA|37.7772|-121.9554|\n|     435|    Andrew|      Oakes|  94130|167|94130|San Francisco|   CA|37.8231|-122.3693|\n|     481|     Grace|     Brooks|  95675| 37|95675|  River Pines|   CA|38.5463| -120.743|\n|     489|    George|       Sams|  94088|190|94088|    Sunnyvale|   CA|37.1894|-121.7053|\n|     530|       Ann|   Stennett|  95190|202|95190|     San Jose|   CA|37.3894|-121.8868|\n|     543|      Joan|     Benito|  95915|121|95915|       Belden|   CA|39.9324|-121.3144|\n|     556|  Gretchen|    Akridge|  94074|184|94074| San Gregorio|   CA|37.3255|-122.3556|\n+--------+----------+-----------+-------+---+-----+-------------+-----+-------+---------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1590357630450_-1451589382","id":"20200428-232333_123134156","dateCreated":"2020-05-24T22:00:30+0000","dateStarted":"2020-05-26T04:07:52+0000","dateFinished":"2020-05-26T04:07:52+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140637"},{"text":"%md\n### Count Active Devices","user":"sysadmin","dateUpdated":"2020-05-24T22:00:30+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Count Active Devices</h3>\n"}]},"apps":[],"jobName":"paragraph_1590357630450_313187695","id":"20200428-232333_439776920","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140638"},{"title":"19 - Review the account device data and upload it to HDFS","text":"%sh\nhdfs dfs -put /home/devuser/data/telco/accountdevice /user/zeppelin/accountdevice","user":"sysadmin","dateUpdated":"2020-05-26T04:08:07+0000","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1590357630451_-920626653","id":"20200428-232333_2145921133","dateCreated":"2020-05-24T22:00:30+0000","dateStarted":"2020-05-26T04:08:07+0000","dateFinished":"2020-05-26T04:08:09+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140639"},{"title":"20 - Create a DataFrame based on the account device data","text":"%pyspark\naccountDeviceDF = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"/user/zeppelin/accountdevice\")","user":"sysadmin","dateUpdated":"2020-05-26T04:08:11+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1590357630451_331393130","id":"20200428-232333_1817940809","dateCreated":"2020-05-24T22:00:30+0000","dateStarted":"2020-05-26T04:08:11+0000","dateFinished":"2020-05-26T04:08:12+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140640"},{"title":"21 - Analyze the data presented in this exercise","text":"%pyspark\n# Create a DataFrame with only active accounts\nactiveAccountsDF = accountsDF.where(accountsDF.acct_close_dt.isNull())\n\n# Create a DataFrame with a device model IDs for only devices used by active accounts\nactiveAcctDevsDF =  activeAccountsDF.join(accountDeviceDF,activeAccountsDF.acct_num == accountDeviceDF.account_id).select(\"device_id\")\n\n# Sum up the total number of each device model \nsumDevicesDF = activeAcctDevsDF.groupBy(\"device_id\").count().withColumnRenamed(\"count\",\"active_num\")\n\n# Order by count in descending order\norderDevicesDF = sumDevicesDF.orderBy(sumDevicesDF.active_num.desc())\n\n# Create a DataFrame based on the devices.json file\ndevDF = spark.read.json(\"/user/zeppelin/devices.json\")\n\n# Join the list of device model totals with the list of devices\n# to get the make and model for each device\njoinDevicesDF = orderDevicesDF.join(devDF,sumDevicesDF.device_id == devDF.devnum)\n\n# Write out the data with the correct columns\n# Use overwrite mode so solution can be run multiple times\njoinDevicesDF.select(\"device_id\",\"make\",\"model\",joinDevicesDF.active_num).write.mode(\"overwrite\").save(\"/user/zeppelin/top_devices\")\n# *** ^^^Should be saved as parquet !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!","user":"sysadmin","dateUpdated":"2020-06-02T03:34:33+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590357630451_-490688322","id":"20200428-232327_1166252029","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140641"},{"title":"Review the resulting file","text":"%sh\nhdfs dfs -get /user/zeppelin/top_devices /tmp/\n\n# In a separate shell:\nparquet-tools head /tmp/top_devices","user":"sysadmin","dateUpdated":"2020-06-02T19:09:02+0000","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"get: `/tmp/top_devices/_SUCCESS': File exists\n"},{"type":"TEXT","data":"ExitValue: 1"}]},"apps":[],"jobName":"paragraph_1590357630452_-644118691","id":"20200428-232327_20671638","dateCreated":"2020-05-24T22:00:30+0000","dateStarted":"2020-05-26T04:08:33+0000","dateFinished":"2020-05-26T04:08:34+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:140642"},{"text":"%md\nWe hope you've enjoyed this lab. Below are additional resources that you should find useful:\n\n1. [Hortonworks Apache Spark Tutorials](http://hortonworks.com/tutorials/#tuts-developers) are your natural next step where you can explore Spark in more depth.\n2. [Hortonworks Community Connection (HCC)](https://community.hortonworks.com/spaces/85/data-science.html?type=question) is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.\n3. [Hortonworks Apache Spark Docs](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/spark-overview/content/analyzing_data_with_apache_spark.html) - official Spark documentation.\n4. [Hortonworks Apache Zeppelin Docs](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/zeppelin-overview/content/overview.html) - official Zeppelin documentation.\n","user":"sysadmin","dateUpdated":"2020-05-24T22:07:33+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>We hope you've enjoyed this lab. Below are additional resources that you should find useful:</p>\n<ol>\n<li><a href=\"http://hortonworks.com/tutorials/#tuts-developers\">Hortonworks Apache Spark Tutorials</a> are your natural next step where you can explore Spark in more depth.</li>\n<li><a href=\"https://community.hortonworks.com/spaces/85/data-science.html?type=question\">Hortonworks Community Connection (HCC)</a> is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.</li>\n<li><a href=\"https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/spark-overview/content/analyzing_data_with_apache_spark.html\">Hortonworks Apache Spark Docs</a> - official Spark documentation.</li>\n<li><a href=\"https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/zeppelin-overview/content/overview.html\">Hortonworks Apache Zeppelin Docs</a> - official Zeppelin documentation.</li>\n</ol>\n"}]},"apps":[],"jobName":"paragraph_1590357630452_-1923354568","id":"20181126-133017_244739700","dateCreated":"2020-05-24T22:00:30+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140643"}],"name":"PYSPARK/06-AnalyzingDatawithDataFrameQueries","id":"2F9GTNYEW","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"angular:shared_process":[],"sh:shared_process":[],"jdbc:shared_process":[],"spark2:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}