{"paragraphs":[{"text":"%md\n# About\n**Lab:** Using Datasets in Scala\n**Objective:** Explore Datasets using web log data\n**File locations:**\n    /user/zeppelin/weblogs\n\n**Successful outcome:** \n**Before you begin:** \n**Related lessons:** \n\n---","user":"sysadmin","dateUpdated":"2020-06-04T19:06:52+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>About</h1>\n<p><strong>Lab:</strong> Using Datasets in Scala\n<br  /><strong>Objective:</strong> Explore Datasets using web log data\n<br  /><strong>File locations:</strong></p>\n<pre><code>/devsh_loudacre/weblogs\n</code></pre>\n<p><strong>Successful outcome:</strong>\n<br  /><strong>Before you begin:</strong>\n<br  /><strong>Related lessons:</strong></p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1591297511329_677802870","id":"20181126-092644_1457476546","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:21246"},{"text":"%md\n# Setup","user":"sysadmin","dateUpdated":"2020-06-04T19:05:37+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Setup</h1>\n<p><strong>Important:</strong> This exercise depends on <strong><em> ***Insert previous exercise title here (with link?)*** </em></strong>. If you did not complete that exercise, run the course catch-up script and advance to the current exercise:</p>\n<pre><code>$ $DEVSH/scripts/catchup.sh\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1591297511330_-796760304","id":"20181201-044336_178705192","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21247"},{"text":"%md\n# Lab\n","user":"sysadmin","dateUpdated":"2020-06-04T19:05:11+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Lab</h1>\n"}]},"apps":[],"jobName":"paragraph_1591297511331_-1789399607","id":"20181126-093358_358613711","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21248"},{"text":"%md\n### Explore Datasets Using Web Log Data\n\nFind all the account IDs and the IP addresses from which those accounts logged in to the web site from Loudacre's web log data.","user":"sysadmin","dateUpdated":"2020-06-04T19:05:11+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Explore Datasets Using Web Log Data</h3>\n<p>Find all the account IDs and the IP addresses from which those accounts logged in to the web site from Loudacre's web log data.</p>\n"}]},"apps":[],"jobName":"paragraph_1591297511331_286540015","id":"20200425-214556_1601909015","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21249"},{"title":"1 - Create a case class for account ID/IP address pairs","text":"%spark2\ncase class AccountIP (id: Int, ip: String)","user":"sysadmin","dateUpdated":"2020-06-04T19:05:44+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511332_176953940","id":"20200425-214738_1778456643","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21250"},{"title":"2 - Create an RDD of AccountIP objects","text":"%md\nCreate an RDD of `AccountIP` objects by using the web log data in `/devsh_loudacre/weblogs`. Split the data by spaces and use the first field as IP address and the third as account ID.","user":"sysadmin","dateUpdated":"2020-06-04T19:05:11+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511333_1906514144","id":"20200429-045932_1953923456","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21251"},{"title":"","text":"%spark2\nval accountIPRDD = sc.\ntextFile(\"/user/zeppelin/weblogs\").\nmap(line => line.split(' ')).\nmap(fields => new AccountIP(fields(2).toInt,fields(0)))","user":"sysadmin","dateUpdated":"2020-06-04T19:06:59+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:28: error: not found: type AccountIP\n       map(fields => new AccountIP(fields(2).toInt,fields(0)))\n                         ^\n"}]},"apps":[],"jobName":"paragraph_1591297511334_-1957388444","id":"20200425-214850_1932539533","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21252"},{"title":"3 - Create a Dataset of AccountIP objects using the new RDD","text":"%spark2\nval accountIPDS = spark.createDataset(accountIPRDD)","user":"sysadmin","dateUpdated":"2020-06-04T19:07:05+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511334_207570594","id":"20200425-215002_646404360","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21253"},{"title":"4 - View the schema and the data in the new Dataset","text":"%spark2\n","user":"sysadmin","dateUpdated":"2020-06-04T19:07:18+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511335_-109243186","id":"20200425-215045_629388297","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21254"},{"title":"5 - Compare the result types of a typed transformation and an untyped transformation","text":"%md\nCompare the result types of a typed transformation -- `distinct` -- and an untyped transformation -- `groupBy/count`.","user":"sysadmin","dateUpdated":"2020-06-04T19:05:11+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511336_286381772","id":"20200425-215147_758473712","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21255"},{"text":"%spark2\nval distinctIPDS = accountIPDS.distinct\nval accountIPCountDS = distinctIPDS.groupBy(\"id\",\"ip\").count","user":"sysadmin","dateUpdated":"2020-06-04T19:05:11+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511337_43534773","id":"20200429-050210_544844192","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21256"},{"title":"6 - Save the new Dataset as a Parquet file, then read it back into a DataFrame","text":"%md\nSave the `accountIPDS` Dataset as a Parquet file, then read the file back into a DataFrame. Note that the type of the original Dataset (`AccountIP`) is not preserved, but the types of the columns are.","user":"sysadmin","dateUpdated":"2020-06-04T19:05:11+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511337_579370614","id":"20200425-215146_2094043180","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21257"},{"text":"%spark2\n","user":"sysadmin","dateUpdated":"2020-06-04T19:05:11+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511338_-1976969458","id":"20200429-050458_1142980792","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21258"},{"text":"%md\n### Bonus Exercise","user":"sysadmin","dateUpdated":"2020-06-04T19:05:11+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Bonus Exercise</h3>\n"}]},"apps":[],"jobName":"paragraph_1591297511338_1931603078","id":"20200425-215146_126681074","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21259"},{"title":"1 - Perform a SQL query on a view","text":"%md\nCreate a view on the `AccountIPDS` Dataset, and perform a SQL query on the view. What is the return type of the SQL query? Were column types preserved?","user":"sysadmin","dateUpdated":"2020-06-04T19:05:11+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511339_-498606425","id":"20200425-215145_1722351189","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21260"},{"text":"%spark2\n","user":"sysadmin","dateUpdated":"2020-06-04T19:05:11+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511339_1329462517","id":"20200429-050600_1572101890","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21261"},{"text":"%md\n# Result\n**You have now:** \n\n---","user":"sysadmin","dateUpdated":"2020-06-04T19:05:11+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Result</h1>\n<p><strong>You have now:</strong></p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1591297511340_857491201","id":"20181126-133507_1472573213","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21262"},{"text":"%md\n# Solution\n---","user":"sysadmin","dateUpdated":"2020-06-04T19:05:11+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Solution</h1>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1591297511341_122828450","id":"20181018-125200_1133281582","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21263"},{"text":"%md\n### Explore Datasets Using Web Log Data\n\nIf not previously uploaded: \n```\n$ hdfs dfs -put /home/devuser/data/telco/weblogs /user/zeppelin/\n```","user":"sysadmin","dateUpdated":"2020-06-04T19:07:54+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511341_-1464199808","id":"20200429-045508_1792730451","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21264"},{"title":"1 - Create a case class for account ID/IP address pairs","text":"%spark2\ncase class AccountIP (id: Int, ip: String)","user":"sysadmin","dateUpdated":"2020-06-04T19:07:59+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511342_-830343724","id":"20200429-045519_1771957595","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21265"},{"title":"2 - Create an RDD of AccountIP objects","text":"%spark2\nval accountIPRDD=sc.textFile(\"/user/zeppelin/weblogs\").map(line => line.split(' ')).map(fields => new AccountIP(fields(2).toInt,fields(0)))","user":"sysadmin","dateUpdated":"2020-06-04T19:08:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511343_1430022169","id":"20200429-045517_898375787","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21266"},{"title":"3 - Create a Dataset of AccountIP objects using the new RDD","text":"%spark2\nval accountIPDS = spark.createDataset(accountIPRDD)","user":"sysadmin","dateUpdated":"2020-06-04T19:08:23+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511344_411014633","id":"20200429-045515_737119741","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21267"},{"title":"4 - View the schema and the data in the new Dataset","text":"%spark2\naccountIPDS.printSchema\naccountIPDS.show","user":"sysadmin","dateUpdated":"2020-06-04T19:08:32+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511345_364710257","id":"20200429-045514_971111712","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21268"},{"title":"5 - Compare the result types of a typed transformation and an untyped transformation","text":"%spark2\nval distinctIPDS = accountIPDS.distinct\nval accountIPCountDS = distinctIPDS.groupBy(\"id\",\"ip\").count","user":"sysadmin","dateUpdated":"2020-06-04T19:08:42+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511346_-1014600991","id":"20200429-045514_1400658563","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21269"},{"title":"6 - Save the new Dataset as a Parquet file, then read it back into a DataFrame","text":"%spark2\naccountIPDS.write.save(\"/user/zeppelin/accountIPs\")\n\nval accountIPDF = spark.read.load(\"/user/zeppelin/accountIPs\")","user":"sysadmin","dateUpdated":"2020-06-04T19:09:02+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511347_-351926337","id":"20200429-045513_134581158","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21270"},{"text":"%md\n### Bonus Exercise","user":"sysadmin","dateUpdated":"2020-06-04T19:05:11+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511348_-1716202243","id":"20200429-045512_272015402","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21271"},{"title":"1 - Perform a SQL query on a view","text":"%spark2\n//case class AccountIP (id: Int, ip: String)\n\n//val accountIPRDD=sc.textFile(\"/devsh_loudacre/weblogs\").map(line => line.split(' ')).map(fields => new AccountIP(fields(2).toInt,fields(0)))\n\n//val accountIPDS = spark.createDataset(accountIPRDD)\naccountIPDS.createOrReplaceTempView(\"account_ip\")\nval queryDF = spark.sql(\"SELECT DISTINCT *  FROM account_ip WHERE id < 200\")\nqueryDF.printSchema\nqueryDF.show","user":"sysadmin","dateUpdated":"2020-06-04T19:09:33+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591297511348_1544605389","id":"20200429-045511_206929784","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21272"},{"text":"%md\nWe hope you've enjoyed this lab. Below are additional resources that you should find useful:\n\n1. [Hortonworks Apache Spark Tutorials](http://hortonworks.com/tutorials/#tuts-developers) are your natural next step where you can explore Spark in more depth.\n2. [Hortonworks Community Connection (HCC)](https://community.hortonworks.com/spaces/85/data-science.html?type=question) is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.\n3. [Hortonworks Apache Spark Docs](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/spark-overview/content/analyzing_data_with_apache_spark.html) - official Spark documentation.\n4. [Hortonworks Apache Zeppelin Docs](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/zeppelin-overview/content/overview.html) - official Zeppelin documentation.\n","user":"sysadmin","dateUpdated":"2020-06-04T19:09:49+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>We hope you've enjoyed this lab. Below are additional resources that you should find useful:</p>\n<ol>\n<li><a href=\"http://hortonworks.com/tutorials/#tuts-developers\">Hortonworks Apache Spark Tutorials</a> are your natural next step where you can explore Spark in more depth.</li>\n<li><a href=\"https://community.hortonworks.com/spaces/85/data-science.html?type=question\">Hortonworks Community Connection (HCC)</a> is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.</li>\n<li><a href=\"https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/spark-overview/content/analyzing_data_with_apache_spark.html\">Hortonworks Apache Spark Docs</a> - official Spark documentation.</li>\n<li><a href=\"https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/zeppelin-overview/content/overview.html\">Hortonworks Apache Zeppelin Docs</a> - official Zeppelin documentation.</li>\n</ol>\n"}]},"apps":[],"jobName":"paragraph_1591297511349_1623749288","id":"20181126-133017_244739700","dateCreated":"2020-06-04T19:05:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:21273"}],"name":"ScalaSpark/11-UsingDatasetsInScala","id":"2FAX31QJZ","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"sh:shared_process":[],"jdbc:shared_process":[],"spark2:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}